{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c82473-1e97-4dc3-b404-c5926b20deaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19153030-7623-40fd-8c0a-c969bcb9dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7eb3bd-f350-47e1-9e71-6ee334e08c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated random seed is 76\n"
     ]
    }
   ],
   "source": [
    "# Initialise the random state\n",
    "num = random.randint(1, 500)\n",
    "\n",
    "torch.manual_seed(num)\n",
    "print(f\"The generated random seed is {num}\") #347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bec4425-36e5-40c7-a35c-2dc247661b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_id</th>\n",
       "      <th>id</th>\n",
       "      <th>p_id</th>\n",
       "      <th>itr_id</th>\n",
       "      <th>prj_id</th>\n",
       "      <th>ppt_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>hand</th>\n",
       "      <th>clt_id</th>\n",
       "      <th>ch_01</th>\n",
       "      <th>ch_02</th>\n",
       "      <th>ch_03</th>\n",
       "      <th>ch_04</th>\n",
       "      <th>ch_05</th>\n",
       "      <th>ch_06</th>\n",
       "      <th>ch_07</th>\n",
       "      <th>ch_08</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_id      id  p_id  itr_id  prj_id  ppt_id  rating  hand  clt_id  \\\n",
       "0       1  132383    19     119     622      16       6     0      27   \n",
       "1       2  132383    19     119     622      16       6     0      27   \n",
       "2       3  132383    19     119     622      16       6     0      27   \n",
       "3       4  132383    19     119     622      16       6     0      27   \n",
       "4       5  132383    19     119     622      16       6     0      27   \n",
       "\n",
       "      ch_01     ch_02     ch_03     ch_04     ch_05     ch_06     ch_07  \\\n",
       "0  0.001062  0.003030  0.002932  0.006998  0.010902  0.016429  0.024816   \n",
       "1  0.001062  0.011202  0.002932  0.001948  0.002860  0.000817  0.015065   \n",
       "2  0.001062  0.003030  0.002932  0.001948  0.002860  0.014796  0.004439   \n",
       "3  0.001062  0.003030  0.006901  0.001948  0.002860  0.014796  0.005313   \n",
       "4  0.001062  0.003030  0.002932  0.001948  0.002860  0.014796  0.005313   \n",
       "\n",
       "      ch_08                timestamp  \n",
       "0  0.034724  2022-02-13 11:24:11.302  \n",
       "1  0.004675  2022-02-13 11:24:11.302  \n",
       "2  0.024374  2022-02-13 11:24:11.302  \n",
       "3  0.044074  2022-02-13 11:24:11.302  \n",
       "4  0.004675  2022-02-13 11:24:11.302  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed emg data\n",
    "emg_path = \"/Users/niharawarawita/Desktop/MSc Project/Data/EMG_data_collection/emg_combined_stats.csv\"\n",
    "emg_df = pd.read_csv(emg_path)\n",
    "emg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157053d6-3787-423d-a432-3d7fb8ae0294",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Preprocess the emg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc77ca27-1650-4414-a120-51671ffc5dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_id</th>\n",
       "      <th>id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>hand</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>ch_01</th>\n",
       "      <th>ch_02</th>\n",
       "      <th>ch_03</th>\n",
       "      <th>ch_04</th>\n",
       "      <th>ch_05</th>\n",
       "      <th>ch_06</th>\n",
       "      <th>ch_07</th>\n",
       "      <th>ch_08</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_id      id  participant_id  interaction_id  project_id  property_id  \\\n",
       "0       1  132383              19             119         622           16   \n",
       "1       2  132383              19             119         622           16   \n",
       "2       3  132383              19             119         622           16   \n",
       "3       4  132383              19             119         622           16   \n",
       "4       5  132383              19             119         622           16   \n",
       "\n",
       "   rating  hand  clothes_id     ch_01     ch_02     ch_03     ch_04     ch_05  \\\n",
       "0       6     0          27  0.001062  0.003030  0.002932  0.006998  0.010902   \n",
       "1       6     0          27  0.001062  0.011202  0.002932  0.001948  0.002860   \n",
       "2       6     0          27  0.001062  0.003030  0.002932  0.001948  0.002860   \n",
       "3       6     0          27  0.001062  0.003030  0.006901  0.001948  0.002860   \n",
       "4       6     0          27  0.001062  0.003030  0.002932  0.001948  0.002860   \n",
       "\n",
       "      ch_06     ch_07     ch_08                timestamp  \n",
       "0  0.016429  0.024816  0.034724  2022-02-13 11:24:11.302  \n",
       "1  0.000817  0.015065  0.004675  2022-02-13 11:24:11.302  \n",
       "2  0.014796  0.004439  0.024374  2022-02-13 11:24:11.302  \n",
       "3  0.014796  0.005313  0.044074  2022-02-13 11:24:11.302  \n",
       "4  0.014796  0.005313  0.004675  2022-02-13 11:24:11.302  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_df.rename(columns={'p_id': 'participant_id', 'itr_id': 'interaction_id',  'prj_id': 'project_id',  'ppt_id': 'property_id', 'clt_id': 'clothes_id'}, inplace=True)\n",
    "emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab4f6d2-d5fb-4e5f-8868-2c98574fe3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>hand</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>ch_01</th>\n",
       "      <th>ch_02</th>\n",
       "      <th>ch_03</th>\n",
       "      <th>ch_04</th>\n",
       "      <th>ch_05</th>\n",
       "      <th>ch_06</th>\n",
       "      <th>ch_07</th>\n",
       "      <th>ch_08</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  interaction_id  property_id  rating  hand  clothes_id  \\\n",
       "0              19             119           16       6     0          27   \n",
       "1              19             119           16       6     0          27   \n",
       "2              19             119           16       6     0          27   \n",
       "3              19             119           16       6     0          27   \n",
       "4              19             119           16       6     0          27   \n",
       "\n",
       "      ch_01     ch_02     ch_03     ch_04     ch_05     ch_06     ch_07  \\\n",
       "0  0.001062  0.003030  0.002932  0.006998  0.010902  0.016429  0.024816   \n",
       "1  0.001062  0.011202  0.002932  0.001948  0.002860  0.000817  0.015065   \n",
       "2  0.001062  0.003030  0.002932  0.001948  0.002860  0.014796  0.004439   \n",
       "3  0.001062  0.003030  0.006901  0.001948  0.002860  0.014796  0.005313   \n",
       "4  0.001062  0.003030  0.002932  0.001948  0.002860  0.014796  0.005313   \n",
       "\n",
       "      ch_08                timestamp  \n",
       "0  0.034724  2022-02-13 11:24:11.302  \n",
       "1  0.004675  2022-02-13 11:24:11.302  \n",
       "2  0.024374  2022-02-13 11:24:11.302  \n",
       "3  0.044074  2022-02-13 11:24:11.302  \n",
       "4  0.004675  2022-02-13 11:24:11.302  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_df.drop(['new_id', 'id', 'project_id'], axis=1, inplace=True)\n",
    "emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f89cb6-f5cc-4b9e-bf49-23c2aebaf9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the timestamp to the datetime format\n",
    "emg_df['timestamp']= pd.to_datetime(emg_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c020378-1343-4433-a392-f65a692d317b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the values in each df by ascending value of the timestamp\n",
    "emg_df.sort_values(by=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed299123-0402-4e82-b9fa-93e565c2294f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into hands 0 (left) and 1 (right)\n",
    "emg_0 = emg_df[emg_df.hand == 0]\n",
    "emg_1 = emg_df[emg_df.hand == 1]\n",
    "\n",
    "# Reset indexes\n",
    "emg_0.reset_index(inplace=True, drop = True)\n",
    "emg_1.reset_index(inplace=True, drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6225c3c9-ff37-4042-9528-24dfc0f7fbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interaction_time(df):\n",
    "    # Create a column for the starting time of each interaction \n",
    "    df['interaction_start_time'] = df['timestamp'].groupby(df['interaction_id']).transform('min')\n",
    "    # Create a column for the ending time of each interaction \n",
    "    df['interaction_end_time'] = df['timestamp'].groupby(df['interaction_id']).transform('max')\n",
    "    \n",
    "    df['interaction_duration'] = df['interaction_end_time'] - df['interaction_start_time']#.datetime.total_seconds()\n",
    "    df['interaction_duration'] = df['interaction_duration'].dt.total_seconds()\n",
    "    return df\n",
    "\n",
    "emg_0 = interaction_time(emg_0)\n",
    "emg_1 = interaction_time(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b3f1116-c870-41d1-b85b-466e03440739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def emg_get_15_seconds(interaction_id, emg_interaction_df, emg_df):\n",
    "    interaction_end_time = emg_interaction_df.iloc[0,16]\n",
    "    threshold = interaction_end_time - datetime.timedelta(0,16)\n",
    "\n",
    "    # Remove rows with interaction_id with a timestamp less than the threshold from the dfs\n",
    "    emg_df.drop(emg_df[(emg_df.interaction_id==interaction_id) & (emg_df.timestamp<=threshold)].index, inplace=True)\n",
    "    \n",
    "    # Drop the interaction_start_time and interaction_end_time for the dfs\n",
    "    emg_df.drop(['interaction_start_time', 'interaction_end_time', 'interaction_duration'], axis=1, inplace=True)\n",
    "\n",
    "    # Recalculate the columns\n",
    "    emg_df = interaction_time(emg_df)\n",
    "     \n",
    "    return emg_df\n",
    "\n",
    "emg_191_0 = emg_0[emg_0.interaction_id==191]\n",
    "emg_0 = emg_get_15_seconds(191, emg_191_0, emg_0) \n",
    "emg_196_0 = emg_0[emg_0.interaction_id==196]\n",
    "emg_0 = emg_get_15_seconds(196, emg_196_0, emg_0) \n",
    "\n",
    "emg_191_1 = emg_1[emg_1.interaction_id==191]\n",
    "emg_1 = emg_get_15_seconds(191, emg_191_1, emg_1)  \n",
    "emg_196_1 = emg_1[emg_1.interaction_id==196]\n",
    "emg_1 = emg_get_15_seconds(196, emg_196_1, emg_1)  \n",
    "emg_296_1 = emg_1[emg_1.interaction_id==296]\n",
    "emg_1 = emg_get_15_seconds(296, emg_296_1, emg_1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3734301f-6968-4800-82b2-0aaef677f2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_property_names_column(df):\n",
    "    df.insert(3, 'property_name', 'smoothness')\n",
    "    df.property_name[df['property_id'] == 13] = 'thickness'\n",
    "    df.property_name[df['property_id'] == 14] = 'warmth'\n",
    "    df.property_name[df['property_id'] == 15] = 'flexibility'\n",
    "    df.property_name[df['property_id'] == 16] = 'softness'\n",
    "    df.property_name[df['property_id'] == 17] = 'enjoyment'\n",
    "    return df\n",
    "\n",
    "emg_0 = add_property_names_column(emg_0)\n",
    "emg_1 = add_property_names_column(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56e96da1-e33e-4fea-844b-591dceae92e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emg_0 = emg_0[emg_0.property_name != 'enjoyment']\n",
    "emg_1 = emg_1[emg_1.property_name != 'enjoyment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69dc269-bc36-4ccc-a247-bf9bb5058af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def renumber_socks(df):\n",
    "    df.clothes_id[(df['clothes_id'] == 25) | (df['clothes_id'] == 31) | (df['clothes_id'] == 38) | (df['clothes_id'] == 44) | (df['clothes_id'] == 50) | (df['clothes_id'] == 56)] = 1\n",
    "    df.clothes_id[(df['clothes_id'] == 26) | (df['clothes_id'] == 32) | (df['clothes_id'] == 39) | (df['clothes_id'] == 45) | (df['clothes_id'] == 51) | (df['clothes_id'] == 57)] = 2\n",
    "    df.clothes_id[(df['clothes_id'] == 27) | (df['clothes_id'] == 33) | (df['clothes_id'] == 40) | (df['clothes_id'] == 46) | (df['clothes_id'] == 52) | (df['clothes_id'] == 58)] = 3\n",
    "    df.clothes_id[(df['clothes_id'] == 28) | (df['clothes_id'] == 34) | (df['clothes_id'] == 41) | (df['clothes_id'] == 47) | (df['clothes_id'] == 53) | (df['clothes_id'] == 59)] = 4\n",
    "    df.clothes_id[(df['clothes_id'] == 29) | (df['clothes_id'] == 35) | (df['clothes_id'] == 42) | (df['clothes_id'] == 48) | (df['clothes_id'] == 54) | (df['clothes_id'] == 60)] = 5\n",
    "    df.clothes_id[(df['clothes_id'] == 30) | (df['clothes_id'] == 36) | (df['clothes_id'] == 43) | (df['clothes_id'] == 49) | (df['clothes_id'] == 55) | (df['clothes_id'] == 61)] = 6\n",
    "    return df\n",
    "\n",
    "emg_0 = renumber_socks(emg_0)\n",
    "emg_1 = renumber_socks(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f51ed2a-1c5a-439c-863c-a56242ef2c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_classes_rating(df):\n",
    "    df.insert(5, 'rating_level', 'medium')\n",
    "    df.loc[df['rating'] > 5,'rating_level'] = 'high'\n",
    "    df.loc[df['rating'] < 3,'rating_level'] = 'low'\n",
    "    return df\n",
    "    \n",
    "emg_0 = combine_classes_rating(emg_0)\n",
    "emg_1 = combine_classes_rating(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b694d56d-eef3-41dc-a963-e44262aba520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def represent_rating_level_numerically(df):\n",
    "    df.insert(6, 'rating_level_num', 1)\n",
    "    df.loc[df['rating_level'] == 'medium','rating_level_num'] = 2\n",
    "    df.loc[df['rating_level'] == 'high','rating_level_num'] = 3\n",
    "    return df\n",
    "\n",
    "emg_0 = represent_rating_level_numerically(emg_0)\n",
    "emg_1 = represent_rating_level_numerically(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd823992-19c5-4031-83d7-1fa9d9e2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subwindows(df, num_subwindows=15):\n",
    "    \n",
    "    # Create a column with the subwindow numbers\n",
    "    df.insert(9, 'sub_window_num', num_subwindows)\n",
    "    for num in range(num_subwindows-1,0,-1):\n",
    "        df.sub_window_num[pd.to_datetime(df['timestamp']) <= pd.to_datetime(df['interaction_start_time']) + datetime.timedelta(0,num)] = num\n",
    "        \n",
    "    return df\n",
    "\n",
    "emg_0 = create_subwindows(emg_0, num_subwindows=15)\n",
    "emg_1 = create_subwindows(emg_1, num_subwindows=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1975e781-29d1-4e1f-9075-a840a24ebb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_emg(df):\n",
    "    column_names = ['ch_01','ch_02','ch_03','ch_04','ch_05','ch_06','ch_07','ch_08']\n",
    "    for col in column_names:\n",
    "        new_col_name = 'mean_'+col           \n",
    "        df[new_col_name] = df[col].groupby([df['interaction_id'], df['sub_window_num']]).transform('mean')\n",
    "    return df\n",
    "\n",
    "\n",
    "emg_0 = downsample_emg(emg_0)\n",
    "emg_1 = downsample_emg(emg_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc122011-d032-4b85-aa62-785a21d5ed6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emg_0_new = emg_0[['participant_id','clothes_id', 'property_id','property_name','interaction_id','hand','rating','rating_level','rating_level_num', 'sub_window_num', 'mean_ch_01','mean_ch_02','mean_ch_03','mean_ch_04','mean_ch_05','mean_ch_06','mean_ch_07','mean_ch_08']]\n",
    "emg_1_new = emg_1[['participant_id','clothes_id', 'property_id','property_name','interaction_id','hand','rating','rating_level','rating_level_num', 'sub_window_num', 'mean_ch_01','mean_ch_02','mean_ch_03','mean_ch_04','mean_ch_05','mean_ch_06','mean_ch_07','mean_ch_08']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adb93a3c-e1ff-49ca-8045-c2ccf751918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1307504, 18)\n",
      "(1307504, 18)\n"
     ]
    }
   ],
   "source": [
    "print(emg_0_new.shape)\n",
    "print(emg_0_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e4aef6-ff3d-4513-9e3a-ff7f8118cbac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "emg_0_new.drop_duplicates(keep='first', inplace=True)\n",
    "emg_1_new.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# Reset the indexes\n",
    "emg_0_new.reset_index(drop=True, inplace=True) \n",
    "emg_1_new.reset_index(drop=True, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb803388-d93c-4521-958a-9e4797fef677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2694, 18)\n",
      "(2694, 18)\n"
     ]
    }
   ],
   "source": [
    "print(emg_0_new.shape)\n",
    "print(emg_0_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5db3c38-6cb2-499c-85d1-93005fdd4934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 15\n",
      "min: 9\n",
      "mean: 15.0\n",
      "std: 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='interaction_id'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEQCAYAAABPxOQhAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAk5klEQVR4nO3dfbxdVX3n8c8vuSQkAZIA5UFQg0J1LFaxsSiiVlFLWx87dipWC2plpg+jtlqLxdE601fHqm1tbTsOClI7FFGE0fqAIMWi8ngJgYQkyEMSSCCEPJLkJrm59/7mj99vzd45nvt0zrk3ZPN9v173te49Z6+91l577d9ee+19zjV3R0REmmHGga6AiIj0joK6iEiDKKiLiDSIgrqISIMoqIuINEjfdBZ29NFH+6JFi6azSBGRg94dd9yxyd1/ZiLLTmtQX7RoEf39/dNZpIjIQc/M1k50WU2/iIg0iIK6iEiDKKiLiDSIgrqISIMoqIuINIiCuohIgyioi4g0iIK6iEiDKKiLiDTItAb1Zeu3A7Dogm9POJ3MsgdDnuLJmufJ3n5q8yd/njq1eW/yTIZG6iIiDaKgLiLSIArqIiINoqAuItIgCuoiIg2ioC4i0iAK6iIiDaKgLiLSIArqIiINMm5QN7NLzGyjmS1v896HzMzN7OipqZ6IiEzGREbqlwJnt75oZk8HXgs81OM6iYhIh8YN6u5+I7ClzVt/A3wY8F5XSkREOtPRnLqZvRFY7+53TWDZ882s38z6hwe2d1KciIhMUN9kM5jZXOBC4HUTWd7dLwIuAph9/Cka1YuITKFORurPBk4C7jKzNcCJwBIzO66XFRMRkcmb9Ejd3ZcBx5S/M7AvdvdNPayXiIh0YCKPNF4O3Aw8x8zWmdl7pr5aIiLSiXFH6u5+zjjvL+pZbUREpCv6RKmISIMoqIuINIiCuohIgyioi4g0iIK6iEiDKKiLiDSIgrqISIMoqIuINIiCuohIgyioi4g0iIK6iEiDKKiLiDSIgrqISIMoqIuINIiCuohIgyioi4g0iIK6iEiDKKiLiDSIgrqISINM5B9PX2JmG81see21T5vZKjO728yuNrMFU1pLERGZkImM1C8Fzm557TrgVHf/eeAnwEd6XC8REenAuEHd3W8EtrS8dq27D+WftwAnTkHdRERkknoxp/5u4LujvWlm55tZv5n1Dw9s70FxIiIymq6CupldCAwBl422jLtf5O6L3X3xzLnzuylORETG0ddpRjM7F3g9cJa7e++qJCIineooqJvZ2cCfAK9094HeVklERDo1kUcaLwduBp5jZuvM7D3A3wOHA9eZ2VIz+/wU11NERCZg3JG6u5/T5uWLp6AuIiLSJX2iVESkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGkRBXUSkQSbyj6cvMbONZra89tqRZnadmd2X6cKpraaIiEzEREbqlwJnt7x2AXC9u58CXJ9/i4jIATZuUHf3G4EtLS+/Cfin/P2fgDf3tloiItKJTufUj3X3RwEyPWa0Bc3sfDPrN7P+4YHtHRYnIiITMeU3St39Indf7O6LZ86dP9XFiYg8pXUa1B8zs+MBMt3YuyqJiEinOg3q3wTOzd/PBb7Rm+qIiEg3JvJI4+XAzcBzzGydmb0H+CTwWjO7D3ht/i0iIgdY33gLuPs5o7x1Vo/rIiIiXdInSkVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGkRBXUSkQRTURaSnFl3w7QNdhac0BXURkQZRUBcRaRAFdRGRBlFQFxFpEAV1EZEGUVAXEWkQBXURkQZRUBcRaRAFdRGRBukqqJvZH5rZPWa23MwuN7NDe1UxERGZvI6DupmdALwPWOzupwIzgbf1qmIiIjJ53U6/9AFzzKwPmAs80n2VRESkUx0HdXdfD3wGeAh4FNju7te2Lmdm55tZv5n1Dw9s77ymIiIyrm6mXxYCbwJOAp4GzDOzd7Qu5+4Xuftid188c+78zmsqIiLj6mb65TXAand/3N33AVcBZ/SmWiIi0olugvpDwEvMbK6ZGXAWsLI31RIRkU50M6d+K3AlsARYluu6qEf1EhGRDvR1k9ndPw58vEd1ERGRLukTpSIiDaKgLiLSIArqIiINoqAuItIgCuoiIg2ioC4i0iAK6iIiDaKgLiLSIArqIiINoqAuItIgCuoiIg2ioC4i0iAK6iIiDaKgLiLSIArqIiINoqAuItIgCuoiIg2ioC4i0iAK6iIiDdJVUDezBWZ2pZmtMrOVZvbSXlVMREQmr6t/PA38LXCNu7/VzGYBc3tQJxER6VDHQd3MjgBeAZwH4O6DwGBvqiUiIp3oZvrlWcDjwJfM7E4z+6KZzWtdyMzON7N+M+sfHtjeRXEiIjKeboJ6H/Ai4H+5+2nALuCC1oXc/SJ3X+zui2fOnd9FcSIiMp5ugvo6YJ2735p/X0kEeREROUA6DuruvgF42Myeky+dBazoSa1ERKQj3T798l+By/LJlweBd3VfJRER6VRXQd3dlwKLe1MVERHplj5RKiLSIArqIiINoqAuItIgCuoiIg2ioC4i0iAK6iIiDaKgLiLSIArqIiINoqAuItIgCuoiIg2ioC4i0iAK6iIiDaKgLiLSIArqIiINoqAuItIgCuoiIg2ioC4i0iAK6iIiDdJ1UDezmWZ2p5l9qxcVEhGRzvVipP5+YGUP1iMiIl3qKqib2YnArwFf7E11RESkG92O1D8LfBgY6b4qIiLSrY6Dupm9Htjo7neMs9z5ZtZvZv3DA9s7LU5ERCagm5H6y4A3mtka4CvAq83s/7Qu5O4Xuftid188c+78LooTEZHxdBzU3f0j7n6iuy8C3gb8m7u/o2c1ExGRSdNz6iIiDdLXi5W4+w+AH/RiXSIi0jmN1EVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGqTjoG5mTzezG8xspZndY2bv72XFRERk8rr5x9NDwAfdfYmZHQ7cYWbXufuKHtVNREQmqeORurs/6u5L8vcdwErghF5VTEREJq8nc+pmtgg4Dbi1zXvnm1m/mfUPD2zvRXEiIjKKroO6mR0GfB34gLs/0fq+u1/k7ovdffHMufO7LU5ERMbQVVA3s0OIgH6Zu1/VmyqJiEinunn6xYCLgZXu/te9q5KIiHSqm5H6y4B3Aq82s6X586s9qpeIiHSg40ca3f1HgPWwLiIi0iV9olREpEEU1EVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEEU1EVEGkRBXUSkQRTURUQaREFdRKRBFNRFRBpEQV1EpEG6CupmdraZ3Wtm95vZBb2qlIiIdKbjoG5mM4F/AH4FeB5wjpk9r1cVExGRyetmpP6LwP3u/qC7DwJfAd7Um2qJiEgnzN07y2j2VuBsd/+d/PudwOnu/gcty50PnJ9/PgfYDGwCjq6ltHltvLSTPNNdnvIcHHVsWp6DoY5NyzPV5c1z959hIty9ox/gN4Av1v5+J/C5CeTrb03bvTZe2kme6S5PeQ6OOjYtz8FQx6blmY7yJvrTzfTLOuDptb9PBB7pYn0iItKlboL67cApZnaSmc0C3gZ8szfVEhGRTvR1mtHdh8zsD4DvATOBS9z9nglkvWiUdKz3eplnustTnoOjjk3LczDUsWl5prq8Cen4RqmIiDz56BOlIiINoqAuItIgCuoiIg2ioC4i0iAdP/0iYmZGfF3ECcQTUA8DtwJziU8PnwSsBp6Wfw8DDwFOfKbhTmDI3UfM7DTAgOOBZwIrgVcDd7n7lWb2BuDlmf96d1+Zj9KeCswBXgDcAeyrlbcv6/QsYJD4bMVjwC3A84G9wIPArwO3uPuaWjmWZa3Put4KHAK8Hvgx8B/blFffvlIOwM9mPU7Pevz8KNv3n4DdwHLgNuC2bJtZwJnAPVnul4FXAIcDLyEGZ/Oznrdnus/dl+R+elW2dR/w0lo5d+fyt7m7ZzkXAp+urf9E4LD8fU1L249Wp5Ln5JZylrj7vsz7rKzzvOwvpwN3ZRkvIvrOTcA12a6lHR/McpcSj1EvA94KDBF97XZgSeY5JNczF1iQdXpxSzlnZHstIfpHafN5WaeZxKfg633q0FzfIy3lte7rkvcFmX9J7oOX5zLfB+4dYx//bK3cFe7+XSZgWp5+MbPFxAeV6gfXaAd1PRCczk8f1GuBfwdWAGTe5wM/Q3XAlA52j7uvbTlg7iY+xVU/YMY6UMfaiT8VGLJ+bwJeltt5O3BzHjTPzWXfD9xYK6d06IeBFwLPzra5kvadpWznZuLAqXeWEoweZf9OOgv4pdz2twH/Bvwy0dH7iIOr5C37ZxlwsrvfnXV/Qf78EFgM/BGwLbdhVtZzI3Gwrsplh3O9u4E9ue71wGuJg24E+DrxCeUHiT7iueyM/H1vLjuLOFA8yzk8t/NkYIA4eEfy/R257GHER637sl4jVIOZEWBnrmck23M+MDvrvS/L9Fx/X9ZjRtavlEdt+7YRJ6ZZufyeXNesXHZ2m+0bznWRbeW19FqiLx2SP3vyvdmZf1fuu9JP9tTaai/Rn0/PNj++tu1DWZ+RXM+lwBuBYzPf7CxnL9H/i3LCOrzWHvU61fN4ljNUW8edxEn4aOKY9fwZzDpvBRYS+6y8P5zrLG1ySO6buVSzDcO5D+blMmW/bAeOalPOTuCI2t/1QPgJ4MNZ3pxa2+6m2k/rib61oFbePmJ/zK3lLe27O1/ry5+yj4eJ4/zX2H8fD2a7HQFcQey7fnf/COOZzMdPJ/sDvJIIIiUIbgQ2EAfPvtoOe29u/FKqjjCcDbSbOFB25YaO5HvlgLw4f9/T0rilM22l6ryDub6yjmuIg39frbxSp6F8b5hqBLallrde/+35+lDWdWcuX5YdBH6SdXkkl/Pauvfkshszf8lbtmVHrnOwZTtL3t0t9RlpSct2jmRdB2vrL3Uo7b4j989eqgNhTa5/by6zmyrYlu27iejopc435PsDud17gcezjR/PtryiVsYI8PHaduzKepT9dXn+vbZl+2+tbcsmIuBsynYpbbM2X/9+1vXHtXK3ZN3KPlgNfI04wQwB32lpzz25/np5W3PZx3O5q3Nf1svZRJyANrbZPicO6ruy3XYDf1XLuzHzlnK35Hacne+/MbfhH7Mej+S6d9Xapl7Opbl9Tpxkh3M/DdTaZD1wb/79itzuO6n6yd42darneXG+VtqxtH39mFqV9SrH1crM+80s7/JcblObtijteFnWay3Rd0o5O6n69YpRynl37rvFuT3LqY6Nn2RdH8h2Kdu5Iv9u7VP18up5R4AvsH/ceAdxHK6r7Z/Wffz5bM//QMTQPuDuqf6agIn4LPHVvHOIAL8D+CrV2fWrmZaH67cSDTRIbPTMfP0IYkc/QWyoEyeAecC7ankfz9+HMv8QcSZ9AzF6X0ecCa8hzpK/nGUMZ/45VF84ti3Xfy9VgNtHjHDLyKGchcvOGiZGev9KjFquyPe3Aqfk+mbma6Wc7cRI4T5iZPLdWt6RLOewzPtEbTuNuDLoy/xGjHafIDrTaqIDlu3cnfW7ONtgU66nnBAeIE4mg7X6bcs6HJnlrM/3ZmSen6PqzB8nRm8P5jaeXGuXLVmXebm+hcRo5ntZjzIK20UV1Ne4+1FUXz3xm9kOTgwM9uTrX6QaST1EHOCPEQfu49mWJxD94J9zuYtreZ4gLnnX5d8nElddM7OuV+T6Sh/YSRy09fK2ZP2/lK+/guizFxP7i3x/W5bTbvs+n202H8DdP5jrh9hfG2rlrsv63J5//4DoA0upgsTO/Hks/95WK+eduX0biEACcWyur61/GXH8kOXUT/BlxNlap3qelbktpR1L2w/ksjNyuwazDnuB/5zLnJnbU6Ze9gCfammLDfn3udluZP1KObuo9unsUcr5BHCEu/dnHY04DqC6ottO9MnHch2/S1x1tPapXbU61fM6MerfS/Q1A/4n0Ze3EVesRss+dvf/ku25Iduwj4neA53ikfrdmd5H7KRh4hsbS/B4dzbYhtz4h4mdvp040O6kOtuVALcm855LnN3Ke3cSVwQjtXLvr613mDi7lrwbqEaum4iR5kiu45osfw9xMiqj8L2Zd5DYyeUEsybzPcz+o79ziY7UX1vHqlHKeVWbvKWcv8z3NhMHy5L8eyExnbQ1t69s5/Jsj3uIgO65zE5iDtprZW+kGqUM5zaVKZj7s85/mnnekXUdyGXL1cMg8FtU0wqbqYLA1vx7KN+7kgj8m7OOHyHm5bdQjXSGqU5Oe7MNtuXvy4jBwMuzHesngq3EyfuJXLascykRPN+fy96Zf2/IZfYRfWMvcTIso8NdxKBhI3FyL1MWj7aUt5lqtLWROPA31bZvA1UwLyPV+vaVK7F9udwu4GPZXpdSTSmVcldn/jKQKMfGHZl3U+6jj2T++lXuzlx2AzEo+CjVtMQjtfU/WGvXnVmX0va/Xtu/j7bJU79C3ZD5P1lb/j6qEf++3JYyUBrIZXYC/0Ls91V5PJdjttTJib66gzh+B7OcEaLP/jzVVXtrOY9nupe4otpFFU+2UF0Rb82fJ6hiwJ4s7xHi2CzlDWQ59bxl/9avqvvz9a8Sg5uH2+zjrxB964FcTz/w9onE3SmdUzezS7KC84jgYsDfAOcRc+zLiNHeWmAR1XzfNuLsVOblthFn2zlExzmOGFHdAXyIGBlDNOghxGUbxFzkCVTzjFuJ0eRfEjvhYuB38r3Hcr3bcn1vJhq8BJolWccvE2fejxIj4zJ/ejjRWZ+b6THE6PRwqvn3Mqrva1NOqf+9xI3CNZnnY+7+F2a2gehUJxAdeh7REcuo6Yl8bTZxGX90ttf6/Pu3c9nSRg8Rc+G7iVHDYL5/X67ncKLjn5zteQ7VKL2cXPuIUfxe4FvAW4gR9f3EKOYLuT33EfdKNhIj2OOz3L9096W57ZjZ04jOOxP4DLGPl+c2vTb/voq4AhwBTiMC6seIeeOriaC4kBjtlZPH7lx2H3HgfRZ4nrv/i5kdRUxb3ETcOJuX7b+FOBi35M+Xs70PbVPefOL+yxriH8aUE9sXy/aZ2QLgD4n7Lce32b43ECfcjVnvZcAP3f36vGf0bqJPnQ58kLj/83O5P+7Ocst04wZgpbt/2sz6iH46L8ueRVw1Pkb0i3VE4FhC3CN5IfAXROCeS9zf2U70kf9ba/uXE1fh9TqVPEfmLj2JajpsLRE8b8r3ZmR5JxH7vEzX7CWOjVOyHb4NPOTuP8l2PBV4DzH3/xrg+ty2zdkGtxPH3SXuvif/mc9ncn13EVMtG4njZRYRI/Zm/e4jBjv3E/303EznZBudmXU8lAjox2X7rQAuyTpBHDvnZVqOybnEFdUbMv+txNXt7mzDI9h/H/8h1c3k+cD/cPdtTMBUB/VDiPny5xEN2UdMMZyQi3yM6vIUovJfJALBA8QO+AbVQb2ImHP8OtHp5+eN0NLpX0w09POJYDkf+AXgGVQdudwALAfMM2l/oJbAMNZO/PWWwPAj4qbM04gOt50IQl+nCggXAGcRl/WlnMXAzfn+qcQNxvXEtNTX3H1Ptud84kAogeG6bL+Hsu4nEgfLmkxXA19y9xW1NjqWuGF6PRHELdumjOJW5zKbiIPhtGyD5xJPWjwjt+l04uD9HvD3mf8Yd19Lw5jZMQDuvtHMjplI2oMyj3L3zZNJs46buy1bJm6i/aGewv59qeeVmsrplyfrDxF8Ok4nWdZRwFHl98mkT+Yf4oT5SWIOsNzM9JafkdpPeTrh3sy3INfz3dZ0lNeOIEZuy4mTzDeIE+03iBHWauKS9cFMVxM3PNdnnnuJ6ZByw3db/mxtkz6Q2/UA8fTJo7me12f6ikxfmenvEVc1z8r0cmKUv5UYSKzKuo6Wbs76bs71lamtMqUz3CYt005lCqZMW+0jBkbLiavJevqPxODhO8SIeRPV1MRYaf1meuu+bXdjvrw3Vn9o91NftkyB/Q2j95Vrifnp0g/qaekPrf1iTbbFBmJQtJIYoD1OXGG16w+t6YNU/WMXcdVU7w/19BGivzySf28iBnO/T0y7XJ91aO0XD9TSFcRU1LETOTan65HGI4j5vZOIS5ndxDO6G4mgdxsxml9J3O2dma+dTlymnE5cop1BNOohxGX0qVR39mH/R8FKOoNqnmw4130cMR3xd8DbiQY7hzgY639fRVwhXEuMvG8hOsVCYgcfQVzGlfTYLHN7LjOL6hG2GcQOPYo4eOtpueFa6l3mircSU0RvIzpkPT0yf39dpsuAD2RbLCAegVzQpk1Ke8D+j4M51U3c0pYlD7W03s7lQNxHHCBHZTu8hLicfylx8FxPTG3cS1zeryX2978Sl6mXtqQjxHTHb9fSh4i+cQdxZbMn23Y1cQU3RPV4X0l3E/umTK3tyNfL44/lCam+Wjq7ZRsno6xjMNO7iKvGx/jpvlJP5xBXoK/KOs4mDu4TqKZUFrakJxKP6X6N6NtHUf2XnCGq/lb/7zkj2W6zqJ4EM6pHP3e2SRcQ+/I0IricTNyjeDHVVd1jLenM3I45uQ6yDs/Iurc7To8nTjhHE9MUryX6y5mZ51r27w9fJm543kRMoWwipi7WE1fK5fHCeS3pAuIkfVz+fVjWuzw+WfZda78YynWU6ctO+kc7Za59hP37xQriGFlBdQ/sle7+5nHXOMWjuRflz/XEkwF3EQfnttyIdVSP0Q1R3Zgrc5L1dGs2wCNUNziHqG5g7KG6oVNPy44qI4XW0cNEf+o3aErdn2hJy+OR12adHs7lb6G6+722TTpCjDCcqtOXx7gey+1uTUtnKCeR0n6b8mcD1aODg1SPc/2I6qQxmPtiMOtd8q/P5Z/I+q/Lem3J5R/O8n5M9Wz2PwGbc78PlpQ4MMvIsozAWtu0NR3rp7TPg5nemnXfSXVTrp4OA3+ey64jAvpDmQ4So/d6+qFaO20kDqahXP4zo6QrgL25zSNE0FuS6QARPJeMkY4QgWOE6Ct7aukAMWJrTVvz7CbmucuJqjxmV0/LjfBhqhH4HqoHF1rb4k5gpGxXpsMlHaVeA1RP5tTTci/m3lF+Sp9x4gmz+r4e62dfy7LliZPx+kNJR7Jeu8dog5IOUT2Rcw3RPwZqabv+MUj0pW2ZZ5A4GS7Jcks/2a9fZFuUdGk9He9nqh9pvD037BeJ0dSziMuJOcRZ7tJM/5bqMTqn/SXg3lznJZlnB/sHpRnEZXhrOkx0khEi2JbH+Er6V2OkTtxBHyRuRg0SgW8pMTK6vyVdT4xSfjXLX09189fz991tUtz9TbnMG6k+sAPVB0taU6ieuijb/wxiJHJkLjeDOGlQUnc/s5a3nBRLoN1FBOyFuXxf/jxKdbPoCOJGYpmLH8z31gJzzOw7wICZfT/Xf0iWdQ9xQroj0wHi5uJQm3RDLl9PV+V7R2VaHpk8gepDPgtb0gW5XW/JdHYu+2WqRwxn1FN3/wzVyWs+MYgoj3A+e5T0JGCWmX071/t0oq8/Pcs8JP8eLfXczhFixDiSecvxOb9NOpR1HKK6l/Lu3B9fIQL1lS3pZuAfiAC3g+ppjGNyvU9vl5rZdZleA7iZfT7rXG6St6YQ/cQzHQb+jOrRvb426VD2mfJ0yABxxTxIjMZb+8M9ue2z2b9fvD/Lb9cfFrJ/f3gLVVCfnWXOIE4Q7dLNxIMV+7I9Z+fvJW3XP3ZnW88l+lIfcZXw7Py99JP9+oWZfRCYkZ/aLv1gQvG6b/xFurKSuET6JnFz8J5aego/3bjlAC3TFztq6QJGP0A/SJsDNNMtxI64n9gRL2X8HVFSiI41i2j4vkxn0v4AXUlMe5SR03OJjvw8qimPdgcoZraC6MCfJjrXPxDTKVcRl6A/akkXEk8BXEY8d/xl4uT4p7ndg0RHaj1Ab8i/F+b2HEb1CbcFVE/oHE31jPxIbkc5UD9EHCSHUj1v/NFc5ldy/Wflsovy73LQDWT73JJ5/7pNupYY/RxTSxcR02+vJqZtXk30q9uIj7bvIaYwXlpLv5f1uZCYxnpvpl+l+oj5OiIorgNONLOTicv/C4irj1dm/UeIKYJ26SbiQD0z225l5jGiPwwRfe8ZY6QrcjvLibTsCyf6SGu6r7bsMVnW4lzPu4B/dvfzzOwrJSXmnz+V2w1xMipThpbrbU1Hcl8aMdVn2Y6DVAF7Tkta9rtlWu8fixjdWZn+cZb7duLDPZ/INqr3h43E49H1/vCvxH68iRh4tPaHG4gPbP1zllH6xXuI42cT8Unv/98f2qSHEk969RNz6WVqZgaj94+FxIDpDKo4QOZbnm05j/37w0lEP3oesNTMjiMGk+Oa6qdf3kp0oPcQo+TX1dIziMb5MNHRSnohEdRvJnZESf+dOEDfTbUjLibmIa+izQFaS/+YuDlXbqzUd8S9xAixXfoCqgN2gNihP+and0BJv050ms3E3HF53LB+M6t1LtGo5jjLo5UziJHNWe7+m3lgvq2eArS89oJsv3nZ/K0HbEnLnLoTJyertUV5GqaMXsrVRTn576ltTx9xYH2KOGGsJx6x+98t+3lHrU1XESe6ku7KdvtWmzyty46XZyfVPZnWdGcX5VxLBJcb8/XSB17WJl1L9JlLJlHOVLTFWHkGcn99m5i3vi7Tsdpv1xh5RivHiSB/I/G01jwiyD1KDHjmtEkXEIOxPcS8+BHESardsqPlmT9FedrlPYEYrCzLdWwfJZ1L9fmbk4iBUsmzdYzyNlHdD1jl7t9hIg7g0xPvGi0d670e5DmfuMF6PjF6mDOZdJrqeDDkuYw4QO+merKlzOfupXrKZIS4udwuLU/NTCTP6gnkWT1KOpk80123ieTtpP2mq5zR8uzItEwRPkEE+j1Uc/n1tMyND1E9RVN+P9B5DkR5Q7nPthFXKzcCF04oth7AoP7QaOlY7x3oPAdDHacpzyAx/76M6LhLqD7NOkJ8gGWEmP8caJOWPPuewnkOhjp2mqef6gp1HxHUS9Ba1SZ1YhTrVPP9T5Y8B6K8Z2Z6DDFwmsMEv/tlSufUzezu/PWUTMvjYpbve7t0rPcOdJ6DoY7TmOdE4hLUqL418Abikv0c4sCfS/WNhvV0NjFt8YKncJ6DoY6d5rmZ6oNrR1JN3ZUnTVpTd/fV2bfuJ6brHsj0QOeZ9vI8PlS51+NDSiPuvtvM6vPxo5rqp1+OJZ4p3Ul8hHgbcalfHjv64Cjp1lymNZ2uPNNd3sGYZyiXuTN//2Ni9L6I6Ff3EHP284jO2prOqC37VM1zMNSx0zxHZnptptcRo817iRFoa7o7bwbuJp4e81p6oPNMe3n56fFVmY6UlAmY6qdfvkXcFPgmcelxNXGWKjcUbyPmjVrTB2n/lMB05Znu8g7GPN8iOub7iK8zWEJ8UvF3iQ8f3ZLpMBH4T2tJX0M8t1tf9qmW52CoYyd5XuzuV5vZF9z9B7X0CqpPzrZ+CO84YnDwcmK6pqRvIB4/PpB5DkR5hxDfPdOajmtaPlEqIiLTY6qnX0REZBopqIuINIiCuohIgyioywFnZjdNYJkPmNncKa7HAjP7vdrfTzOzK3tcxncs/mFG6+t/ZmYf6mVZ8tSkoC4HnLufMYHFPkD1H6ImxOK/3kzGAuK70QFw90fc/a2TXMeY3P1XfYL/wUakEwrqcsCZ2c5Mf8nMfmBmV5rZKjO7zML7iO/ouKF8IZmZvc7MbjazJWb2NTM7LF9fY2YfM7MfAb9hZu81s9vN7C4z+3oZ7ZvZsWZ2db5+l5mdQXw/0LPNbKmZfdrMFpnZ8lz+UDP7kpktM7M7zexV+fp5ZnaVmV1jZveZ2afG2dY1ZnZ0/n6hmd1r8e2Ez5mKtpWnnql+Tl1ksk4jvhjsEfKLstz978zsj4BXufumDIofBV7j7rvM7E+If/P333Mdezy/Ytji3719IX//c+KL4D5H/IOUf3f3t+SI/jDimxlPdfcX5vKLavX6fQB3f76ZPRe41sx+Nt97YdZ7L/HBkc+5+8NjbaSZ/QLxTZGnEcfhEuJriUW6oqAuTza3ufs6ADNbSnyK8Ucty7yE+ErSH5sZxLdc3lx7/4ra76dmMF9ABO7v5euvJj7tjLsPA9vNbOEY9TqTOBng7qvMbC3xtboA17v79qzzCuJ7O8YM6sSHUK5294HM981xlheZEAV1ebLZW/t9mPZ91IDr3P2cUdaxq/b7pcCb3f0uMzuP+KfbnbAx3ptIndvRJ/+k5zSnLgeLHcDh+fstwMss/qEFZja3NhXS6nDgUTM7BPit2uvXE19pgJnNtPg/uvUyWt1Y8mdZzyC+q6NTNwJvMbM5ZnY48bFxka4pqMvB4iLgu2Z2g7s/TvyD6sstvgn0FuIfM7Tz34j/Y3od8bWmxfuBV5nZMmIu++fcfTMxpbPczD7dsp5/BGbm8lcA57n7Xjrk7ktyPUuJ70L6YafrEqnTd7+IiDSIRuoiIg2iG6UiU8DMbqX6pzDFO919WbvlRXpF0y8iIg2i6RcRkQZRUBcRaRAFdRGRBlFQFxFpkP8HqoH3XMtSMh8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df0 = emg_0_new.groupby('interaction_id')['sub_window_num'].nunique()\n",
    "print(f'max: {df0.max()}')\n",
    "print(f'min: {df0.min()}')\n",
    "print(f'mean: {round(df0.mean(),1)}')\n",
    "print(f'std: {round(df0.std(),1)}')\n",
    "df0.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "633521d3-0cf8-4aaa-8575-b41e38e000ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 15\n",
      "min: 9\n",
      "mean: 15.0\n",
      "std: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='interaction_id'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = emg_1_new.groupby('interaction_id')['sub_window_num'].nunique()\n",
    "print(f'max: {df1.max()}')\n",
    "print(f'min: {df1.min()}')\n",
    "print(f'mean: {round(df1.mean(),1)}')\n",
    "print(f'std: {round(df1.std(),1)}')\n",
    "df1.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3e678-dd0d-4d1f-81e8-5b3a39205c2c",
   "metadata": {},
   "source": [
    "### Create X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a47061-827b-45cb-be34-9490b0bf7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(df):\n",
    "    dim1 = df.interaction_id.nunique()\n",
    "    #num_timestamps_per_interaction = df.groupby('interaction_id')['sub_window_num'].nunique()\n",
    "    dim2 = df.sub_window_num.nunique()\n",
    "        \n",
    "    X = np.zeros((dim1, dim2, 8)) \n",
    "\n",
    "    itr_id_lst = df.interaction_id.unique().tolist()\n",
    "\n",
    "    for i in range(len(itr_id_lst)):\n",
    "        itr_id = itr_id_lst[i]\n",
    "        itr_id_df = df[df.interaction_id==itr_id]       \n",
    "        \n",
    "        for j in range(itr_id_df.shape[0]):\n",
    "            starting_index = 10\n",
    "            vals_arr = itr_id_df.iloc[j,starting_index:].values\n",
    "            X[i,j] = vals_arr\n",
    "    \n",
    "    X_tensor = torch.Tensor(X)    \n",
    "    return X_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf7422b5-05bd-4c47-ad57-92dbc3a1af7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_train(df, predicting_feature = 'property_id'):\n",
    "    # Create a dataset with only the required columns\n",
    "    df2 = df[['participant_id', 'clothes_id', 'property_id', 'rating_level_num']]\n",
    "\n",
    "    # Remove duplicates\n",
    "    df2.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # Reset the indexes\n",
    "    df2.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    ## Create y train\n",
    "    # CreatE an instance of a one-hot-encoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Perform one-hot encoding on the specified column \n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(df2[[predicting_feature]]).toarray())\n",
    "    \n",
    "    # Convert to a numpy array\n",
    "    y_train = encoder_df.to_numpy()\n",
    "    \n",
    "    # Convert to a tensor\n",
    "    y_train = torch.Tensor(y_train)\n",
    "  \n",
    "    return y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c95e4b49-e025-4fd4-9adc-64e513ce5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_test(df, predicting_feature = 'property_id'):\n",
    "    # Create a dataset with only the required columns\n",
    "    df2 = df[['participant_id', 'clothes_id', 'property_id', 'rating_level_num']]\n",
    "\n",
    "    # Remove duplicates\n",
    "    df2.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # Reset the indexes\n",
    "    df2.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    y_test = df2[predicting_feature].values\n",
    "    y_test = y_test - 12\n",
    "    y_test = torch.Tensor(y_test)\n",
    "    \n",
    "    #y_test = y_test.type(torch.LongTensor)\n",
    "    \n",
    "    return y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3566b-4103-4d96-9277-de91705cba4d",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a06397b-37d3-4902-a428-16bea2a2d876",
   "metadata": {},
   "source": [
    "input1 = torch.rand(180,15,8)\n",
    "input2 = torch.rand(180,15,5*2)\n",
    "conv1 = nn.Conv1d(in_channels=15, out_channels=15, kernel_size=1, stride=1, padding=0, groups=15) # Change kernel size to 3\n",
    "pool = nn.MaxPool1d(1, 1) # Change kernel size to 1 and stride to 1\n",
    "rnn = nn.LSTM(8, 5, 1)\n",
    "h0 = torch.randn(1, 10, 5)\n",
    "c0 = torch.randn(1, 10, 5)\n",
    "fc1 = nn.Linear(15 * 5 * 2, 50)\n",
    "fc2 = nn.Linear(50, 5)\n",
    "\n",
    "print(input1.shape)\n",
    "x=conv1(input1)\n",
    "print(x.shape)\n",
    "x=pool(x)\n",
    "print(x.shape)\n",
    "x, (hn,cn) = rnn(x)\n",
    "print(x.shape)\n",
    "print('=================')\n",
    "y = torch.flatten(input2, 1)\n",
    "print(y.shape)\n",
    "y = fc1(y)\n",
    "print(y.shape)\n",
    "y = fc2(y)\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "189cb1c0-ad2d-4bc0-9922-8c1fa5ee995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=15, out_channels=15, kernel_size=1, stride=1, padding=0, groups=15) # Change kernel size to 3\n",
    "        self.pool = nn.MaxPool1d(1, 1) # Change kernel size to 1 and stride to 1\n",
    "        self.rnn = nn.LSTM(8, 8, 1)\n",
    "        self.h0 = torch.randn(1, 15, 8)\n",
    "        self.c0 = torch.randn(1, 15, 8)\n",
    "        self.fc1 = nn.Linear(15 * 8 * 2, 70)\n",
    "        self.fc2 = nn.Linear(70, 5)\n",
    "        \n",
    "           \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.pool(F.relu(self.conv1(x1))) # Use tanh instead?\n",
    "        x2 = self.pool(F.relu(self.conv1(x2))) # Use tanh instead?\n",
    "        \n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        x1, (hn, cn) = self.rnn(x1, (self.h0, self.c0))\n",
    "        x2, (hm, cm) = self.rnn(x2, (self.h0, self.c0))\n",
    "        \n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bdcb131-9094-4488-b583-c1791c3f8771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LSTM(\n",
      "  (conv1): Conv1d(15, 15, kernel_size=(1,), stride=(1,), groups=15)\n",
      "  (pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (rnn): LSTM(8, 8)\n",
      "  (fc1): Linear(in_features=240, out_features=70, bias=True)\n",
      "  (fc2): Linear(in_features=70, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = CNN_LSTM()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2adee9e-1d09-4453-bb2c-82781a5112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(num_epochs, loss_vals):\n",
    "    plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), loss_vals)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55afe291-28f8-46ec-ba72-f1208ead24bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss(4, [20,28,19,17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c4feec5f-2fcb-4c58-ae83-5d438c189024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_LOSO(data_0, data_1, predicting_feature='property_id', batch_size=50, learning_rate=0.01, num_epochs=100, random_state=num): #, num_inner_folds=5\n",
    "\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(num)\n",
    "    \n",
    "    for cloth_id in range(1,7): \n",
    "        # Split the data into training and testing\n",
    "        training_data_0 = data_0[data_0.clothes_id != cloth_id] \n",
    "        training_data_1 = data_1[data_1.clothes_id != cloth_id] \n",
    "        testing_data_0 = data_0[data_0.clothes_id == cloth_id] \n",
    "        testing_data_1 = data_1[data_1.clothes_id == cloth_id] \n",
    "\n",
    "        # Data preparation\n",
    "        X_train_0 = create_X(training_data_0)\n",
    "        X_train_1 = create_X(training_data_1)        \n",
    "        y_train = create_y_train(training_data_0, predicting_feature = 'property_id')\n",
    "        X_test_0 = create_X(testing_data_0) \n",
    "        X_test_1 = create_X(testing_data_1)\n",
    "        y_test = create_y_test(testing_data_0, predicting_feature = 'property_id')\n",
    "        \n",
    " \n",
    "        # Create the datasets and dataloaders\n",
    "        train_dataset = TensorDataset(X_train_0, X_train_1, y_train) \n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        \n",
    "        test_dataset = TensorDataset(X_test_0, X_test_1, y_test) \n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=30, shuffle=True, num_workers=2)\n",
    "        \n",
    "        # Model\n",
    "        model = CNN_LSTM()\n",
    "\n",
    "        # Loss and Optimiser\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        print('Starting training.')\n",
    "        training_loss = []\n",
    "        \n",
    "        for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(train_dataloader, 0):\n",
    "                # get the inputs; data is a list of [input1, input2, label]\n",
    "                input1, input2, labels = data\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(input1, input2)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update statistics\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "            training_loss.append(running_loss)\n",
    "            \n",
    "       # print(num_epochs, training_loss)\n",
    "        plot_loss(num_epochs, training_loss)\n",
    "        \n",
    "        print('Training done.')\n",
    "\n",
    "        # save trained model - this is the last model saved \n",
    "        torch.save(model.state_dict(), 'saved_model.pt')\n",
    "        print('Model saved.')\n",
    "        \n",
    "        print('Starting testing')\n",
    "        \n",
    "        dataiter = iter(test_dataloader)\n",
    " \n",
    "        # load the trained model\n",
    "        class_model = CNN_LSTM()\n",
    "        class_model.load_state_dict(torch.load('saved_model.pt'))\n",
    "\n",
    "        # inference\n",
    "        test_input1, test_input2, test_labels = dataiter.next()\n",
    "        test_labels = test_labels.type(torch.LongTensor)\n",
    "\n",
    "        test_outputs = class_model(test_input1, test_input2)\n",
    "        _, predicted = torch.max(test_outputs, 1) # Does the same thing as argmax\n",
    "        \n",
    "        predicted_np = predicted.numpy()\n",
    "        labels_np = test_labels.numpy()        \n",
    "\n",
    "        conf_mat = confusion_matrix(labels_np, predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "        macro_f1_score = f1_score(labels_np, predicted_np, average='macro') \n",
    "        micro_f1_score = f1_score(labels_np, predicted_np, average='micro')  \n",
    "        acc = accuracy_score(labels_np, predicted_np)\n",
    "\n",
    "        print(f'Leaving sock {cloth_id} out:') \n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        print(f\"(3) macro F1 score = {round(macro_f1_score,2)}\")    \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "\n",
    "\n",
    "        print('--------------------------------------------------')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "        \n",
    "        \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa2436-eef9-43b3-ac31-c170d90fed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training.\n",
      "Training done.\n",
      "Model saved.\n",
      "Starting testing\n",
      "Leaving sock 1 out:\n",
      "(1) Confusion matrix:\n",
      " [[0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]]\n",
      "(2) micro F1 score = 0.2\n",
      "(3) macro F1 score = 0.07\n",
      "(4) Percentage Classification accuracy = 20.0%\n",
      "--------------------------------------------------\n",
      "Starting training.\n",
      "Training done.\n",
      "Model saved.\n",
      "Starting testing\n",
      "Leaving sock 2 out:\n",
      "(1) Confusion matrix:\n",
      " [[0 0 0 6 0]\n",
      " [0 0 0 6 0]\n",
      " [0 0 1 5 0]\n",
      " [0 0 0 6 0]\n",
      " [0 0 0 6 0]]\n",
      "(2) micro F1 score = 0.23\n",
      "(3) macro F1 score = 0.13\n",
      "(4) Percentage Classification accuracy = 23.33%\n",
      "--------------------------------------------------\n",
      "Starting training.\n"
     ]
    }
   ],
   "source": [
    "NN_LOSO(emg_0_new, emg_1_new, predicting_feature='property_id', batch_size=50, learning_rate=0.01, num_epochs=10, random_state=num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9374c3a6-8750-47f2-b8e4-06c6b5e9871a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dxtfcygvuhbijnokp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_2442/853669779.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdxtfcygvuhbijnokp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dxtfcygvuhbijnokp' is not defined"
     ]
    }
   ],
   "source": [
    "dxtfcygvuhbijnokp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b5cc79-efca-46ac-98a3-1b4388c2a583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec0cfa-51fd-493d-9b4a-42be74694c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296ef81c-83a7-4c6f-9985-b9e382b3ae01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fcfc1e-83c8-4230-b8fb-5be86e608fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8783b-1763-44a6-8034-60cbb6334db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7973a98-7d95-4e32-b018-d567fc3c4f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad16b1c-153d-45fc-9fbb-f7b9d691601e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52845044-dea0-4adc-b742-508c1352f93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aab379-b149-433c-9557-669a3bee66be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8d505-44eb-4fa2-b8af-cb834ddb0bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7194c9-02f2-4b35-998b-788f014634cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd70867-e06c-4d91-9e2b-663aeea2916d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "#def CV(data, num_inner_folds=5, learning_rate, num_epochs=1, random_state=num)\n",
    "num_inner_folds=2\n",
    "# Set fixed random number seed\n",
    "torch.manual_seed(num)\n",
    "#for cloth_id in range(1,7): \n",
    "    ## For fold results\n",
    "   # results = {}\n",
    "\n",
    "data = emg_0_new.copy()\n",
    "# Split the data into training and testing\n",
    "training_data = data[data.clothes_id != 1] #cloth_id\n",
    "testing_data = data[data.clothes_id == 1] #cloth_id\n",
    "\n",
    "# Data preparation\n",
    "X_train_0 = create_X(emg_0_new)  \n",
    "X_test_0 = create_X(emg_0_new) \n",
    "y_train = create_y(emg_0_new, predicting_feature = 'property_id')\n",
    "\n",
    "X_train_1 = create_X(emg_1_new) \n",
    "X_test_1 = create_X(emg_1_new)\n",
    "y_test = create_y(emg_0_new, predicting_feature = 'property_id')\n",
    "\n",
    "# Create the datasets and dataloaders\n",
    "train_dataset = TensorDataset(X_train_0, X_train_1, y_train) \n",
    "test_dataset = TensorDataset(X_test_0, X_test_1, y_test) \n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset) #, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "# Configure the cross-validation procedure\n",
    "cv_inner = KFold(n_splits=num_inner_folds, shuffle=True, random_state=num)\n",
    "\n",
    "for fold, (train_ids, val_ids) in enumerate(cv_inner.split(train_dataset)):\n",
    "    print(f'FOLD {fold+1}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids) # The ids are the same for both\n",
    "    val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=train_subsampler)\n",
    "    val_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=val_subsampler)\n",
    "    \n",
    "    # Model\n",
    "    model = CNN_LSTM()\n",
    "\n",
    "    # Loss and Optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "            input1, input2, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(input1, input2)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "    # Process is complete.\n",
    "    print('Training process has finished. Saving trained model.')\n",
    "\n",
    "        training_loss.append(running_loss)\n",
    "        if training_loss < lowest_loss:\n",
    "            lowest_loss = training_loss\n",
    "            \n",
    "                \n",
    "    plot_loss(np.linspace(1, num_epochs, num_epochs).astype(int), training_loss)\n",
    "        \n",
    "        \n",
    "    print('Training done.')\n",
    "\n",
    "    # save trained model    \n",
    "    torch.save(model.state_dict(), 'saved_model.pt')\n",
    "    print('Model saved.')\n",
    " \n",
    "    # Print statistics\n",
    "    current_loss += loss.item()\n",
    "    if i % 500 == 499:\n",
    "        print('Loss after mini-batch %5d: %.3f' %\n",
    "              (i + 1, current_loss / 500))\n",
    "        current_loss = 0.0\n",
    "\n",
    "# Process is complete.\n",
    "print('Training process has finished. Saving trained model.')\n",
    "\n",
    "# Print about testing\n",
    "print('Starting testing')\n",
    "\n",
    "# Saving the model\n",
    "save_path = f'./model-fold-{fold}.pth'\n",
    "torch.save(network.state_dict(), save_path)\n",
    "\n",
    "# Evaluationfor this fold\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "\n",
    "  # Iterate over the test data and generate predictions\n",
    "  for i, data in enumerate(testloader, 0):\n",
    "\n",
    "    # Get inputs\n",
    "    inputs, targets = data\n",
    "\n",
    "    # Generate outputs\n",
    "    outputs = network(inputs)\n",
    "\n",
    "    # Set total and correct\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += targets.size(0)\n",
    "    correct += (predicted == targets).sum().item()\n",
    "\n",
    "  # Print accuracy\n",
    "  print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
    "  print('--------------------------------')\n",
    "  results[fold] = 100.0 * (correct / total)\n",
    "\n",
    "# Print fold results\n",
    "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
    "print('--------------------------------')\n",
    "sum = 0.0\n",
    "for key, value in results.items():\n",
    "print(f'Fold {key}: {value} %')\n",
    "sum += value\n",
    "print(f'Average: {sum/len(results.items())} %')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Prepare MNIST dataset by concatenating Train/Test part; we split later.\n",
    "#dataset_train_part = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor(), train=True)\n",
    "#dataset_test_part = MNIST(os.getcwd(), download=True, transform=transforms.ToTensor(), train=False)\n",
    "#dataset = ConcatDataset([dataset_train_part, dataset_test_part])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "#kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "# Start print\n",
    "#print('--------------------------------')\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d821f-d236-4005-a7ff-bb0563134de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(epochs, loss_vals):\n",
    "    plt.plot(epochs, loss)\n",
    "    \n",
    "def train(df, config):#, y_train, lr=0.001, num_epochs=1000):\n",
    "    \n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train) \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset) #, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    ## Model\n",
    "    model = CNN_LSTM()\n",
    "\n",
    "    ## Loss and Optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "    \n",
    "    ## Train\n",
    "    print('Starting training.')\n",
    "    training_loss = []\n",
    "    lowest_loss = np.inf\n",
    "    \n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update statistics\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        training_loss.append(running_loss)\n",
    "        if training_loss < lowest_loss:\n",
    "            lowest_loss = training_loss\n",
    "            \n",
    "                \n",
    "    plot_loss(np.linspace(1, num_epochs, num_epochs).astype(int), training_loss)\n",
    "        \n",
    "        \n",
    "    print('Training done.')\n",
    "\n",
    "    # save trained model    \n",
    "    torch.save(model.state_dict(), 'saved_model.pt')\n",
    "    print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b558bce-05f6-4c50-9aec-cef79da22181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "def testing(X_test, y_test, predicting_feature='new_property_id'):\n",
    "\n",
    "    #batch_size = 18\n",
    "    test_dataset = TensorDataset(X_test, y_test) \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    dataiter = iter(test_dataloader)\n",
    "    #if predicting_feature=='new_property_id':\n",
    "       # classes = ('smoothness', 'thickness', 'warmth', 'flexibility', 'softness')\n",
    "    #elif predicting_feature == 'new_rating_level_num':\n",
    "        #classes = (1,2,3,4,5,6,7)\n",
    "\n",
    "\n",
    "    ## load the trained model\n",
    "    class_model = CNN_LSTM()\n",
    "    class_model.load_state_dict(torch.load('saved_model.pt'))\n",
    "\n",
    "\n",
    "    ## inference\n",
    "    images, labels = dataiter.next()\n",
    "    labels = labels.reshape([batch_size])\n",
    "    labels = labels.type(torch.LongTensor)\n",
    "    #print('Ground-truth: ', ' '.join('%5s' % classes[labels_3[j]] for j in range(batch_size)))\n",
    "\n",
    "    outputs = class_model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    #print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(batch_size)))\n",
    "    \n",
    "    labels_np = labels.numpy()\n",
    "    predicted_np = predicted.numpy()\n",
    "    \n",
    "    if predicting_feature=='new_property_id':\n",
    "        conf_mat = confusion_matrix(labels_np, predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "        macro_f1_score = f1_score(labels_np, predicted_np, average='macro') \n",
    "    elif predicting_feature=='new_rating_level_num':\n",
    "        conf_mat = confusion_matrix(labels_np, predicted_np, labels=[0, 1, 2]) \n",
    "        weighted_f1_score = f1_score(labels_np, predicted_np, average='weighted') \n",
    "    micro_f1_score = f1_score(labels_np, predicted_np, average='micro')  \n",
    "    acc = accuracy_score(labels_np, predicted_np)\n",
    "     \n",
    "    if predicting_feature == 'new_property_id':\n",
    "        print(f'Using a CNN+LSTM for automatic property recognition:') \n",
    "    elif predicting_feature == 'new_rating_level_num':\n",
    "        print(f'Using a CNN+LSTM for automatic rating prediction:')    \n",
    "    print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "    print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "    if predicting_feature == 'new_property_id':\n",
    "        print(f\"(3) macro F1 score = {round(macro_f1_score,2)}\")\n",
    "    elif predicting_feature == 'new_rating_level_num':\n",
    "        print(f\"(3) weighted F1 score = {round(weighted_f1_score,2)}\")      \n",
    "    print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79477431-395e-4f82-b9e3-622ec6458f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_LOCOCV_properties(data, num_inner_folds=5, predicting_feature = 'property_id', random_state=num):\n",
    "    #if predicting_feature == 'property_id':\n",
    "    #    print(f'Classification accuracy when predicting properties at random : {round(1/len(data.property_id.unique())*100,2)}% ')\n",
    "    #else:\n",
    "    #    print(f'Classification accuracy when predicting ratings at random : {round(1/len(data.rating_level_num.unique())*100,2)}% ')\n",
    "    #print('__________________________________________')\n",
    "        \n",
    "    if predicting_feature == 'property_id':\n",
    "        macro_f1_lst = []\n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        weighted_f1_lst = []    \n",
    "    micro_f1_lst = []\n",
    "    acc_lst = []\n",
    "    for cloth_id in range(1,7):      \n",
    "        # Split the data into training and testing\n",
    "        training_data = data[data.clothes_id != cloth_id]\n",
    "        testing_data = data[data.clothes_id == cloth_id]\n",
    "        \n",
    "        # Data preparation\n",
    "        X_train = create_X(training_data)     \n",
    "        y_train = create_y(training_data, predicting_feature = 'property_id')\n",
    "        X_test = create_X(testing_data)         \n",
    "        y_test = create_y(testing_data, predicting_feature = 'property_id')\n",
    "        \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_inner_folds, shuffle=True, random_state=num)\n",
    "        \n",
    "        # Define the model\n",
    "        NN_model = CNN_LSTM()\n",
    "        \n",
    "        # Create a dictionary with the hyperparameters to tune\n",
    "        features_dict = dict()\n",
    "        features_dict['n_estimators'] = [100, 500, 1000, 1500]\n",
    "        \n",
    "        # Define the Grid Search\n",
    "        if predicting_feature == 'property_id':\n",
    "            search = GridSearchCV(rf_model, features_dict, scoring='f1_macro', cv=cv_inner, refit=True) #accuracy\n",
    "        elif predicting_feature == 'rating_level_num':\n",
    "            search = GridSearchCV(rf_model, features_dict, scoring='f1_weighted', cv=cv_inner, refit=True) #accuracy\n",
    "        \n",
    "        # Execute the search\n",
    "        result = search.fit(X_train, y_train)    \n",
    "        \n",
    "        # Obtain the best performing model fit on the whole training set\n",
    "        best_rf_model = result.best_estimator_\n",
    "        \n",
    "        # Using the model, obtain predictions for the test data\n",
    "        predictions = best_rf_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        if predicting_feature == 'property_id':\n",
    "            conf_mat = confusion_matrix(y_test, predictions, labels=[12, 13, 14, 15, 16])\n",
    "            macro_f1_score = f1_score(y_test, predictions, average='macro') \n",
    "            macro_f1_lst.append(macro_f1_score) \n",
    "        elif predicting_feature == 'rating_level_num':\n",
    "            conf_mat = confusion_matrix(y_test, predictions, labels=[1,2,3])\n",
    "            weighted_f1_score = f1_score(y_test, predictions, average='weighted') \n",
    "            weighted_f1_lst.append(weighted_f1_score) \n",
    "            \n",
    "        micro_f1_score = f1_score(y_test, predictions, average='micro')  \n",
    "        micro_f1_lst.append(micro_f1_score)\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        acc_lst.append(acc)\n",
    "        \n",
    "        print(f'Leaving sock {cloth_id} out {result.best_params_}:') \n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) Micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        if predicting_feature == 'property_id':\n",
    "            print(f\"(3) Macro F1 score = {round(macro_f1_score,2)}\")\n",
    "        elif predicting_feature == 'rating_level_num':\n",
    "            print(f\"(3) Weighted F1 score = {round(weighted_f1_score,2)}\")            \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "\n",
    "        print('__________________________________________')    \n",
    "\n",
    "    avg_micro_f1_score = sum(micro_f1_lst) / len(micro_f1_lst)\n",
    "    if predicting_feature == 'property_id':\n",
    "        avg_macro_f1_score = sum(macro_f1_lst) / len(macro_f1_lst)\n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        avg_weighted_f1_score = sum(weighted_f1_lst) / len(weighted_f1_lst)               \n",
    "    avg_acc = sum(acc_lst) / len(acc_lst)   \n",
    "    \n",
    "    print(f'Using Leave One Cloth Out CV (LOCOCV):') \n",
    "    print(f\"(1) Average micro F1 score = {round(avg_micro_f1_score,2)}\")\n",
    "    if predicting_feature == 'property_id':\n",
    "        print(f\"(2) Average macro F1 score = {round(avg_macro_f1_score,2)}\")\n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        print(f\"(2) Average weighted F1 score = {round(avg_weighted_f1_score,2)}\")      \n",
    "    print(f\"(3) Average Percentage Classification accuracy = {round(avg_acc*100,2)}%\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb89bdb-b815-4371-b049-e7a2165391dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df986cc-e2dd-4105-8c40-c54d8ad01cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "batch_size = X_train.shape[0]\n",
    "train_dataset = TensorDataset(X_train, y_train) \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "## Model\n",
    "model = CNN_LSTM()\n",
    "\n",
    "\n",
    "## Loss and Optimiser\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "## Train\n",
    "print('Starting training.')\n",
    "#for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "running_loss = 0.0\n",
    "for i, data in enumerate(train_dataloader, 0):\n",
    "    # get the inputs; data is a list of [inputs, labels]\n",
    "    inputs, labels = data\n",
    "    #labels = labels.reshape([batch_size])\n",
    "    #labels = labels.type(torch.LongTensor)\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    #print(outputs)\n",
    "    #print(labels)\n",
    "    loss = criterion(outputs, labels)\n",
    "    #print(loss)\n",
    "    #print('--------------')\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "\n",
    "    # Update statistics\n",
    "    #running_loss += loss.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfb85ff-e8cc-4c11-a891-56550e376e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(1, 10, 10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ca688-a4f0-4962-86b6-88a49501a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \n",
    "training(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd96621-4038-49b8-a63f-890cf0fba3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == '__main__':\n",
    "def testing(X_test, y_test, predicting_feature='new_property_id'):\n",
    "\n",
    "    batch_size = 18\n",
    "    test_dataset = TensorDataset(X_test, y_test) \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    dataiter = iter(test_dataloader)\n",
    "    #if predicting_feature=='new_property_id':\n",
    "       # classes = ('smoothness', 'thickness', 'warmth', 'flexibility', 'softness')\n",
    "    #elif predicting_feature == 'new_rating_level_num':\n",
    "        #classes = (1,2,3,4,5,6,7)\n",
    "\n",
    "\n",
    "    ## load the trained model\n",
    "    class_model = CNN_LSTM()\n",
    "    class_model.load_state_dict(torch.load('saved_model.pt'))\n",
    "\n",
    "\n",
    "    ## inference\n",
    "    images, labels = dataiter.next()\n",
    "    labels = labels.reshape([batch_size])\n",
    "    labels = labels.type(torch.LongTensor)\n",
    "    #print('Ground-truth: ', ' '.join('%5s' % classes[labels_3[j]] for j in range(batch_size)))\n",
    "\n",
    "    outputs = class_model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    #print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(batch_size)))\n",
    "    \n",
    "    labels_np = labels.numpy()\n",
    "    predicted_np = predicted.numpy()\n",
    "    \n",
    "    if predicting_feature=='new_property_id':\n",
    "        conf_mat = confusion_matrix(labels_np, predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "        macro_f1_score = f1_score(labels_np, predicted_np, average='macro') \n",
    "    elif predicting_feature=='new_rating_level_num':\n",
    "        conf_mat = confusion_matrix(labels_np, predicted_np, labels=[0, 1, 2]) \n",
    "        weighted_f1_score = f1_score(labels_np, predicted_np, average='weighted') \n",
    "    micro_f1_score = f1_score(labels_np, predicted_np, average='micro')  \n",
    "    acc = accuracy_score(labels_np, predicted_np)\n",
    "     \n",
    "    if predicting_feature == 'new_property_id':\n",
    "        print(f'Using a CNN+LSTM for automatic property recognition:') \n",
    "    elif predicting_feature == 'new_rating_level_num':\n",
    "        print(f'Using a CNN+LSTM for automatic rating prediction:')    \n",
    "    print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "    print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "    if predicting_feature == 'new_property_id':\n",
    "        print(f\"(3) macro F1 score = {round(macro_f1_score,2)}\")\n",
    "    elif predicting_feature == 'new_rating_level_num':\n",
    "        print(f\"(3) weighted F1 score = {round(weighted_f1_score,2)}\")      \n",
    "    print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b28c00c-6410-4292-8bae-c94282052b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting properties\n",
    "\n",
    "# Create the training and testing data\n",
    "X_train, X_test, y_train, y_test = data_preparation(emg_data, starting_index = 13, predicting_feature='new_property_id', random_state=num)\n",
    "print('----------------------------')\n",
    "# Train the model\n",
    "training(X_train, y_train)\n",
    "print('----------------------------')\n",
    "# Test the model\n",
    "testing(X_test, y_test, predicting_feature='new_property_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c632eb2-aa9a-483f-b773-9372e00e101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "x = fc1(x)\n",
    "print(x.shape)\n",
    "x = fc2(x)\n",
    "print(x.shape)\n",
    "x = fc3(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7033883-a9f0-4df6-9d87-93aaa717f03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.random.rand(180, 8, 15)\n",
    "inp1 = torch.Tensor(arr) \n",
    "arr2 = np.random.rand(180, 8, 15)\n",
    "inp2 = torch.Tensor(arr) \n",
    "\n",
    "conv1 = nn.Conv1d(in_channels=8, out_channels=8, kernel_size=2, stride=1, padding=0) # Change kernel size to 3\n",
    "pool = nn.MaxPool1d(2, 2) # Change kernel size to 1\n",
    "rnn = nn.LSTM(7, 5, 1)\n",
    "h0 = torch.randn(1, 8, 5)\n",
    "c0 = torch.randn(1, 8, 5)\n",
    "fc1 = nn.Linear(8 * 10, 50)\n",
    "fc2 = nn.Linear(50, 5)\n",
    "#fc3 = nn.Linear(220, 5)\n",
    "\n",
    "#print(inp.shape)\n",
    "x = (F.relu(conv1(inp1))) # Try tanh instead\n",
    "#print(x.shape)\n",
    "x = (pool(x))\n",
    "#print(x.shape)\n",
    "x, (hn, cn) = rnn(x, (h0, c0))\n",
    "#print(x.shape)\n",
    "\n",
    "\n",
    "y = (F.relu(conv1(inp2))) # Try tanh instead\n",
    "#print(y.shape)\n",
    "y = (pool(y))\n",
    "#print(y.shape)\n",
    "y, (hm, cm) = rnn(y, (h0, c0))\n",
    "#print(y.shape)\n",
    "\n",
    "z = torch.cat((x, y), 2)\n",
    "print(z.shape)\n",
    "z = torch.flatten(z, 1) # flatten all dimensions except batch\n",
    "print(z.shape)\n",
    "z = fc1(z)\n",
    "print(z.shape)\n",
    "z = fc2(z)\n",
    "print(z.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630b9e8-b216-4de7-98aa-8ca3ab596ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(emg_data, starting_index = 13, predicting_feature='new_property_id', random_state=num):\n",
    "    \n",
    "    X_arr = emg_data.iloc[:,starting_index:].values\n",
    "    print(f'X_arr before reshaping {X_arr.shape}')\n",
    "    X_arr = X_arr.reshape((int(X_arr.shape[0]/3), 3, int(X_arr.shape[1])),order='F')\n",
    "    print(f'X_arr after reshaping {X_arr.shape}')\n",
    "    \n",
    "    #y_arr = emg_data.new_property_id.values\n",
    "    y_arr = emg_data[predicting_feature].values\n",
    "    y_arr = y_arr[0::3]\n",
    "    print(f'y_arr before reshaping {y_arr.shape}')\n",
    "    y_arr = np.reshape(y_arr, (y_arr.shape[0],1))\n",
    "    print(f'y_arr after reshaping {y_arr.shape}')\n",
    "    \n",
    "    # Create training and testing datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size = 0.1, shuffle=True, random_state = num) \n",
    "\n",
    "    # transform arrays to torch tensors\n",
    "    tensor_X_train = torch.Tensor(X_train) \n",
    "    tensor_X_test = torch.Tensor(X_test) \n",
    "    tensor_y_train = torch.Tensor(y_train)\n",
    "    tensor_y_test = torch.Tensor(y_test)\n",
    "    \n",
    "    return tensor_X_train, tensor_X_test, tensor_y_train, tensor_y_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9999828-93f6-4ac5-acea-54d6881b6f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c84a74-8c28-4a27-b49f-918ca798a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting rating\n",
    "# Create the training and testing data\n",
    "#property_id_lst = [12,13,14,15,16]\n",
    "property_lst = ['smoothness', 'thickness', 'warmth', 'flexibility', 'softness']#, 'enjoyment']\n",
    "#print(f'Classification accuracy when predicting properties at random: {round((1/7)*100,2)}% ')\n",
    "for prop in property_lst:\n",
    "    # Create dataset\n",
    "    property_data = emg_data[emg_data.property_name == prop]\n",
    "    print(prop)\n",
    "    X_train, X_test, y_train, y_test = data_preparation(property_data, starting_index = 13, predicting_feature='new_rating_level_num', random_state=num)\n",
    "    print('----------------------------')\n",
    "    # Train the model\n",
    "    training(X_train, y_train)\n",
    "    print('----------------------------')\n",
    "    # Test the model\n",
    "    testing(X_test, y_test, predicting_feature='new_rating_level_num')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e63d8e-5ea2-4f6d-8f4a-6225a6f5359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fchgvjhbkjnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0817b0-5d76-4a1e-a0d6-136ffa800b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xtdrycfguvhibjonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c287c-1a07-4253-acf1-e52c32682b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_LOCOCV_properties(data, num_inner_folds=5, predicting_feature = 'property_id', random_state=num):\n",
    "    if predicting_feature == 'property_id':\n",
    "        print(f'Classification accuracy when predicting properties at random : {round(1/len(data.property_id.unique())*100,2)}% ')\n",
    "    else:\n",
    "        print(f'Classification accuracy when predicting ratings at random : {round(1/len(data.rating_level_num.unique())*100,2)}% ')\n",
    "    print('__________________________________________')\n",
    "        \n",
    "    if predicting_feature == 'property_id':\n",
    "        macro_f1_lst = []\n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        weighted_f1_lst = []    \n",
    "    micro_f1_lst = []\n",
    "    acc_lst = []\n",
    "    for cloth_id in range(1,7):      \n",
    "        # Split the data into training and testing\n",
    "        training_data = data[data.clothes_id != cloth_id]\n",
    "        testing_data = data[data.clothes_id == cloth_id]\n",
    "        \n",
    "        # Data preparation\n",
    "        starting_index = 11\n",
    "        X_train = training_data.iloc[:,starting_index:].values        \n",
    "        y_train = training_data[predicting_feature].values\n",
    "        X_test = testing_data.iloc[:,starting_index:].values        \n",
    "        y_test = testing_data[predicting_feature].values\n",
    "        \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_inner_folds, shuffle=True, random_state=num)\n",
    "        \n",
    "        # Define the model\n",
    "        rf_model = RandomForestClassifier(random_state=num)\n",
    "        \n",
    "        # Create a dictionary with the hyperparameters to tune\n",
    "        features_dict = dict()\n",
    "        features_dict['n_estimators'] = [100, 500, 1000, 1500]\n",
    "        \n",
    "        # Define the Grid Search\n",
    "        if predicting_feature == 'property_id':\n",
    "            search = GridSearchCV(rf_model, features_dict, scoring='f1_macro', cv=cv_inner, refit=True) #accuracy\n",
    "        elif predicting_feature == 'rating_level_num':\n",
    "            search = GridSearchCV(rf_model, features_dict, scoring='f1_weighted', cv=cv_inner, refit=True) #accuracy\n",
    "        \n",
    "        # Execute the search\n",
    "        result = search.fit(X_train, y_train)    \n",
    "        \n",
    "        # Obtain the best performing model fit on the whole training set\n",
    "        best_rf_model = result.best_estimator_\n",
    "        \n",
    "        # Using the model, obtain predictions for the test data\n",
    "        predictions = best_rf_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        if predicting_feature == 'property_id':\n",
    "            conf_mat = confusion_matrix(y_test, predictions, labels=[12, 13, 14, 15, 16])\n",
    "            macro_f1_score = f1_score(y_test, predictions, average='macro') \n",
    "            macro_f1_lst.append(macro_f1_score) \n",
    "        elif predicting_feature == 'rating_level_num':\n",
    "            conf_mat = confusion_matrix(y_test, predictions, labels=[1,2,3])\n",
    "            weighted_f1_score = f1_score(y_test, predictions, average='weighted') \n",
    "            weighted_f1_lst.append(weighted_f1_score) \n",
    "            \n",
    "        micro_f1_score = f1_score(y_test, predictions, average='micro')  \n",
    "        micro_f1_lst.append(micro_f1_score)\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        acc_lst.append(acc)\n",
    "        \n",
    "        print(f'Leaving sock {cloth_id} out {result.best_params_}:') \n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) Micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        if predicting_feature == 'property_id':\n",
    "            print(f\"(3) Macro F1 score = {round(macro_f1_score,2)}\")\n",
    "        elif predicting_feature == 'rating_level_num':\n",
    "            print(f\"(3) Weighted F1 score = {round(weighted_f1_score,2)}\")            \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "\n",
    "        print('__________________________________________')    \n",
    "\n",
    "    avg_micro_f1_score = sum(micro_f1_lst) / len(micro_f1_lst)\n",
    "    if predicting_feature == 'property_id':\n",
    "        avg_macro_f1_score = sum(macro_f1_lst) / len(macro_f1_lst)\n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        avg_weighted_f1_score = sum(weighted_f1_lst) / len(weighted_f1_lst)               \n",
    "    avg_acc = sum(acc_lst) / len(acc_lst)   \n",
    "    \n",
    "    print(f'Using Leave One Cloth Out CV (LOCOCV):') \n",
    "    print(f\"(1) Average micro F1 score = {round(avg_micro_f1_score,2)}\")\n",
    "    if predicting_feature == 'property_id':\n",
    "        print(f\"(2) Average macro F1 score = {round(avg_macro_f1_score,2)}\")\n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        print(f\"(2) Average weighted F1 score = {round(avg_weighted_f1_score,2)}\")      \n",
    "    print(f\"(3) Average Percentage Classification accuracy = {round(avg_acc*100,2)}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6327bcc3-9d9e-4721-baf3-a8421eef67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = create_X(emg_0_new)\n",
    "y_arr = create_y(emg_0_new, predicting_feature = 'property_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43baa0b2-5879-4e7c-be81-da5d47f4f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831866c-65f6-4ea7-bb7e-f8edd816b0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe0566-ec83-4dcf-9684-184505422710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efec75f-1fd4-4d8b-9493-ebe0e5860ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/niharawarawita/Desktop/MSc Project/Data/EMG_data_collection/combined_stats_nihara.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff0f4f-181b-4f0c-b6c5-a2d271f6ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain only the physical properties\n",
    "physical_data = data[data.property_name != 'enjoyment']\n",
    "physical_data.reset_index(inplace=True, drop = True)\n",
    "physical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083852d-6ae4-4f4b-b5b3-d917f5fde249",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_data.property_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39feb2-bcda-480b-8708-493a9121f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_data.insert(3, 'new_property_id', 20)\n",
    "physical_data['new_property_id'] = physical_data['property_id'] - 12\n",
    "\n",
    "physical_data.insert(9, 'new_rating_level_num', 10)\n",
    "physical_data['new_rating_level_num'] = physical_data['rating_level_num'] - 1\n",
    "physical_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9430e9-3769-496d-a49b-c3224f30917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain only the EMG data\n",
    "ending_index = 61\n",
    "emg_data = physical_data.iloc[:, :ending_index]\n",
    "emg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15e083-c762-4fcf-921d-a9432e629ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emg_data.property_name.unique())\n",
    "print(emg_data.new_property_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c5e897-96f1-4b4a-9ef2-18ae583214ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.rand(180, 8, 469)\n",
    "inp = torch.Tensor(arr) \n",
    "\n",
    "conv1 = nn.Conv1d(in_channels=8, out_channels=8, kernel_size=2, stride=1, padding=0) # Change kernel size to 3\n",
    "pool = nn.MaxPool1d(2, 2) # Change kernel size to 1\n",
    "rnn = nn.LSTM(234, 150, 1)\n",
    "h0 = torch.randn(1, 8, 150)\n",
    "c0 = torch.randn(1, 8, 150)\n",
    "fc1 = nn.Linear(8 * 150, 500)\n",
    "fc2 = nn.Linear(500, 220)\n",
    "fc3 = nn.Linear(220, 5)\n",
    "\n",
    "print(inp.shape)\n",
    "x = (F.relu(conv1(inp))) # Try tanh instead\n",
    "print(x.shape)\n",
    "x = (pool(inp))\n",
    "print(x.shape)\n",
    "x, (hn, cn) = rnn(x, (h0, c0))\n",
    "print(x.shape)\n",
    "x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "print(x.shape)\n",
    "x = fc1(x)\n",
    "print(x.shape)\n",
    "x = fc2(x)\n",
    "print(x.shape)\n",
    "x = fc3(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf7685-4253-4f8f-aa51-2c7fb4a86c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8da02-8dc9-48d3-ba55-489bfeebdbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise and print the network architechture\n",
    "m = CNN_LSTM()\n",
    "print(f\"Summary of the network architechture: {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736bd68-92ff-4f6a-954f-5fbbd9214e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae14dd-5e5c-411a-9525-ac6154350b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c6281-fee5-4c74-914f-6d834e8425b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "drytfuygiuhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5ca934-4a3f-4f2f-bf08-74be6e1166d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(tensor_X_train, tensor_y_train) \n",
    "train_dataloader = DataLoader(train_dataset) \n",
    "\n",
    "def foo():\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "        if i in range(2):\n",
    "            b = labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            print(inputs.shape,labels.shape, labels)\n",
    "            print('-----------------------------------------------------------------------------------------------------------')\n",
    "            return b\n",
    "\n",
    "c= foo()\n",
    "c.val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65707aa-2086-4d9a-9f81-45be147cb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(c.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4367eea-4193-4e70-b070-b4a6efbadbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "     self.conv1 = nn.Conv1d(in_channels=3, out_channels=24, kernel_size=3, stride=1, padding=1) #3, 6, 5\n",
    "        self.pool = nn.MaxPool2d(2, 2) # Kernel size of 2 and a stride of 2\n",
    "        self.conv2 = nn.Conv1d(in_channels=12, out_channels=48, kernel_size=3, stride=1, padding=1) #3, 6, 5\n",
    "        self.rnn = nn.LSTM(12, 18, 1)\n",
    "        self.h0 = torch.randn(1, 24, 18)\n",
    "        self.c0 = torch.randn(1, 24, 18)\n",
    "        self.fc1 = nn.Linear(12 * 18, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a93775-caeb-4483-b1e7-7c5f355e7afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "inpt = np.random.rand(1,3,48)\n",
    "input_tensor = torch.Tensor(inpt)\n",
    "\n",
    "conv1 = nn.Conv1d(in_channels=3, out_channels=24, kernel_size=3, stride=1, padding=1) #3, 6, 5\n",
    "pool = nn.MaxPool2d(2, 2) # Kernel size of 2 and a stride of 2\n",
    "conv2 = nn.Conv1d(in_channels=12, out_channels=48, kernel_size=3, stride=1, padding=1) #3, 6, 5\n",
    "rnn = nn.LSTM(12, 18, 1)\n",
    "h0 = torch.randn(1, 24, 18)\n",
    "c0 = torch.randn(1, 24, 18)\n",
    "fc1 = nn.Linear(24 * 18, 120)\n",
    "fc2 = nn.Linear(120, 84)\n",
    "fc3 = nn.Linear(84, 5)\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "x = pool(F.relu(conv1(input_tensor)))\n",
    "print(x.shape)\n",
    "x = pool(F.relu(conv2(x)))\n",
    "print(x.shape)\n",
    "\n",
    "x, (hn, cn) = rnn(x, (h0, c0))\n",
    "print(x.shape)\n",
    "x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "print(x.shape)\n",
    "x = F.relu(fc1(x))\n",
    "print(x.shape)\n",
    "x = F.relu(fc2(x))\n",
    "print(x.shape)\n",
    "x = fc3(x)\n",
    "print(x.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      #  x = self.pool(F.relu(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0c58e-9301-4e0c-9ebf-f532985ed9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cghvjbknl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba112447-b2aa-44e0-ad5d-6d968c7c2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        print(x.shape)\n",
    "        print(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6e5f66-0d1c-4638-bf28-79676ef3582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ## cifar-10 dataset\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    batch_size = 20\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # example images\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    im = Image.fromarray((torch.cat(images.split(1,0),3).squeeze()/2*255+.5*255).permute(1,2,0).numpy().astype('uint8'))\n",
    "    im.save(\"train_pt_images.jpg\")\n",
    "    print('train_pt_images.jpg saved.')\n",
    "    print('Ground truth labels:' + ' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "\n",
    "\n",
    "    ## cnn\n",
    "    net = Net()\n",
    "\n",
    "\n",
    "    ## loss and optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "    ## train\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            if i in range(2):\n",
    "                print(labels)\n",
    "                print(labels.shape)\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad5e236-e5fd-406e-a62a-4c8fa49ac662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image   \n",
    "if __name__ == '__main__':\n",
    "    ## cifar-10 dataset\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    batch_size = 4\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    dataiter = iter(testloader)\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\n",
    "    ## load the trained model\n",
    "    #model = Net()\n",
    "    #model.load_state_dict(torch.load('saved_model.pt'))\n",
    "\n",
    "\n",
    "    ## inference\n",
    "    images, labels = dataiter.next()\n",
    "    print(labels)\n",
    "    print(labels.shape)\n",
    "    print('Ground-truth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "    #outputs = model(images)\n",
    "    #_, predicted = torch.max(outputs, 1)\n",
    "    #print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))\n",
    "\n",
    "    # save to images\n",
    "    #im = Image.fromarray((torch.cat(images.split(1,0),3).squeeze()/2*255+.5*255).permute(1,2,0).numpy().astype('uint8'))\n",
    "    #im.save(\"test_pt_images.jpg\")\n",
    "    #print('test_pt_images.jpg saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b20ef1-0808-421e-a024-fa6e4edfe894",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 54\n",
    "train_dataset = TensorDataset(tensor_X_train, tensor_y_train) \n",
    "#train_dataloader = DataLoader(train_dataset) \n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "classes = (12.0,13.0,14.0,15.0,16.0)\n",
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        print(labels.shape)\n",
    "        labels_2 = labels.reshape([batch_size])\n",
    "        #if i in range(2):\n",
    "           # print(labels_2)\n",
    "           # print(labels_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69c7d79-f7f5-4f9f-83b9-7a7d73550d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "\n",
    "#from network_pt import Net\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ## cifar-10 dataset\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    batch_size = 20\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    # example images\n",
    "    dataiter = iter(trainloader)\n",
    "    images, labels = dataiter.next()\n",
    "\n",
    "    im = Image.fromarray((torch.cat(images.split(1,0),3).squeeze()/2*255+.5*255).permute(1,2,0).numpy().astype('uint8'))\n",
    "    im.save(\"train_pt_images.jpg\")\n",
    "    print('train_pt_images.jpg saved.')\n",
    "    print('Ground truth labels:' + ' '.join('%5s' % classes[labels[j]] for j in range(batch_size)))\n",
    "\n",
    "\n",
    "    ## cnn\n",
    "    net = Net()\n",
    "\n",
    "\n",
    "    ## loss and optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "\n",
    "    ## train\n",
    "    for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Training done.')\n",
    "\n",
    "    # save trained model\n",
    "    torch.save(net.state_dict(), 'saved_model.pt')\n",
    "    print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19479315-3b6c-41fd-b1ae-e629d453f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgfhgvjhbkjnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6c268-480d-43d4-aa58-90c6772686a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaffe8e-654f-4377-9470-7e2a381ce4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32027cea-6bd2-4360-9722-2d1488392608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d2722d-c432-454e-b44a-2c32c5d92209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0069c65e-790d-4c8f-8ce5-d19739aecbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt = np.random.rand(4, 3, 32, 32)\n",
    "input_tensor = torch.Tensor(inpt)\n",
    "\n",
    "conv1 = nn.Conv2d(3, 6, 5)\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "conv2 = nn.Conv2d(6, 16, 5)\n",
    "fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "fc2 = nn.Linear(120, 84)\n",
    "fc3 = nn.Linear(84, 10)\n",
    "\n",
    "print(input_tensor.shape)\n",
    "x = pool(F.relu(conv1(input_tensor)))\n",
    "print(x.shape)\n",
    "x = pool(F.relu(conv2(x)))\n",
    "print(x.shape)\n",
    "print('drfytguhjn')\n",
    "x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "print(x.shape)\n",
    "x = F.relu(fc1(x))\n",
    "print(x.shape)\n",
    "x = F.relu(fc2(x))\n",
    "print(x.shape)\n",
    "x = fc3(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1860b60e-5805-428e-addf-300122585a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489419e3-f076-468c-8865-4790bcfdfeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6657a71-b5df-4477-9ff5-2495b1cd41da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c61047-e920-4725-a825-14ed36f70b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fc6eb-cbee-428b-ac48-6ab966b9a059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04029ce2-72d0-4b2d-ab4c-48679ac162c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747adc6-156c-495a-95c2-291bf28241bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "===========\n",
    "rnn = nn.LSTM(features_in=10, features_out=20, num_layers=1)\n",
    "is similar to lstm = tf.keras.layers.LSTM(features_out=20)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    ">>> c0 = torch.randn(2, 3, 20)\n",
    ">>> output, (hn, cn) = rnn(input, (h0, c0))\n",
    "\n",
    "===========\n",
    "\n",
    "rnn = nn.LSTM(10, 20, 1, batch_first=True)\n",
    "\n",
    "#  [batch, sequence length, features]\n",
    "input = torch.randn(5, 3, 10)\n",
    "\n",
    "h0 = torch.randn(1, 5, 20)\n",
    "c0 = torch.randn(1, 5, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))\n",
    "\n",
    "# output shape: [batch, sequence length, out features]\n",
    "output.shape\n",
    "===============\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eafb2e-2f8d-43fe-bc17-437d4e86bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = nn.Conv2d(3, 6, 5) # Input channel size is 3 as the images have 3 colour channels, output channel size is 6 and the kernel size is 5\n",
    "pool = nn.MaxPool2d(2, 2) # Kernel size of 2 and a stride of 2\n",
    "conv2 = nn.Conv2d(6, 16, 5) # The input channel size is equal to the last output channel size\n",
    "print(images.shape) # [ 4, 3, 32, 32] 4 batches, 3 colour channels (rgb) and images are 32x32\n",
    "x = conv1(images)\n",
    "print(x.shape) # [4, 6, 28, 28] 6 output channels as specified, image size is 28x28 (resulting image is smaller as calculated in line 88)\n",
    "x = pool(x)\n",
    "print(x.shape) # [4, 6, 14, 14] The pooling layer has a kernel size of 2x2 and a stride of 2. This reduces the images by a factor of 2\n",
    "x = conv2(x)\n",
    "print(x.shape) # [4, 16, 10, 10] 16 is the specified output size, 10 is calculated using the formula\n",
    "x = pool(x)\n",
    "print(x.shape) # [4, 16, 5, 5] The pooling layer has a kernel size of 2x2 and a stride of 2. This reduces the images by a factor of 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590bc65a-0657-40aa-b24f-745a1f9f237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7011ee5-f569-48be-8fe3-338c632c142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rating_arr = emg_data.rating_level_num.values\n",
    "y_rating_arr = y_rating_arr[0::3]\n",
    "y_rating_arr = np.reshape(y_rating_arr, (y_rating_arr.shape[0],1))\n",
    "y_rating_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953e95f-2064-4c9f-817c-a8f0d7a42a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_x = [np.array([[1.0,2],[3,4]]),np.array([[5.,6],[7,8]])] # a list of numpy arrays\n",
    "#my_y = [np.array([4.]), np.array([2.])] # another list of numpy arrays (targets)\n",
    "\n",
    "tensor_X = torch.Tensor(my_x) # transform to torch tensor\n",
    "tensor_y = torch.Tensor(my_y)\n",
    "\n",
    "my_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "my_dataloader = DataLoader(my_dataset) # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bc326-39e1-480e-a3c8-544ea8b66958",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713b478-8fbf-4a1c-9321-10affddcb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaturalSceneClassification(ImageClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 32, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "        \n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128 ,128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256,256, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(82944,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,6)\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599782ca-dd54-43e9-9f38-493029744cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dxtcfvgjbhknl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42bc2f1-5ac4-4d6c-9be2-268665408793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a10f0f-5c9b-4a8f-88b0-782fdb2785d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a8fa3-a6c5-4489-bda7-39d1bad48cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67117718-1626-4085-811d-a236b8e7905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/niharawarawita/Desktop/MSc Project/Data/EMG_data_collection/emg_0_stats.csv\"\n",
    "emg_0 = pd.read_csv(path)\n",
    "emg_0.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115bad9-4905-470c-a8d3-31f4edca7066",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/niharawarawita/Desktop/MSc Project/Data/EMG_data_collection/emg_1_stats.csv\"\n",
    "emg_1 = pd.read_csv(path)\n",
    "emg_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753da2ab-674b-4cfe-a813-4159e390dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(emg_0_arr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dcd76f-f00c-4af9-bcac-72106e21bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_index = 11\n",
    "emg_0_arr = emg_0.iloc[:,starting_index:].values\n",
    "print(emg_0_arr.shape)\n",
    "reshaped_emg_0_arr = emg_0_arr.reshape((int(emg_0_arr.shape[0]/3), 3, int(emg_0_arr.shape[1])),order='F')\n",
    "print(reshaped_emg_0_arr.shape)\n",
    "\n",
    "emg_1_arr = emg_1.iloc[:,starting_index:].values\n",
    "#print(emg_1_arr.shape)\n",
    "reshaped_emg_1_arr = emg_1_arr.reshape((int(emg_1_arr.shape[0]/3), 3, int(emg_1_arr.shape[1])),order='F')\n",
    "#print(reshaped_emg_1_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc1ee09-d4b8-4de3-8243-87bc028b3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_0_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ab58b-41be-42bf-a978-f7c75bef4837",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_emg_0_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2dac1-fc82-496a-9eda-0a7833f46ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16],[17,18,19,20],[21,22,23,24]])\n",
    "print(arr)\n",
    "print('-----------')\n",
    "newarr = arr.reshape((2, 3, 4),order='A')\n",
    "print(newarr)\n",
    "print('-----------')\n",
    "newarr = arr.reshape((2, 3, 4),order='C')\n",
    "print(newarr)\n",
    "print('-----------')\n",
    "newarr = arr.reshape((2, 3, 4),order='F')\n",
    "print(newarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85786536-c5cc-41a9-9452-b1317807eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_index = 11\n",
    "a = emg_0.iloc[:,starting_index:].values\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cd0155-d52e-464e-bd82-f97bbadf9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(6,7,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f7f446-37f3-47de-865e-25d06b526f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acbfdb9-92d3-4430-8479-08c3a211446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(3,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05408196-6a5e-490d-8733-548130a6b2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_index = 11\n",
    "X = emg_data.iloc[:,starting_index:].values\n",
    "y = emg_data[['property_id', 'rating_level_num']].values\n",
    "print(f'X.shape {X.shape}')\n",
    "print(f'y.shape {y.shape}')\n",
    "print('--------------------------------')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_property, X_test_property, y_train, y_test = train_test_split(X, y, test_size = 0.15, shuffle=True, random_state = num) \n",
    "print(f'X_train_property.shape {X_train_property.shape}')\n",
    "print(f'X_test_property.shape {X_test_property.shape}')\n",
    "print(f'y_train.shape {y_train.shape}')\n",
    "print(f'y_test.shape {y_test.shape}')\n",
    "print('--------------------------------')\n",
    "\n",
    "y_train_property, y_train_ranking = np.hsplit(y_train,2)\n",
    "y_test_property, y_test_ranking = np.hsplit(y_test,2)\n",
    "print(f'y_train_property.shape {y_train_property.shape}')\n",
    "print(f'y_test_property.shape {y_test_property.shape}')\n",
    "print(f'y_train_ranking.shape {y_train_ranking.shape}')\n",
    "print(f'y_test_ranking.shape {y_test_ranking.shape}')\n",
    "print('--------------------------------')\n",
    "\n",
    "X_train_ranking = np.concatenate((X_train_property, y_train_property), axis=1)\n",
    "X_test_ranking = np.concatenate((X_test_property, y_test_property), axis=1)\n",
    "print(f'X_train_ranking.shape {X_train_ranking.shape}')\n",
    "print(f'X_test_ranking.shape {X_test_ranking.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572b916-dc36-4484-a2a0-23fdf0667379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build CNN+LSTM to predict the property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4d6d4-5887-4a50-b2f2-0d6048794b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.hsplit(y_train,2)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e6c4b-2808-40c6-837f-0bb057347feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_property = np.reshape(y_property, (y_property.shape[0], 1))\n",
    "y_rating = np.reshape(y_rating, (y_rating.shape[0], 1))\n",
    "y_comb = np.concatenate((y_property, y_rating), axis=1)\n",
    "X_train_property, X_test_property, y_train_property, y_test_property = train_test_split(X_property, y_comb, test_size = 0.15, shuffle=True, random_state = num) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecdd920-dda5-4510-8857-c9b1f7af4e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_property.shape)\n",
    "print(y_property.shape)\n",
    "b = \n",
    "print(b.shape)\n",
    "\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92693a-64d7-40a5-b6db-b73a5a59c38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902935a-335f-47f4-a131-5aeaf8eea35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import dstack\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd915d-1a22-48ac-9f83-798dec610e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    " \n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    " \n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + '/Users/niharawarawita/Downloads/UCI HAR Dataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + '/Users/niharawarawita/Downloads/UCI HAR Dataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(f'trainX.shape {trainX.shape}')\n",
    "    print(f'trainy.shape {trainy.shape}')\n",
    "    print(f'testX.shape {testX.shape}')\n",
    "    print(f'testy.shape {testy.shape}')\n",
    "   # print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n",
    "\n",
    "# load data\n",
    "trainX, trainy, testX, testy = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95383a-7c33-4b7b-8254-e6c1f791b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c04f45-b0cc-4884-9baf-09c97d009123",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2d_layer = tf.keras.layers.Conv2D(64, (3, 3))\n",
    ">>> outputs = tf.keras.layers.TimeDistributed(conv_2d_layer)(inputs)\n",
    ">>> outputs.shape\n",
    "TensorShape([None, 10, 126, 126, 64])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44cdb9-aa27-4640-8da6-ba1c7ddebc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "output = TimeDistributed(conv1, input_shape=(None,n_length,n_features))(trainX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480bcae7-4050-4372-8e46-0c1774e68f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Before:trainX.shape {trainX.shape}')\n",
    "n_timesteps, n_features= trainX.shape[1], trainX.shape[2]\n",
    "conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')\n",
    "n_steps, n_length = 4, 32\n",
    "\n",
    "print(f'trainX.shape before reshaping {trainX.shape}')\n",
    "trainX_reshaped = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "print(f'trainX.shape after reshaping{trainX_reshaped.shape}')\n",
    "\n",
    "output = TimeDistributed(conv1, input_shape=(None,n_length,n_features))(trainX_reshaped)\n",
    "print(f'After conv1+temporal {output.shape}')\n",
    "\n",
    "#output1 = TimeDistributed(conv1)(output)\n",
    "#print(f'After conv1+temporal {output1.shape}')\n",
    "\n",
    "   #model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "   # model.add(TimeDistributed(Dropout(0.5)))\n",
    "   # model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "   # model.add(TimeDistributed(Flatten()))\n",
    "   # model.add(LSTM(100))\n",
    "   # model.add(Dropout(0.5))\n",
    "   # model.add(Dense(100, activation='relu'))\n",
    "   # model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d89f2a0-9c87-449a-942a-077026b729ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    verbose, epochs, batch_size = 0, 25, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    print(n_timesteps, n_features, n_outputs)\n",
    "    # reshape data into time steps of sub-sequences\n",
    "    n_steps, n_length = 4, 32\n",
    "    print(f'trainX.shape before {trainX.shape}')\n",
    "    print(f'testX.shape before {testX.shape}')\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    print(f'trainX.shape after {trainX.shape}')\n",
    "    print(f'testX.shape after {testX.shape}')\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "score = evaluate_model(trainX, trainy, testX, testy)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0de4a3-76f5-49d3-acd2-5613ee4d5e23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cabe1e-6101-4fb9-879a-a4bd1aa58625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a single file as a numpy array\n",
    "def load_file(filepath):\n",
    "    dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
    "    return dataframe.values\n",
    " \n",
    "# load a list of files and return as a 3d numpy array\n",
    "def load_group(filenames, prefix=''):\n",
    "    loaded = list()\n",
    "    for name in filenames:\n",
    "        data = load_file(prefix + name)\n",
    "        loaded.append(data)\n",
    "    # stack group so that features are the 3rd dimension\n",
    "    loaded = dstack(loaded)\n",
    "    return loaded\n",
    " \n",
    "# load a dataset group, such as train or test\n",
    "def load_dataset_group(group, prefix=''):\n",
    "    filepath = prefix + group + '/Inertial Signals/'\n",
    "    # load all 9 files as a single array\n",
    "    filenames = list()\n",
    "    # total acceleration\n",
    "    filenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "    # body acceleration\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    # body gyroscope\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "    # load input data\n",
    "    X = load_group(filenames, filepath)\n",
    "    # load class output\n",
    "    y = load_file(prefix + group + '/y_'+group+'.txt')\n",
    "    return X, y\n",
    " \n",
    "# load the dataset, returns train and test X and y elements\n",
    "def load_dataset(prefix=''):\n",
    "    # load all train\n",
    "    trainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
    "    print(trainX.shape, trainy.shape)\n",
    "    # load all test\n",
    "    testX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
    "    print(testX.shape, testy.shape)\n",
    "    # zero-offset class values\n",
    "    trainy = trainy - 1\n",
    "    testy = testy - 1\n",
    "    # one hot encode y\n",
    "    trainy = to_categorical(trainy)\n",
    "    testy = to_categorical(testy)\n",
    "    print(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
    "    return trainX, trainy, testX, testy\n",
    " \n",
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    # define model\n",
    "    verbose, epochs, batch_size = 0, 25, 64\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    # reshape data into time steps of sub-sequences\n",
    "    n_steps, n_length = 4, 32\n",
    "    trainX = trainX.reshape((trainX.shape[0], n_steps, n_length, n_features))\n",
    "    testX = testX.reshape((testX.shape[0], n_steps, n_length, n_features))\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "    model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy\n",
    "\n",
    "evaluate_model(X_train, y_train, X_test, y_test)\n",
    "# summarize scores\n",
    "def summarize_results(scores):\n",
    "    print(scores)\n",
    "    m, s = mean(scores), std(scores)\n",
    "    print('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
    " \n",
    "# run an experiment\n",
    "def run_experiment(repeats=10):\n",
    "    # load data\n",
    "    trainX, trainy, testX, testy = load_dataset()\n",
    "    # repeat experiment\n",
    "    scores = list()\n",
    "    for r in range(repeats):\n",
    "        score = evaluate_model(trainX, trainy, testX, testy)\n",
    "        score = score * 100.0\n",
    "        print('>#%d: %.3f' % (r+1, score))\n",
    "        scores.append(score)\n",
    "    # summarize results\n",
    "    summarize_results(scores)\n",
    " \n",
    "# run the experiment\n",
    "run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
