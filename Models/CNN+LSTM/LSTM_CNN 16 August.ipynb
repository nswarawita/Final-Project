{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c82473-1e97-4dc3-b404-c5926b20deaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19153030-7623-40fd-8c0a-c969bcb9dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7eb3bd-f350-47e1-9e71-6ee334e08c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated random seed is 468\n"
     ]
    }
   ],
   "source": [
    "# Initialise the random state\n",
    "num = random.randint(1, 500)\n",
    "\n",
    "torch.manual_seed(num)\n",
    "print(f\"The generated random seed is {num}\") #347"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bec4425-36e5-40c7-a35c-2dc247661b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_id</th>\n",
       "      <th>id</th>\n",
       "      <th>p_id</th>\n",
       "      <th>itr_id</th>\n",
       "      <th>prj_id</th>\n",
       "      <th>ppt_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>hand</th>\n",
       "      <th>clt_id</th>\n",
       "      <th>ch_01</th>\n",
       "      <th>ch_02</th>\n",
       "      <th>ch_03</th>\n",
       "      <th>ch_04</th>\n",
       "      <th>ch_05</th>\n",
       "      <th>ch_06</th>\n",
       "      <th>ch_07</th>\n",
       "      <th>ch_08</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_id      id  p_id  itr_id  prj_id  ppt_id  rating  hand  clt_id  \\\n",
       "0       1  132383    19     119     622      16       6     0      27   \n",
       "1       2  132383    19     119     622      16       6     0      27   \n",
       "2       3  132383    19     119     622      16       6     0      27   \n",
       "3       4  132383    19     119     622      16       6     0      27   \n",
       "4       5  132383    19     119     622      16       6     0      27   \n",
       "\n",
       "      ch_01     ch_02     ch_03     ch_04     ch_05     ch_06     ch_07  \\\n",
       "0  0.001062  0.003030  0.002932  0.006998  0.010902  0.016429  0.024816   \n",
       "1  0.001062  0.011202  0.002932  0.001948  0.002860  0.000817  0.015065   \n",
       "2  0.001062  0.003030  0.002932  0.001948  0.002860  0.014796  0.004439   \n",
       "3  0.001062  0.003030  0.006901  0.001948  0.002860  0.014796  0.005313   \n",
       "4  0.001062  0.003030  0.002932  0.001948  0.002860  0.014796  0.005313   \n",
       "\n",
       "      ch_08                timestamp  \n",
       "0  0.034724  2022-02-13 11:24:11.302  \n",
       "1  0.004675  2022-02-13 11:24:11.302  \n",
       "2  0.024374  2022-02-13 11:24:11.302  \n",
       "3  0.044074  2022-02-13 11:24:11.302  \n",
       "4  0.004675  2022-02-13 11:24:11.302  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the processed emg data\n",
    "emg_path = \"/Users/niharawarawita/Desktop/MSc Project/Data/EMG_data_collection/emg_combined_stats.csv\"\n",
    "emg_df = pd.read_csv(emg_path)\n",
    "emg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157053d6-3787-423d-a432-3d7fb8ae0294",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocess the emg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc77ca27-1650-4414-a120-51671ffc5dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_id</th>\n",
       "      <th>id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>project_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>hand</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>ch_01</th>\n",
       "      <th>ch_02</th>\n",
       "      <th>ch_03</th>\n",
       "      <th>ch_04</th>\n",
       "      <th>ch_05</th>\n",
       "      <th>ch_06</th>\n",
       "      <th>ch_07</th>\n",
       "      <th>ch_08</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>132383</td>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>622</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   new_id      id  participant_id  interaction_id  project_id  property_id  \\\n",
       "0       1  132383              19             119         622           16   \n",
       "1       2  132383              19             119         622           16   \n",
       "2       3  132383              19             119         622           16   \n",
       "3       4  132383              19             119         622           16   \n",
       "4       5  132383              19             119         622           16   \n",
       "\n",
       "   rating  hand  clothes_id     ch_01     ch_02     ch_03     ch_04     ch_05  \\\n",
       "0       6     0          27  0.001062  0.003030  0.002932  0.006998  0.010902   \n",
       "1       6     0          27  0.001062  0.011202  0.002932  0.001948  0.002860   \n",
       "2       6     0          27  0.001062  0.003030  0.002932  0.001948  0.002860   \n",
       "3       6     0          27  0.001062  0.003030  0.006901  0.001948  0.002860   \n",
       "4       6     0          27  0.001062  0.003030  0.002932  0.001948  0.002860   \n",
       "\n",
       "      ch_06     ch_07     ch_08                timestamp  \n",
       "0  0.016429  0.024816  0.034724  2022-02-13 11:24:11.302  \n",
       "1  0.000817  0.015065  0.004675  2022-02-13 11:24:11.302  \n",
       "2  0.014796  0.004439  0.024374  2022-02-13 11:24:11.302  \n",
       "3  0.014796  0.005313  0.044074  2022-02-13 11:24:11.302  \n",
       "4  0.014796  0.005313  0.004675  2022-02-13 11:24:11.302  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_df.rename(columns={'p_id': 'participant_id', 'itr_id': 'interaction_id',  'prj_id': 'project_id',  'ppt_id': 'property_id', 'clt_id': 'clothes_id'}, inplace=True)\n",
    "emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab4f6d2-d5fb-4e5f-8868-2c98574fe3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>hand</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>ch_01</th>\n",
       "      <th>ch_02</th>\n",
       "      <th>ch_03</th>\n",
       "      <th>ch_04</th>\n",
       "      <th>ch_05</th>\n",
       "      <th>ch_06</th>\n",
       "      <th>ch_07</th>\n",
       "      <th>ch_08</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.006998</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.016429</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>0.034724</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.011202</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.044074</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>119</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.014796</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  interaction_id  property_id  rating  hand  clothes_id  \\\n",
       "0              19             119           16       6     0          27   \n",
       "1              19             119           16       6     0          27   \n",
       "2              19             119           16       6     0          27   \n",
       "3              19             119           16       6     0          27   \n",
       "4              19             119           16       6     0          27   \n",
       "\n",
       "      ch_01     ch_02     ch_03     ch_04     ch_05     ch_06     ch_07  \\\n",
       "0  0.001062  0.003030  0.002932  0.006998  0.010902  0.016429  0.024816   \n",
       "1  0.001062  0.011202  0.002932  0.001948  0.002860  0.000817  0.015065   \n",
       "2  0.001062  0.003030  0.002932  0.001948  0.002860  0.014796  0.004439   \n",
       "3  0.001062  0.003030  0.006901  0.001948  0.002860  0.014796  0.005313   \n",
       "4  0.001062  0.003030  0.002932  0.001948  0.002860  0.014796  0.005313   \n",
       "\n",
       "      ch_08                timestamp  \n",
       "0  0.034724  2022-02-13 11:24:11.302  \n",
       "1  0.004675  2022-02-13 11:24:11.302  \n",
       "2  0.024374  2022-02-13 11:24:11.302  \n",
       "3  0.044074  2022-02-13 11:24:11.302  \n",
       "4  0.004675  2022-02-13 11:24:11.302  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_df.drop(['new_id', 'id', 'project_id'], axis=1, inplace=True)\n",
    "emg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75f89cb6-f5cc-4b9e-bf49-23c2aebaf9e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the timestamp to the datetime format\n",
    "emg_df['timestamp']= pd.to_datetime(emg_df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c020378-1343-4433-a392-f65a692d317b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the values in each df by ascending value of the timestamp\n",
    "emg_df.sort_values(by=['timestamp'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed299123-0402-4e82-b9fa-93e565c2294f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into hands 0 (left) and 1 (right)\n",
    "emg_0 = emg_df[emg_df.hand == 0]\n",
    "emg_1 = emg_df[emg_df.hand == 1]\n",
    "\n",
    "# Reset indexes\n",
    "emg_0.reset_index(inplace=True, drop = True)\n",
    "emg_1.reset_index(inplace=True, drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6225c3c9-ff37-4042-9528-24dfc0f7fbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interaction_time(df):\n",
    "    # Create a column for the starting time of each interaction \n",
    "    df['interaction_start_time'] = df['timestamp'].groupby(df['interaction_id']).transform('min')\n",
    "    # Create a column for the ending time of each interaction \n",
    "    df['interaction_end_time'] = df['timestamp'].groupby(df['interaction_id']).transform('max')\n",
    "    \n",
    "    df['interaction_duration'] = df['interaction_end_time'] - df['interaction_start_time']#.datetime.total_seconds()\n",
    "    df['interaction_duration'] = df['interaction_duration'].dt.total_seconds()\n",
    "    return df\n",
    "\n",
    "emg_0 = interaction_time(emg_0)\n",
    "emg_1 = interaction_time(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b3f1116-c870-41d1-b85b-466e03440739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def emg_get_15_seconds(interaction_id, emg_interaction_df, emg_df):\n",
    "    interaction_end_time = emg_interaction_df.iloc[0,16]\n",
    "    threshold = interaction_end_time - datetime.timedelta(0,16)\n",
    "\n",
    "    # Remove rows with interaction_id with a timestamp less than the threshold from the dfs\n",
    "    emg_df.drop(emg_df[(emg_df.interaction_id==interaction_id) & (emg_df.timestamp<=threshold)].index, inplace=True)\n",
    "    \n",
    "    # Drop the interaction_start_time and interaction_end_time for the dfs\n",
    "    emg_df.drop(['interaction_start_time', 'interaction_end_time', 'interaction_duration'], axis=1, inplace=True)\n",
    "\n",
    "    # Recalculate the columns\n",
    "    emg_df = interaction_time(emg_df)\n",
    "     \n",
    "    return emg_df\n",
    "\n",
    "emg_191_0 = emg_0[emg_0.interaction_id==191]\n",
    "emg_0 = emg_get_15_seconds(191, emg_191_0, emg_0) \n",
    "emg_196_0 = emg_0[emg_0.interaction_id==196]\n",
    "emg_0 = emg_get_15_seconds(196, emg_196_0, emg_0) \n",
    "\n",
    "emg_191_1 = emg_1[emg_1.interaction_id==191]\n",
    "emg_1 = emg_get_15_seconds(191, emg_191_1, emg_1)  \n",
    "emg_196_1 = emg_1[emg_1.interaction_id==196]\n",
    "emg_1 = emg_get_15_seconds(196, emg_196_1, emg_1)  \n",
    "emg_296_1 = emg_1[emg_1.interaction_id==296]\n",
    "emg_1 = emg_get_15_seconds(296, emg_296_1, emg_1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3734301f-6968-4800-82b2-0aaef677f2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_property_names_column(df):\n",
    "    df.insert(3, 'property_name', 'smoothness')\n",
    "    df.property_name[df['property_id'] == 13] = 'thickness'\n",
    "    df.property_name[df['property_id'] == 14] = 'warmth'\n",
    "    df.property_name[df['property_id'] == 15] = 'flexibility'\n",
    "    df.property_name[df['property_id'] == 16] = 'softness'\n",
    "    df.property_name[df['property_id'] == 17] = 'enjoyment'\n",
    "    return df\n",
    "\n",
    "emg_0 = add_property_names_column(emg_0)\n",
    "emg_1 = add_property_names_column(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56e96da1-e33e-4fea-844b-591dceae92e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emg_0 = emg_0[emg_0.property_name != 'enjoyment']\n",
    "emg_1 = emg_1[emg_1.property_name != 'enjoyment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a69dc269-bc36-4ccc-a247-bf9bb5058af7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def renumber_socks(df):\n",
    "    df.clothes_id[(df['clothes_id'] == 25) | (df['clothes_id'] == 31) | (df['clothes_id'] == 38) | (df['clothes_id'] == 44) | (df['clothes_id'] == 50) | (df['clothes_id'] == 56)] = 1\n",
    "    df.clothes_id[(df['clothes_id'] == 26) | (df['clothes_id'] == 32) | (df['clothes_id'] == 39) | (df['clothes_id'] == 45) | (df['clothes_id'] == 51) | (df['clothes_id'] == 57)] = 2\n",
    "    df.clothes_id[(df['clothes_id'] == 27) | (df['clothes_id'] == 33) | (df['clothes_id'] == 40) | (df['clothes_id'] == 46) | (df['clothes_id'] == 52) | (df['clothes_id'] == 58)] = 3\n",
    "    df.clothes_id[(df['clothes_id'] == 28) | (df['clothes_id'] == 34) | (df['clothes_id'] == 41) | (df['clothes_id'] == 47) | (df['clothes_id'] == 53) | (df['clothes_id'] == 59)] = 4\n",
    "    df.clothes_id[(df['clothes_id'] == 29) | (df['clothes_id'] == 35) | (df['clothes_id'] == 42) | (df['clothes_id'] == 48) | (df['clothes_id'] == 54) | (df['clothes_id'] == 60)] = 5\n",
    "    df.clothes_id[(df['clothes_id'] == 30) | (df['clothes_id'] == 36) | (df['clothes_id'] == 43) | (df['clothes_id'] == 49) | (df['clothes_id'] == 55) | (df['clothes_id'] == 61)] = 6\n",
    "    return df\n",
    "\n",
    "emg_0 = renumber_socks(emg_0)\n",
    "emg_1 = renumber_socks(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f51ed2a-1c5a-439c-863c-a56242ef2c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_classes_rating(df):\n",
    "    df.insert(5, 'rating_level', 'medium')\n",
    "    df.loc[df['rating'] > 5,'rating_level'] = 'high'\n",
    "    df.loc[df['rating'] < 3,'rating_level'] = 'low'\n",
    "    return df\n",
    "    \n",
    "emg_0 = combine_classes_rating(emg_0)\n",
    "emg_1 = combine_classes_rating(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b694d56d-eef3-41dc-a963-e44262aba520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def represent_rating_level_numerically(df):\n",
    "    df.insert(6, 'rating_level_num', 1)\n",
    "    df.loc[df['rating_level'] == 'medium','rating_level_num'] = 2\n",
    "    df.loc[df['rating_level'] == 'high','rating_level_num'] = 3\n",
    "    return df\n",
    "\n",
    "emg_0 = represent_rating_level_numerically(emg_0)\n",
    "emg_1 = represent_rating_level_numerically(emg_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd823992-19c5-4031-83d7-1fa9d9e2a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subwindows(df, num_subwindows=15):\n",
    "    \n",
    "    # Create a column with the subwindow numbers\n",
    "    df.insert(9, 'sub_window_num', num_subwindows)\n",
    "    for num in range(num_subwindows-1,0,-1):\n",
    "        df.sub_window_num[pd.to_datetime(df['timestamp']) <= pd.to_datetime(df['interaction_start_time']) + datetime.timedelta(0,num)] = num\n",
    "        \n",
    "    return df\n",
    "\n",
    "emg_0 = create_subwindows(emg_0, num_subwindows=15)\n",
    "emg_1 = create_subwindows(emg_1, num_subwindows=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1975e781-29d1-4e1f-9075-a840a24ebb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_emg(df):\n",
    "    column_names = ['ch_01','ch_02','ch_03','ch_04','ch_05','ch_06','ch_07','ch_08']\n",
    "    for col in column_names:\n",
    "        new_col_name = 'mean_'+col           \n",
    "        df[new_col_name] = df[col].groupby([df['interaction_id'], df['sub_window_num']]).transform('mean')\n",
    "    return df\n",
    "\n",
    "\n",
    "emg_0 = downsample_emg(emg_0)\n",
    "emg_1 = downsample_emg(emg_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc122011-d032-4b85-aa62-785a21d5ed6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emg_0_new = emg_0[['participant_id','clothes_id', 'property_id','property_name','interaction_id','hand','rating','rating_level','rating_level_num', 'sub_window_num', 'mean_ch_01','mean_ch_02','mean_ch_03','mean_ch_04','mean_ch_05','mean_ch_06','mean_ch_07','mean_ch_08']]\n",
    "emg_1_new = emg_1[['participant_id','clothes_id', 'property_id','property_name','interaction_id','hand','rating','rating_level','rating_level_num', 'sub_window_num', 'mean_ch_01','mean_ch_02','mean_ch_03','mean_ch_04','mean_ch_05','mean_ch_06','mean_ch_07','mean_ch_08']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adb93a3c-e1ff-49ca-8045-c2ccf751918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1307504, 18)\n",
      "(1307504, 18)\n"
     ]
    }
   ],
   "source": [
    "print(emg_0_new.shape)\n",
    "print(emg_0_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5e4aef6-ff3d-4513-9e3a-ff7f8118cbac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "emg_0_new.drop_duplicates(keep='first', inplace=True)\n",
    "emg_1_new.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "# Reset the indexes\n",
    "emg_0_new.reset_index(drop=True, inplace=True) \n",
    "emg_1_new.reset_index(drop=True, inplace=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb803388-d93c-4521-958a-9e4797fef677",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2694, 18)\n",
      "(2694, 18)\n"
     ]
    }
   ],
   "source": [
    "print(emg_0_new.shape)\n",
    "print(emg_0_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5db3c38-6cb2-499c-85d1-93005fdd4934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 15\n",
      "min: 9\n",
      "mean: 15.0\n",
      "std: 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='interaction_id'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df0 = emg_0_new.groupby('interaction_id')['sub_window_num'].nunique()\n",
    "print(f'max: {df0.max()}')\n",
    "print(f'min: {df0.min()}')\n",
    "print(f'mean: {round(df0.mean(),1)}')\n",
    "print(f'std: {round(df0.std(),1)}')\n",
    "df0.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "633521d3-0cf8-4aaa-8575-b41e38e000ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 15\n",
      "min: 9\n",
      "mean: 15.0\n",
      "std: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='interaction_id'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df1 = emg_1_new.groupby('interaction_id')['sub_window_num'].nunique()\n",
    "print(f'max: {df1.max()}')\n",
    "print(f'min: {df1.min()}')\n",
    "print(f'mean: {round(df1.mean(),1)}')\n",
    "print(f'std: {round(df1.std(),1)}')\n",
    "df1.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c3e678-dd0d-4d1f-81e8-5b3a39205c2c",
   "metadata": {},
   "source": [
    "### Create X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a47061-827b-45cb-be34-9490b0bf7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X(df):\n",
    "    dim1 = df.interaction_id.nunique()\n",
    "    #num_timestamps_per_interaction = df.groupby('interaction_id')['sub_window_num'].nunique()\n",
    "    dim2 = df.sub_window_num.nunique()\n",
    "        \n",
    "    X = np.zeros((dim1, dim2, 8)) \n",
    "\n",
    "    itr_id_lst = df.interaction_id.unique().tolist()\n",
    "\n",
    "    for i in range(len(itr_id_lst)):\n",
    "        itr_id = itr_id_lst[i]\n",
    "        itr_id_df = df[df.interaction_id==itr_id]       \n",
    "        \n",
    "        for j in range(itr_id_df.shape[0]):\n",
    "            starting_index = 10\n",
    "            vals_arr = itr_id_df.iloc[j,starting_index:].values\n",
    "            X[i,j] = vals_arr\n",
    "    \n",
    "    X_tensor = torch.Tensor(X)    \n",
    "    return X_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c95e4b49-e025-4fd4-9adc-64e513ce5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y(df, predicting_feature = 'property_id'):\n",
    "    # Create a dataset with only the required columns\n",
    "    df2 = df[['participant_id', 'clothes_id', 'property_id', 'rating_level_num']]\n",
    "\n",
    "    # Remove duplicates\n",
    "    df2.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # Reset the indexes\n",
    "    df2.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    y_test = df2[predicting_feature].values\n",
    "    y_test = y_test - 12\n",
    "    \n",
    "    y_test = torch.Tensor(y_test)    \n",
    "    y_test = y_test.type(torch.LongTensor)\n",
    "    \n",
    "    return y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3566b-4103-4d96-9277-de91705cba4d",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9385aed2-d60b-4793-b01a-8e542cd979b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([180, 15, 8])\n",
      "torch.Size([180, 15, 6])\n",
      "torch.Size([180, 15, 6])\n",
      "torch.Size([180, 15, 3])\n",
      "=================\n",
      "torch.Size([180, 180])\n",
      "torch.Size([180, 20])\n",
      "torch.Size([180, 5])\n"
     ]
    }
   ],
   "source": [
    "input1 = torch.rand(180,15,8)\n",
    "input2 = torch.rand(180,15,6*2)\n",
    "conv1 = nn.Conv1d(in_channels=15, out_channels=15, kernel_size=3, stride=1, padding=0, groups=15) # Change kernel size to 3\n",
    "pool = nn.MaxPool1d(1, 1) # Change kernel size to 1 and stride to 1\n",
    "rnn = nn.LSTM(6, 3, 1, batch_first=True)\n",
    "h0 = torch.randn(1, 15, 6)\n",
    "c0 = torch.randn(1, 15, 6)\n",
    "fc1 = nn.Linear(15 * 6 * 2, 20)\n",
    "fc2 = nn.Linear(20, 5)\n",
    "\n",
    "print(input1.shape)\n",
    "x=conv1(input1)\n",
    "print(x.shape)\n",
    "\n",
    "x=pool(x)\n",
    "print(x.shape)\n",
    "\n",
    "x, (hn,cn) = rnn(x)\n",
    "print(x.shape)\n",
    "print('=================')\n",
    "y = torch.flatten(input2, 1)\n",
    "print(y.shape)\n",
    "y = fc1(y)\n",
    "print(y.shape)\n",
    "y = fc2(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c30f790-676b-4666-b55c-8aeeda9e8d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.001, 0.01, 0.1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.001,0.01,0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7326e1f7-f538-49e4-8a80-90bab69c6545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_train(df, predicting_feature = 'property_id'):\n",
    "    # Create a dataset with only the required columns\n",
    "    df2 = df[['participant_id', 'clothes_id', 'property_id', 'rating_level_num']]\n",
    "\n",
    "    # Remove duplicates\n",
    "    df2.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # Reset the indexes\n",
    "    df2.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    ## Create y train\n",
    "    # CreatE an instance of a one-hot-encoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Perform one-hot encoding on the specified column \n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(df2[[predicting_feature]]).toarray())\n",
    "    \n",
    "    # Convert to a numpy array\n",
    "    y_train = encoder_df.to_numpy()\n",
    "    \n",
    "    # Convert to a tensor\n",
    "    y_train = torch.Tensor(y_train)\n",
    "  \n",
    "    return y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "189cb1c0-ad2d-4bc0-9922-8c1fa5ee995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=15, out_channels=15, kernel_size=3, stride=1, padding=0, groups=15) # Change kernel size to 3\n",
    "        self.pool = nn.MaxPool1d(1, 1) # Change kernel size to 1 and stride to 1\n",
    "        self.rnn = nn.LSTM(6, 3, 1, batch_first=True)\n",
    "        #self.h0 = torch.randn(1, 50, 7)\n",
    "        #self.c0 = torch.randn(1, 50, 7)\n",
    "        #self.fc1 = nn.Linear(15 * 3 * 2, 20)\n",
    "        self.fc1 = nn.Linear(15 * 3 * 2, 5)\n",
    "        \n",
    "           \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.pool(F.relu(self.conv1(x1))) # Use tanh instead?\n",
    "        x2 = self.pool(F.relu(self.conv1(x2))) # Use tanh instead?\n",
    "        \n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        x1, (hn, cn) = self.rnn(x1) #, (self.h0, self.c0)\n",
    "        #x1 = F.tanh(x1)\n",
    "        x2, (hm, cm) = self.rnn(x2) # (self.h0, self.c0)\n",
    "        #x2 = F.tanh(x2)\n",
    "        \n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc1(x), dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1bdcb131-9094-4488-b583-c1791c3f8771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LSTM(\n",
      "  (conv1): Conv1d(15, 15, kernel_size=(3,), stride=(1,), groups=15)\n",
      "  (pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  (rnn): LSTM(6, 3, batch_first=True)\n",
      "  (fc1): Linear(in_features=90, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = CNN_LSTM()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc51c87b-5a22-4f42-ad93-5e9bebd3ef48",
   "metadata": {},
   "source": [
    "def plot_loss(num_epochs, loss_vals):\n",
    "    plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), loss_vals)\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5306f6f3-d6d4-462d-aade-a46f705d9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model_for_fold(train_dataloader, val_dataloader, num_epochs, learning_rate):\n",
    "\n",
    "    # Model\n",
    "    train_model = CNN_LSTM()\n",
    "\n",
    "    # Loss and Optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.7)\n",
    "\n",
    "    best_avg_loss = np.inf\n",
    "    best_model = None\n",
    "    best_model_epoch_num = np.inf\n",
    "    #avg_loss_lst = []\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        #Set the model in training mode\n",
    "        train_model.train()\n",
    "\n",
    "        # Initialise the total training and validation loss\n",
    "        total_train_loss = 0\n",
    "        total_val_loss = 0\n",
    "        avg_loss = 0\n",
    "        count = 0\n",
    "\n",
    "        #running_loss = 0.0\n",
    "        for i, train_data in enumerate(train_dataloader, 0):\n",
    "            count += 1\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "            train_input1, train_input2, train_labels = train_data\n",
    "\n",
    "            #train_labels = train_labels.type(torch.LongTensor)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            train_preds = train_model(train_input1, train_input2)\n",
    "            #print(train_labels)#\n",
    "\n",
    "            train_loss = criterion(train_preds, train_labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training loss\n",
    "            total_train_loss += train_loss.item()\n",
    "\n",
    "        # Switch off auto grad for evaluation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set the model in evaluation mode\n",
    "            train_model.eval()\n",
    "\n",
    "            for j, val_data in enumerate(val_dataloader, 0):\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "                val_input1, val_input2, val_labels = val_data\n",
    "\n",
    "                #val_labels = val_labels.type(torch.LongTensor)\n",
    "\n",
    "                val_preds = train_model(val_input1, val_input2)\n",
    "\n",
    "                # Update validation loss\n",
    "                val_loss = criterion(val_preds, val_labels)\n",
    "\n",
    "                total_val_loss += val_loss.item()\n",
    "                \n",
    "        avg_training_loss = total_train_loss / count\n",
    "\n",
    "        avg_loss = (avg_training_loss + total_val_loss) / 2\n",
    "        \n",
    "        \n",
    "        #if epoch % 5 == 0:    # print every 2000 mini-batches\n",
    "        print(f'epoch {epoch+1}: training loss = {round(avg_training_loss,4)}, validation loss = {round(total_val_loss,4)}, average loss = {round(avg_loss,4)}')\n",
    "            # print('[%d, %5d] loss: %.3f' %\n",
    "            #    (epoch + 1, i + 1, running_loss / 2000))\n",
    "           # running_loss = 0.0\n",
    "        #avg_loss_lst.append(avg_loss)\n",
    "        \n",
    "        #print(f'epoch {epoch+1}: train loss = {round(total_train_loss,2)}, val loss = {round(total_val_loss,2)}, average loss = {round(avg_loss,2)}')\n",
    "\n",
    "        if avg_loss < best_avg_loss:\n",
    "            best_model_epoch_num = epoch\n",
    "            best_avg_loss = avg_loss\n",
    "            best_model = train_model.state_dict()\n",
    "            #best_model_params = list(model.parameters())\n",
    "\n",
    "    #print(f'The model with the lowest average loss ({round(best_avg_loss,2)}) occured in epoch {best_model_epoch_num+1}')\n",
    "\n",
    "    return best_avg_loss, best_model #, avg_loss_lst, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ebec5b16-ca72-4ad9-b44e-0a71f58c5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_lst(lr_lst, num_epochs_lst):\n",
    "    lst = []\n",
    "    for ele1 in lr_lst:\n",
    "        for ele2 in num_epochs_lst:\n",
    "            lst.append((ele1,ele2))\n",
    "    return lst   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be3f1f75-d47a-42d0-8793-072ef7a149c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9446081f-d77b-4ae2-892a-22922c840fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_LOS0CV(data_0, data_1, num_folds=5, predicting_feature='property_id', num_epoch_lst=[5,10,20], learning_rate_lst=[0.001,0.01,0.1], random_state=num): #, num_inner_folds=5\n",
    "\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(num)\n",
    "    \n",
    "    for cloth_id in range(1,7): \n",
    "        print(f'LEAVING SOCK {cloth_id} OUT:')\n",
    "        # Split the data into training and testing\n",
    "        training_data_0 = data_0[data_0.clothes_id != cloth_id] \n",
    "        training_data_1 = data_1[data_1.clothes_id != cloth_id] \n",
    "        testing_data_0 = data_0[data_0.clothes_id == cloth_id] \n",
    "        testing_data_1 = data_1[data_1.clothes_id == cloth_id] \n",
    "\n",
    "        # Data preparation\n",
    "        X_train_0 = create_X(training_data_0)\n",
    "        X_train_1 = create_X(training_data_1)        \n",
    "        y_train = create_y(training_data_0, predicting_feature = 'property_id')\n",
    "        X_test_0 = create_X(testing_data_0) \n",
    "        X_test_1 = create_X(testing_data_1)\n",
    "        y_test = create_y(testing_data_0, predicting_feature = 'property_id')\n",
    "        \n",
    " \n",
    "        # Create the datasets and dataloaders\n",
    "        train_dataset = TensorDataset(X_train_0, X_train_1, y_train) \n",
    "        \n",
    "        test_dataset = TensorDataset(X_test_0, X_test_1, y_test) \n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, num_workers=2, batch_size=30)\n",
    "        \n",
    "            \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_folds, shuffle=True, random_state=num)\n",
    "        \n",
    "        # Create a combined lst\n",
    "        combo_lst = create_combined_lst(num_epoch_lst, learning_rate_lst)\n",
    "        \n",
    "        min_avg_loss_subject = np.inf\n",
    "        best_model_subject = None\n",
    "        best_params_subject = None\n",
    "\n",
    "        for fold, (train_ids, val_ids) in enumerate(cv_inner.split(train_dataset)):\n",
    "            print(f'FOLD {fold+1}:')\n",
    "            \n",
    "            min_avg_loss_fold = np.inf\n",
    "            best_model_fold = None\n",
    "            best_params_fold = None\n",
    "            avg_loss_dict = {}\n",
    "            \n",
    "            # Sample elements randomly from a given list of ids, no replacement.\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids) # The ids are the same for both\n",
    "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "            # Define data loaders for training and testing data in this fold\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=train_subsampler)\n",
    "            val_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=val_subsampler)\n",
    "            \n",
    "\n",
    "            for combo in combo_lst:\n",
    "                print(f'lr={combo[1]}, num epochs={combo[0]}:')\n",
    "                min_avg_loss_combo, best_model_combo = find_best_model_for_fold(train_dataloader, val_dataloader, combo[0], combo[1])\n",
    "                print('-------------------')\n",
    "                #if combo[0] not in avg_loss_dict.keys():\n",
    "                #    avg_loss_dict[combo[0]] = [avg_loss_lst]\n",
    "                #else:\n",
    "                 #   avg_loss_dict[combo[0]].append(avg_loss_lst)\n",
    "                 \n",
    "                if min_avg_loss_combo < min_avg_loss_fold:\n",
    "                    min_avg_loss_fold = min_avg_loss_combo\n",
    "                    best_model_fold = best_model_combo\n",
    "                    best_params_fold = combo\n",
    "                    \n",
    "            if min_avg_loss_fold < min_avg_loss_subject:\n",
    "                min_avg_loss_subject = min_avg_loss_fold\n",
    "                best_model_subject = best_model_fold\n",
    "                best_params_subject = best_params_fold\n",
    "                \n",
    "            print(f'The best model for fold {fold+1} has an average loss of {round(min_avg_loss_fold,1)} and has parameters: learning rate = {best_params_fold[1]}, num_epochs = {best_params_fold[0]}')\n",
    "                \n",
    "           # for key in avg_loss_dict.keys():                             \n",
    "            #    fig = plt.figure(f\"Sock {cloth_id}, fold {fold+1}, num_epochs = {key}\")\n",
    "            #    for lst_num in range(len(avg_loss_dict[key])):                    \n",
    "            #        plt.plot(np.linspace(1, key, key).astype(int), avg_loss_dict[key][lst_num])\n",
    "             #   plt.title(f\"Training loss for Sock {cloth_id}, fold {fold+1}, num_epochs = {key}\")\n",
    "              #  plt.legend(['lr=0.001', 'lr=0.01', 'lr=0.1'])\n",
    "            \n",
    "            #print(f'The best model for fold {fold+1} has an average loss of {round(min_avg_loss_fold,1)} and has parameters: learning rate = {best_params_fold[0]}, num_epochs = {best_params_fold[1]}')\n",
    "        print(f'The model with the least average loss ({round(min_avg_loss_subject,1)}) has parameters: learning rate = {best_params_subject[0]}, num_epochs = {best_params_subject[1]}')\n",
    "        \n",
    "        # save trained model - this is the last model saved \n",
    "        name = 'model_sock_'+str(cloth_id)+'.pt'\n",
    "        torch.save(best_model_subject, name)\n",
    "        \n",
    "        test_model = CNN_LSTM()\n",
    "        test_model.load_state_dict(torch.load(name))\n",
    "        \n",
    "        dataiter = iter(test_dataloader) \n",
    "        test_input1, test_input2, test_labels = dataiter.next()\n",
    "    \n",
    "        test_preds = test_model(test_input1, test_input2)\n",
    "        _, test_predicted = torch.max(test_preds, 1)\n",
    "        \n",
    "        test_predicted_np = test_predicted.numpy()\n",
    "        test_labels_np = test_labels.numpy()        \n",
    "\n",
    "        conf_mat = confusion_matrix(test_labels_np, test_predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "        macro_f1_score = f1_score(test_labels_np, test_predicted_np, average='macro') \n",
    "        micro_f1_score = f1_score(test_labels_np, test_predicted_np, average='micro')  \n",
    "        acc = accuracy_score(test_labels_np, test_predicted_np)\n",
    "\n",
    "        print(f\"Leaving sock {cloth_id} out\")\n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        print(f\"(3) macro F1 score = {round(macro_f1_score,2)}\")    \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "        \n",
    "        print('--------------------------------')\n",
    "  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fd9ccdba-1612-4709-8da1-1009868e6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN_LOS0CV1(data_0, data_1, num_folds=5, predicting_feature='property_id', num_epoch_lst=[5,10,20], learning_rate_lst=[0.001,0.01,0.1], random_state=num): #, num_inner_folds=5\n",
    "\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(num)\n",
    "    \n",
    "    for cloth_id in range(1,7): \n",
    "        print(f'LEAVING SOCK {cloth_id} OUT:')\n",
    "        # Split the data into training and testing\n",
    "        training_data_0 = data_0[data_0.clothes_id != cloth_id] \n",
    "        training_data_1 = data_1[data_1.clothes_id != cloth_id] \n",
    "        testing_data_0 = data_0[data_0.clothes_id == cloth_id] \n",
    "        testing_data_1 = data_1[data_1.clothes_id == cloth_id] \n",
    "\n",
    "        # Data preparation\n",
    "        X_train_0 = create_X(training_data_0)\n",
    "        X_train_1 = create_X(training_data_1)        \n",
    "        y_train = create_y_train(training_data_0, predicting_feature = 'property_id')\n",
    "        X_test_0 = create_X(testing_data_0) \n",
    "        X_test_1 = create_X(testing_data_1)\n",
    "        y_test = create_y(testing_data_0, predicting_feature = 'property_id')\n",
    "        \n",
    " \n",
    "        # Create the datasets and dataloaders\n",
    "        train_dataset = TensorDataset(X_train_0, X_train_1, y_train) \n",
    "        \n",
    "        test_dataset = TensorDataset(X_test_0, X_test_1, y_test) \n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, num_workers=2, batch_size=30)\n",
    "        \n",
    "            \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_folds, shuffle=True, random_state=num)\n",
    "        \n",
    "        # Create a combined lst\n",
    "        combo_lst = create_combined_lst(num_epoch_lst, learning_rate_lst)\n",
    "        \n",
    "        min_avg_loss_subject = np.inf\n",
    "        best_model_subject = None\n",
    "        best_params_subject = None\n",
    "\n",
    "        for fold, (train_ids, val_ids) in enumerate(cv_inner.split(train_dataset)):\n",
    "            print(f'FOLD {fold+1}:')\n",
    "            #print()\n",
    "            print(train_ids)\n",
    "            print(val_ids)\n",
    "            \n",
    "            min_avg_loss_fold = np.inf\n",
    "            best_model_fold = None\n",
    "            best_params_fold = None\n",
    "            avg_loss_dict = {}\n",
    "            \n",
    "            # Sample elements randomly from a given list of ids, no replacement.\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids) # The ids are the same for both\n",
    "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "            # Define data loaders for training and testing data in this fold\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=train_subsampler, batch_size=10)\n",
    "            val_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=val_subsampler, batch_size=50)\n",
    "            \n",
    "\n",
    "            for combo in combo_lst:\n",
    "                print(f'lr={combo[1]}, num epochs={combo[0]}:')\n",
    "                min_avg_loss_combo, best_model_combo = find_best_model_for_fold(train_dataloader, val_dataloader, combo[0], combo[1])\n",
    "                print('-------------------')\n",
    "                #if combo[0] not in avg_loss_dict.keys():\n",
    "                #    avg_loss_dict[combo[0]] = [avg_loss_lst]\n",
    "                #else:\n",
    "                 #   avg_loss_dict[combo[0]].append(avg_loss_lst)\n",
    "                 \n",
    "                if min_avg_loss_combo < min_avg_loss_fold:\n",
    "                    min_avg_loss_fold = min_avg_loss_combo\n",
    "                    best_model_fold = best_model_combo\n",
    "                    best_params_fold = combo\n",
    "                    \n",
    "            if min_avg_loss_fold < min_avg_loss_subject:\n",
    "                min_avg_loss_subject = min_avg_loss_fold\n",
    "                best_model_subject = best_model_fold\n",
    "                best_params_subject = best_params_fold\n",
    "                \n",
    "            print(f'The best model for fold {fold+1} has an average loss of {round(min_avg_loss_fold,1)} and has parameters: learning rate = {best_params_fold[1]}, num_epochs = {best_params_fold[0]}')\n",
    "                \n",
    "           # for key in avg_loss_dict.keys():                             \n",
    "            #    fig = plt.figure(f\"Sock {cloth_id}, fold {fold+1}, num_epochs = {key}\")\n",
    "            #    for lst_num in range(len(avg_loss_dict[key])):                    \n",
    "            #        plt.plot(np.linspace(1, key, key).astype(int), avg_loss_dict[key][lst_num])\n",
    "             #   plt.title(f\"Training loss for Sock {cloth_id}, fold {fold+1}, num_epochs = {key}\")\n",
    "              #  plt.legend(['lr=0.001', 'lr=0.01', 'lr=0.1'])\n",
    "            \n",
    "            #print(f'The best model for fold {fold+1} has an average loss of {round(min_avg_loss_fold,1)} and has parameters: learning rate = {best_params_fold[0]}, num_epochs = {best_params_fold[1]}')\n",
    "        print(f'The model with the least average loss ({round(min_avg_loss_subject,1)}) has parameters: learning rate = {best_params_subject[0]}, num_epochs = {best_params_subject[1]}')\n",
    "        \n",
    "        # save trained model - this is the last model saved \n",
    "        name = 'model_sock_'+str(cloth_id)+'.pt'\n",
    "        torch.save(best_model_subject, name)\n",
    "        \n",
    "        test_model = CNN_LSTM()\n",
    "        test_model.load_state_dict(torch.load(name))\n",
    "        \n",
    "        dataiter = iter(test_dataloader) \n",
    "        test_input1, test_input2, test_labels = dataiter.next()\n",
    "    \n",
    "        test_preds = test_model(test_input1, test_input2)\n",
    "        \n",
    "        test_preds_np = test_preds.detach().numpy()\n",
    "        test_predicted_np = np.argmax(test_preds_np, axis = 1)\n",
    "        #_, test_predicted = torch.max(test_preds, 1)\n",
    "        \n",
    "        #test_predicted_np = test_predicted.numpy()\n",
    "        test_labels_np = test_labels.numpy()        \n",
    "\n",
    "        conf_mat = confusion_matrix(test_labels_np, test_predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "        macro_f1_score = f1_score(test_labels_np, test_predicted_np, average='macro') \n",
    "        micro_f1_score = f1_score(test_labels_np, test_predicted_np, average='micro')  \n",
    "        acc = accuracy_score(test_labels_np, test_predicted_np)\n",
    "\n",
    "        print(f\"Leaving sock {cloth_id} out\")\n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        print(f\"(3) macro F1 score = {round(macro_f1_score,2)}\")    \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "        \n",
    "        print('--------------------------------')\n",
    "  \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d2e976e9-9b76-4a12-9d4f-62227a914cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'softness'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = emg_0_new[['interaction_id', 'clothes_id','property_name']]\n",
    "df = df[df.clothes_id!=1]\n",
    "df.drop_duplicates(keep='first', inplace=True)\n",
    "#emg_1_new.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "\n",
    "lst = df.property_name.to_list()\n",
    "lst[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bcad19f0-bba9-4be7-8794-c7905a310980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11, softness\n",
      "17, flexibility\n",
      "31, smoothness\n",
      "37, thickness\n",
      "47, warmth\n",
      "48, smoothness\n",
      "50, thickness\n",
      "52, flexibility\n",
      "63, softness\n",
      "66, warmth\n",
      "68, warmth\n",
      "69, smoothness\n",
      "74, softness\n",
      "84, flexibility\n",
      "92, thickness\n",
      "97, warmth\n",
      "98, thickness\n",
      "100, softness\n",
      "104, smoothness\n",
      "113, flexibility\n",
      "121, softness\n",
      "122, thickness\n",
      "126, flexibility\n",
      "129, smoothness\n",
      "133, warmth\n",
      "134, warmth\n",
      "135, softness\n",
      "141, thickness\n",
      "143, smoothness\n",
      "149, flexibility\n"
     ]
    }
   ],
   "source": [
    "lst_2 = [ 11,  17,  31,  37,  47,  48,  50,  52,  63,  66,  68,  69,  74,  84,  92,  97,  98, 100, 104, 113, 121, 122, 126, 129, 133, 134, 135, 141, 143, 149]\n",
    "for i in range(len(lst_2)):\n",
    "    print(f'{lst_2[i]}, {lst[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71e59a19-7d51-40f7-9a34-1710213f6d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_name</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>hand</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_level</th>\n",
       "      <th>rating_level_num</th>\n",
       "      <th>sub_window_num</th>\n",
       "      <th>mean_ch_01</th>\n",
       "      <th>mean_ch_02</th>\n",
       "      <th>mean_ch_03</th>\n",
       "      <th>mean_ch_04</th>\n",
       "      <th>mean_ch_05</th>\n",
       "      <th>mean_ch_06</th>\n",
       "      <th>mean_ch_07</th>\n",
       "      <th>mean_ch_08</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.006640</td>\n",
       "      <td>0.009395</td>\n",
       "      <td>0.023830</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.020056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>0.017228</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.007686</td>\n",
       "      <td>0.014378</td>\n",
       "      <td>0.016086</td>\n",
       "      <td>0.019061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>0.007627</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.009618</td>\n",
       "      <td>0.021827</td>\n",
       "      <td>0.016003</td>\n",
       "      <td>0.017120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.005384</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.007886</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>0.014199</td>\n",
       "      <td>0.014924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>high</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.014063</td>\n",
       "      <td>0.011389</td>\n",
       "      <td>0.007741</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.007504</td>\n",
       "      <td>0.011997</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>0.018028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  clothes_id  property_id property_name  interaction_id  \\\n",
       "0              19           3           16      softness             119   \n",
       "1              19           3           16      softness             119   \n",
       "2              19           3           16      softness             119   \n",
       "3              19           3           16      softness             119   \n",
       "4              19           3           16      softness             119   \n",
       "\n",
       "   hand  rating rating_level  rating_level_num  sub_window_num  mean_ch_01  \\\n",
       "0     0       6         high                 3               1    0.012167   \n",
       "1     0       6         high                 3               2    0.019790   \n",
       "2     0       6         high                 3               3    0.012231   \n",
       "3     0       6         high                 3               4    0.009712   \n",
       "4     0       6         high                 3               5    0.014063   \n",
       "\n",
       "   mean_ch_02  mean_ch_03  mean_ch_04  mean_ch_05  mean_ch_06  mean_ch_07  \\\n",
       "0    0.008337    0.007780    0.006640    0.009395    0.023830    0.015122   \n",
       "1    0.017228    0.008390    0.006409    0.007686    0.014378    0.016086   \n",
       "2    0.009103    0.007627    0.006512    0.009618    0.021827    0.016003   \n",
       "3    0.005384    0.005342    0.004616    0.007886    0.020806    0.014199   \n",
       "4    0.011389    0.007741    0.006422    0.007504    0.011997    0.014111   \n",
       "\n",
       "   mean_ch_08  \n",
       "0    0.020056  \n",
       "1    0.019061  \n",
       "2    0.017120  \n",
       "3    0.014924  \n",
       "4    0.018028  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emg_0_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "acdbea9f-7c9d-4391-bd32-0e211b4419f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAVING SOCK 1 OUT:\n",
      "FOLD 1:\n",
      "[  0   1   2   3   4   5   6   7   9  10  12  13  14  15  16  18  19  20\n",
      "  22  23  24  26  27  29  30  32  33  34  35  36  39  41  42  44  45  46\n",
      "  49  51  53  54  55  56  57  58  60  61  62  64  65  67  70  71  72  73\n",
      "  75  77  78  79  80  82  83  86  87  88  89  91  95  96  99 101 102 103\n",
      " 105 106 107 109 110 112 114 115 118 119 120 123 124 125 127 128 130 131\n",
      " 132 136 138 139 140 142 145 146 147 148]\n",
      "[  8  11  17  21  25  28  31  37  38  40  43  47  48  50  52  59  63  66\n",
      "  68  69  74  76  81  84  85  90  92  93  94  97  98 100 104 108 111 113\n",
      " 116 117 121 122 126 129 133 134 135 137 141 143 144 149]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6112, validation loss = 1.6076, average loss = 1.6094\n",
      "-------------------\n",
      "The best model for fold 1 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 2:\n",
      "[  0   1   2   3   5   8   9  11  15  17  18  19  20  21  23  24  25  27\n",
      "  28  31  36  37  38  39  40  43  47  48  50  51  52  56  58  59  60  61\n",
      "  63  66  67  68  69  70  71  74  75  76  77  80  81  82  84  85  86  87\n",
      "  90  91  92  93  94  96  97  98  99 100 101 102 104 105 106 107 108 110\n",
      " 111 113 114 115 116 117 118 119 120 121 122 124 126 127 129 130 133 134\n",
      " 135 136 137 139 140 141 143 144 145 149]\n",
      "[  4   6   7  10  12  13  14  16  22  26  29  30  32  33  34  35  41  42\n",
      "  44  45  46  49  53  54  55  57  62  64  65  72  73  78  79  83  88  89\n",
      "  95 103 109 112 123 125 128 131 132 138 142 146 147 148]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6082, validation loss = 1.6159, average loss = 1.612\n",
      "-------------------\n",
      "The best model for fold 2 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 3:\n",
      "[  4   6   7   8  10  11  12  13  14  16  17  21  22  25  26  28  29  30\n",
      "  31  32  33  34  35  37  38  40  41  42  43  44  45  46  47  48  49  50\n",
      "  52  53  54  55  57  59  62  63  64  65  66  68  69  72  73  74  76  78\n",
      "  79  81  83  84  85  88  89  90  92  93  94  95  97  98 100 103 104 108\n",
      " 109 111 112 113 116 117 121 122 123 125 126 128 129 131 132 133 134 135\n",
      " 137 138 141 142 143 144 146 147 148 149]\n",
      "[  0   1   2   3   5   9  15  18  19  20  23  24  27  36  39  51  56  58\n",
      "  60  61  67  70  71  75  77  80  82  86  87  91  96  99 101 102 105 106\n",
      " 107 110 114 115 118 119 120 124 127 130 136 139 140 145]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.608, validation loss = 1.6133, average loss = 1.6106\n",
      "-------------------\n",
      "The best model for fold 3 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "The model with the least average loss (1.6) has parameters: learning rate = 1, num_epochs = 0.05\n",
      "Leaving sock 1 out\n",
      "(1) Confusion matrix:\n",
      " [[0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]]\n",
      "(2) micro F1 score = 0.2\n",
      "(3) macro F1 score = 0.07\n",
      "(4) Percentage Classification accuracy = 20.0%\n",
      "--------------------------------\n",
      "LEAVING SOCK 2 OUT:\n",
      "FOLD 1:\n",
      "[  0   1   2   3   4   5   6   7   9  10  12  13  14  15  16  18  19  20\n",
      "  22  23  24  26  27  29  30  32  33  34  35  36  39  41  42  44  45  46\n",
      "  49  51  53  54  55  56  57  58  60  61  62  64  65  67  70  71  72  73\n",
      "  75  77  78  79  80  82  83  86  87  88  89  91  95  96  99 101 102 103\n",
      " 105 106 107 109 110 112 114 115 118 119 120 123 124 125 127 128 130 131\n",
      " 132 136 138 139 140 142 145 146 147 148]\n",
      "[  8  11  17  21  25  28  31  37  38  40  43  47  48  50  52  59  63  66\n",
      "  68  69  74  76  81  84  85  90  92  93  94  97  98 100 104 108 111 113\n",
      " 116 117 121 122 126 129 133 134 135 137 141 143 144 149]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6104, validation loss = 1.6094, average loss = 1.6099\n",
      "-------------------\n",
      "The best model for fold 1 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 2:\n",
      "[  0   1   2   3   5   8   9  11  15  17  18  19  20  21  23  24  25  27\n",
      "  28  31  36  37  38  39  40  43  47  48  50  51  52  56  58  59  60  61\n",
      "  63  66  67  68  69  70  71  74  75  76  77  80  81  82  84  85  86  87\n",
      "  90  91  92  93  94  96  97  98  99 100 101 102 104 105 106 107 108 110\n",
      " 111 113 114 115 116 117 118 119 120 121 122 124 126 127 129 130 133 134\n",
      " 135 136 137 139 140 141 143 144 145 149]\n",
      "[  4   6   7  10  12  13  14  16  22  26  29  30  32  33  34  35  41  42\n",
      "  44  45  46  49  53  54  55  57  62  64  65  72  73  78  79  83  88  89\n",
      "  95 103 109 112 123 125 128 131 132 138 142 146 147 148]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6107, validation loss = 1.6078, average loss = 1.6092\n",
      "-------------------\n",
      "The best model for fold 2 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 3:\n",
      "[  4   6   7   8  10  11  12  13  14  16  17  21  22  25  26  28  29  30\n",
      "  31  32  33  34  35  37  38  40  41  42  43  44  45  46  47  48  49  50\n",
      "  52  53  54  55  57  59  62  63  64  65  66  68  69  72  73  74  76  78\n",
      "  79  81  83  84  85  88  89  90  92  93  94  95  97  98 100 103 104 108\n",
      " 109 111 112 113 116 117 121 122 123 125 126 128 129 131 132 133 134 135\n",
      " 137 138 141 142 143 144 146 147 148 149]\n",
      "[  0   1   2   3   5   9  15  18  19  20  23  24  27  36  39  51  56  58\n",
      "  60  61  67  70  71  75  77  80  82  86  87  91  96  99 101 102 105 106\n",
      " 107 110 114 115 118 119 120 124 127 130 136 139 140 145]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6087, validation loss = 1.6124, average loss = 1.6105\n",
      "-------------------\n",
      "The best model for fold 3 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "The model with the least average loss (1.6) has parameters: learning rate = 1, num_epochs = 0.05\n",
      "Leaving sock 2 out\n",
      "(1) Confusion matrix:\n",
      " [[0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]]\n",
      "(2) micro F1 score = 0.2\n",
      "(3) macro F1 score = 0.07\n",
      "(4) Percentage Classification accuracy = 20.0%\n",
      "--------------------------------\n",
      "LEAVING SOCK 3 OUT:\n",
      "FOLD 1:\n",
      "[  0   1   2   3   4   5   6   7   9  10  12  13  14  15  16  18  19  20\n",
      "  22  23  24  26  27  29  30  32  33  34  35  36  39  41  42  44  45  46\n",
      "  49  51  53  54  55  56  57  58  60  61  62  64  65  67  70  71  72  73\n",
      "  75  77  78  79  80  82  83  86  87  88  89  91  95  96  99 101 102 103\n",
      " 105 106 107 109 110 112 114 115 118 119 120 123 124 125 127 128 130 131\n",
      " 132 136 138 139 140 142 145 146 147 148]\n",
      "[  8  11  17  21  25  28  31  37  38  40  43  47  48  50  52  59  63  66\n",
      "  68  69  74  76  81  84  85  90  92  93  94  97  98 100 104 108 111 113\n",
      " 116 117 121 122 126 129 133 134 135 137 141 143 144 149]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6102, validation loss = 1.6089, average loss = 1.6096\n",
      "-------------------\n",
      "The best model for fold 1 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 2:\n",
      "[  0   1   2   3   5   8   9  11  15  17  18  19  20  21  23  24  25  27\n",
      "  28  31  36  37  38  39  40  43  47  48  50  51  52  56  58  59  60  61\n",
      "  63  66  67  68  69  70  71  74  75  76  77  80  81  82  84  85  86  87\n",
      "  90  91  92  93  94  96  97  98  99 100 101 102 104 105 106 107 108 110\n",
      " 111 113 114 115 116 117 118 119 120 121 122 124 126 127 129 130 133 134\n",
      " 135 136 137 139 140 141 143 144 145 149]\n",
      "[  4   6   7  10  12  13  14  16  22  26  29  30  32  33  34  35  41  42\n",
      "  44  45  46  49  53  54  55  57  62  64  65  72  73  78  79  83  88  89\n",
      "  95 103 109 112 123 125 128 131 132 138 142 146 147 148]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6105, validation loss = 1.6096, average loss = 1.6101\n",
      "-------------------\n",
      "The best model for fold 2 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 3:\n",
      "[  4   6   7   8  10  11  12  13  14  16  17  21  22  25  26  28  29  30\n",
      "  31  32  33  34  35  37  38  40  41  42  43  44  45  46  47  48  49  50\n",
      "  52  53  54  55  57  59  62  63  64  65  66  68  69  72  73  74  76  78\n",
      "  79  81  83  84  85  88  89  90  92  93  94  95  97  98 100 103 104 108\n",
      " 109 111 112 113 116 117 121 122 123 125 126 128 129 131 132 133 134 135\n",
      " 137 138 141 142 143 144 146 147 148 149]\n",
      "[  0   1   2   3   5   9  15  18  19  20  23  24  27  36  39  51  56  58\n",
      "  60  61  67  70  71  75  77  80  82  86  87  91  96  99 101 102 105 106\n",
      " 107 110 114 115 118 119 120 124 127 130 136 139 140 145]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6094, validation loss = 1.6129, average loss = 1.6111\n",
      "-------------------\n",
      "The best model for fold 3 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "The model with the least average loss (1.6) has parameters: learning rate = 1, num_epochs = 0.05\n",
      "Leaving sock 3 out\n",
      "(1) Confusion matrix:\n",
      " [[0 6 0 0 0]\n",
      " [0 6 0 0 0]\n",
      " [0 6 0 0 0]\n",
      " [0 5 0 1 0]\n",
      " [0 6 0 0 0]]\n",
      "(2) micro F1 score = 0.23\n",
      "(3) macro F1 score = 0.13\n",
      "(4) Percentage Classification accuracy = 23.33%\n",
      "--------------------------------\n",
      "LEAVING SOCK 4 OUT:\n",
      "FOLD 1:\n",
      "[  0   1   2   3   4   5   6   7   9  10  12  13  14  15  16  18  19  20\n",
      "  22  23  24  26  27  29  30  32  33  34  35  36  39  41  42  44  45  46\n",
      "  49  51  53  54  55  56  57  58  60  61  62  64  65  67  70  71  72  73\n",
      "  75  77  78  79  80  82  83  86  87  88  89  91  95  96  99 101 102 103\n",
      " 105 106 107 109 110 112 114 115 118 119 120 123 124 125 127 128 130 131\n",
      " 132 136 138 139 140 142 145 146 147 148]\n",
      "[  8  11  17  21  25  28  31  37  38  40  43  47  48  50  52  59  63  66\n",
      "  68  69  74  76  81  84  85  90  92  93  94  97  98 100 104 108 111 113\n",
      " 116 117 121 122 126 129 133 134 135 137 141 143 144 149]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6123, validation loss = 1.6062, average loss = 1.6093\n",
      "-------------------\n",
      "The best model for fold 1 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 2:\n",
      "[  0   1   2   3   5   8   9  11  15  17  18  19  20  21  23  24  25  27\n",
      "  28  31  36  37  38  39  40  43  47  48  50  51  52  56  58  59  60  61\n",
      "  63  66  67  68  69  70  71  74  75  76  77  80  81  82  84  85  86  87\n",
      "  90  91  92  93  94  96  97  98  99 100 101 102 104 105 106 107 108 110\n",
      " 111 113 114 115 116 117 118 119 120 121 122 124 126 127 129 130 133 134\n",
      " 135 136 137 139 140 141 143 144 145 149]\n",
      "[  4   6   7  10  12  13  14  16  22  26  29  30  32  33  34  35  41  42\n",
      "  44  45  46  49  53  54  55  57  62  64  65  72  73  78  79  83  88  89\n",
      "  95 103 109 112 123 125 128 131 132 138 142 146 147 148]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6097, validation loss = 1.6101, average loss = 1.6099\n",
      "-------------------\n",
      "The best model for fold 2 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 3:\n",
      "[  4   6   7   8  10  11  12  13  14  16  17  21  22  25  26  28  29  30\n",
      "  31  32  33  34  35  37  38  40  41  42  43  44  45  46  47  48  49  50\n",
      "  52  53  54  55  57  59  62  63  64  65  66  68  69  72  73  74  76  78\n",
      "  79  81  83  84  85  88  89  90  92  93  94  95  97  98 100 103 104 108\n",
      " 109 111 112 113 116 117 121 122 123 125 126 128 129 131 132 133 134 135\n",
      " 137 138 141 142 143 144 146 147 148 149]\n",
      "[  0   1   2   3   5   9  15  18  19  20  23  24  27  36  39  51  56  58\n",
      "  60  61  67  70  71  75  77  80  82  86  87  91  96  99 101 102 105 106\n",
      " 107 110 114 115 118 119 120 124 127 130 136 139 140 145]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6094, validation loss = 1.6105, average loss = 1.61\n",
      "-------------------\n",
      "The best model for fold 3 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "The model with the least average loss (1.6) has parameters: learning rate = 1, num_epochs = 0.05\n",
      "Leaving sock 4 out\n",
      "(1) Confusion matrix:\n",
      " [[0 0 0 0 6]\n",
      " [0 0 0 0 6]\n",
      " [0 0 0 0 6]\n",
      " [0 0 0 0 6]\n",
      " [0 0 0 0 6]]\n",
      "(2) micro F1 score = 0.2\n",
      "(3) macro F1 score = 0.07\n",
      "(4) Percentage Classification accuracy = 20.0%\n",
      "--------------------------------\n",
      "LEAVING SOCK 5 OUT:\n",
      "FOLD 1:\n",
      "[  0   1   2   3   4   5   6   7   9  10  12  13  14  15  16  18  19  20\n",
      "  22  23  24  26  27  29  30  32  33  34  35  36  39  41  42  44  45  46\n",
      "  49  51  53  54  55  56  57  58  60  61  62  64  65  67  70  71  72  73\n",
      "  75  77  78  79  80  82  83  86  87  88  89  91  95  96  99 101 102 103\n",
      " 105 106 107 109 110 112 114 115 118 119 120 123 124 125 127 128 130 131\n",
      " 132 136 138 139 140 142 145 146 147 148]\n",
      "[  8  11  17  21  25  28  31  37  38  40  43  47  48  50  52  59  63  66\n",
      "  68  69  74  76  81  84  85  90  92  93  94  97  98 100 104 108 111 113\n",
      " 116 117 121 122 126 129 133 134 135 137 141 143 144 149]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6101, validation loss = 1.6096, average loss = 1.6099\n",
      "-------------------\n",
      "The best model for fold 1 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 2:\n",
      "[  0   1   2   3   5   8   9  11  15  17  18  19  20  21  23  24  25  27\n",
      "  28  31  36  37  38  39  40  43  47  48  50  51  52  56  58  59  60  61\n",
      "  63  66  67  68  69  70  71  74  75  76  77  80  81  82  84  85  86  87\n",
      "  90  91  92  93  94  96  97  98  99 100 101 102 104 105 106 107 108 110\n",
      " 111 113 114 115 116 117 118 119 120 121 122 124 126 127 129 130 133 134\n",
      " 135 136 137 139 140 141 143 144 145 149]\n",
      "[  4   6   7  10  12  13  14  16  22  26  29  30  32  33  34  35  41  42\n",
      "  44  45  46  49  53  54  55  57  62  64  65  72  73  78  79  83  88  89\n",
      "  95 103 109 112 123 125 128 131 132 138 142 146 147 148]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6101, validation loss = 1.6099, average loss = 1.61\n",
      "-------------------\n",
      "The best model for fold 2 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 3:\n",
      "[  4   6   7   8  10  11  12  13  14  16  17  21  22  25  26  28  29  30\n",
      "  31  32  33  34  35  37  38  40  41  42  43  44  45  46  47  48  49  50\n",
      "  52  53  54  55  57  59  62  63  64  65  66  68  69  72  73  74  76  78\n",
      "  79  81  83  84  85  88  89  90  92  93  94  95  97  98 100 103 104 108\n",
      " 109 111 112 113 116 117 121 122 123 125 126 128 129 131 132 133 134 135\n",
      " 137 138 141 142 143 144 146 147 148 149]\n",
      "[  0   1   2   3   5   9  15  18  19  20  23  24  27  36  39  51  56  58\n",
      "  60  61  67  70  71  75  77  80  82  86  87  91  96  99 101 102 105 106\n",
      " 107 110 114 115 118 119 120 124 127 130 136 139 140 145]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6096, validation loss = 1.6108, average loss = 1.6102\n",
      "-------------------\n",
      "The best model for fold 3 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "The model with the least average loss (1.6) has parameters: learning rate = 1, num_epochs = 0.05\n",
      "Leaving sock 5 out\n",
      "(1) Confusion matrix:\n",
      " [[0 0 0 0 6]\n",
      " [0 0 0 0 6]\n",
      " [0 0 0 0 6]\n",
      " [0 0 0 0 6]\n",
      " [0 0 0 0 6]]\n",
      "(2) micro F1 score = 0.2\n",
      "(3) macro F1 score = 0.07\n",
      "(4) Percentage Classification accuracy = 20.0%\n",
      "--------------------------------\n",
      "LEAVING SOCK 6 OUT:\n",
      "FOLD 1:\n",
      "[  0   1   2   3   4   5   6   7   9  10  12  13  14  15  16  18  19  20\n",
      "  22  23  24  26  27  29  30  32  33  34  35  36  39  41  42  44  45  46\n",
      "  49  51  53  54  55  56  57  58  60  61  62  64  65  67  70  71  72  73\n",
      "  75  77  78  79  80  82  83  86  87  88  89  91  95  96  99 101 102 103\n",
      " 105 106 107 109 110 112 114 115 118 119 120 123 124 125 127 128 130 131\n",
      " 132 136 138 139 140 142 145 146 147 148]\n",
      "[  8  11  17  21  25  28  31  37  38  40  43  47  48  50  52  59  63  66\n",
      "  68  69  74  76  81  84  85  90  92  93  94  97  98 100 104 108 111 113\n",
      " 116 117 121 122 126 129 133 134 135 137 141 143 144 149]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6093, validation loss = 1.611, average loss = 1.6102\n",
      "-------------------\n",
      "The best model for fold 1 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 2:\n",
      "[  0   1   2   3   5   8   9  11  15  17  18  19  20  21  23  24  25  27\n",
      "  28  31  36  37  38  39  40  43  47  48  50  51  52  56  58  59  60  61\n",
      "  63  66  67  68  69  70  71  74  75  76  77  80  81  82  84  85  86  87\n",
      "  90  91  92  93  94  96  97  98  99 100 101 102 104 105 106 107 108 110\n",
      " 111 113 114 115 116 117 118 119 120 121 122 124 126 127 129 130 133 134\n",
      " 135 136 137 139 140 141 143 144 145 149]\n",
      "[  4   6   7  10  12  13  14  16  22  26  29  30  32  33  34  35  41  42\n",
      "  44  45  46  49  53  54  55  57  62  64  65  72  73  78  79  83  88  89\n",
      "  95 103 109 112 123 125 128 131 132 138 142 146 147 148]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6119, validation loss = 1.6071, average loss = 1.6095\n",
      "-------------------\n",
      "The best model for fold 2 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "FOLD 3:\n",
      "[  4   6   7   8  10  11  12  13  14  16  17  21  22  25  26  28  29  30\n",
      "  31  32  33  34  35  37  38  40  41  42  43  44  45  46  47  48  49  50\n",
      "  52  53  54  55  57  59  62  63  64  65  66  68  69  72  73  74  76  78\n",
      "  79  81  83  84  85  88  89  90  92  93  94  95  97  98 100 103 104 108\n",
      " 109 111 112 113 116 117 121 122 123 125 126 128 129 131 132 133 134 135\n",
      " 137 138 141 142 143 144 146 147 148 149]\n",
      "[  0   1   2   3   5   9  15  18  19  20  23  24  27  36  39  51  56  58\n",
      "  60  61  67  70  71  75  77  80  82  86  87  91  96  99 101 102 105 106\n",
      " 107 110 114 115 118 119 120 124 127 130 136 139 140 145]\n",
      "lr=0.05, num epochs=1:\n",
      "epoch 1: training loss = 1.6096, validation loss = 1.619, average loss = 1.6143\n",
      "-------------------\n",
      "The best model for fold 3 has an average loss of 1.6 and has parameters: learning rate = 0.05, num_epochs = 1\n",
      "The model with the least average loss (1.6) has parameters: learning rate = 1, num_epochs = 0.05\n",
      "Leaving sock 6 out\n",
      "(1) Confusion matrix:\n",
      " [[0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]\n",
      " [0 0 6 0 0]]\n",
      "(2) micro F1 score = 0.2\n",
      "(3) macro F1 score = 0.07\n",
      "(4) Percentage Classification accuracy = 20.0%\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "NN_LOS0CV1(emg_0_new, emg_1_new, num_folds=3, predicting_feature='property_id', learning_rate_lst=[0.05], num_epoch_lst=[1], random_state=num)\n",
    "#0.001,0.01,0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a2f86-2107-456f-ae45-dfed67951e30",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "NN_LOS0CV(emg_0_new, emg_1_new, num_folds=3, predicting_feature='property_id', learning_rate_lst=[0.001,0.01,0.1], num_epoch_lst=[5,10,20], random_state=num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1ef4d-f0d8-4428-ac03-6af9508d339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd14207d-e9a3-4cad-b938-55a07990db77",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a43737-140c-4f97-a680-3fc63b47d142",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfde26c-9a09-4203-9372-62b92ea59c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d858ca-60f7-4a9f-96ce-95369ef71a65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca42717-b5cd-48e8-af80-8a1b45965f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add00dd-3c25-42a6-8ca2-58117e760965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d804048-5eab-4250-a7e4-7513e8dc4597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8a12-9cb8-4628-a705-869a36fd65eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c8f760-4a7b-47b2-bf6e-feaeec8cbb67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cfa02d-597e-4c39-b2c8-3ce6b41820b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853e8f6-ec88-4f17-9135-5bba58aeaa03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9505bb7a-6204-46b3-aac7-3130e705fe05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fadd3-fee0-4f65-b8dd-b5919630c2ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a29171e-3bb0-4130-ad0b-134171bb82c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999158f3-7ebf-4f08-a7a8-4d5ea27f20c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2907ba0-a988-4de4-b3ba-62855e0ca7c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0198a-f21c-4f26-bdc0-497a18dcca08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6331ec6-9275-4b51-8de9-ef107d2bc240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee11532e-b457-4002-8fe6-d9ec81dbae52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
