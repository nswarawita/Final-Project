{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f7e15c3-51b7-41e8-8980-c6f52ae4fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f03278ba-5833-40af-a49f-b7295d6e15ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_name</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>sub_window_num</th>\n",
       "      <th>subwindow_start_time</th>\n",
       "      <th>subwindow_end_time</th>\n",
       "      <th>max_ch1_Hand0</th>\n",
       "      <th>...</th>\n",
       "      <th>std_z_Hand1</th>\n",
       "      <th>std_AVx_Hand1</th>\n",
       "      <th>std_AVy_Hand1</th>\n",
       "      <th>std_AVz_Hand1</th>\n",
       "      <th>std_AAx_Hand1</th>\n",
       "      <th>std_AAy_Hand1</th>\n",
       "      <th>std_AAz_Hand1</th>\n",
       "      <th>std_AJx_Hand1</th>\n",
       "      <th>std_AJy_Hand1</th>\n",
       "      <th>std_AJz_Hand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "      <td>2022-02-13 11:24:17.236</td>\n",
       "      <td>0.293434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034045</td>\n",
       "      <td>0.223631</td>\n",
       "      <td>0.400869</td>\n",
       "      <td>0.198252</td>\n",
       "      <td>5.807455</td>\n",
       "      <td>10.633557</td>\n",
       "      <td>4.886320</td>\n",
       "      <td>434.490981</td>\n",
       "      <td>853.585591</td>\n",
       "      <td>445.739808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-13 11:24:17.266</td>\n",
       "      <td>2022-02-13 11:24:22.230</td>\n",
       "      <td>0.122884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034718</td>\n",
       "      <td>0.102369</td>\n",
       "      <td>0.202003</td>\n",
       "      <td>0.215416</td>\n",
       "      <td>2.624330</td>\n",
       "      <td>4.994368</td>\n",
       "      <td>4.763141</td>\n",
       "      <td>163.059962</td>\n",
       "      <td>293.701684</td>\n",
       "      <td>359.806687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-02-13 11:24:22.250</td>\n",
       "      <td>2022-02-13 11:24:27.250</td>\n",
       "      <td>0.159430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045145</td>\n",
       "      <td>0.190866</td>\n",
       "      <td>0.258466</td>\n",
       "      <td>0.341591</td>\n",
       "      <td>4.035735</td>\n",
       "      <td>7.234644</td>\n",
       "      <td>6.105591</td>\n",
       "      <td>307.386108</td>\n",
       "      <td>462.341199</td>\n",
       "      <td>430.277295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>flexibility</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-13 11:27:08.930</td>\n",
       "      <td>2022-02-13 11:27:15.106</td>\n",
       "      <td>0.815143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042501</td>\n",
       "      <td>0.307340</td>\n",
       "      <td>0.676318</td>\n",
       "      <td>0.321149</td>\n",
       "      <td>8.205791</td>\n",
       "      <td>18.275548</td>\n",
       "      <td>7.814122</td>\n",
       "      <td>633.186926</td>\n",
       "      <td>1362.201276</td>\n",
       "      <td>664.974739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>flexibility</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-13 11:27:15.175</td>\n",
       "      <td>2022-02-13 11:27:20.095</td>\n",
       "      <td>0.597988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>0.308847</td>\n",
       "      <td>0.553856</td>\n",
       "      <td>0.392333</td>\n",
       "      <td>6.602712</td>\n",
       "      <td>17.628923</td>\n",
       "      <td>9.375255</td>\n",
       "      <td>463.766340</td>\n",
       "      <td>1186.051852</td>\n",
       "      <td>711.834698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  clothes_id  property_id property_name  interaction_id  \\\n",
       "0              19           3           16      softness             119   \n",
       "1              19           3           16      softness             119   \n",
       "2              19           3           16      softness             119   \n",
       "3              19           3           15   flexibility             120   \n",
       "4              19           3           15   flexibility             120   \n",
       "\n",
       "   rating  sub_window_num     subwindow_start_time       subwindow_end_time  \\\n",
       "0       6               1  2022-02-13 11:24:11.302  2022-02-13 11:24:17.236   \n",
       "1       6               2  2022-02-13 11:24:17.266  2022-02-13 11:24:22.230   \n",
       "2       6               3  2022-02-13 11:24:22.250  2022-02-13 11:24:27.250   \n",
       "3       5               1  2022-02-13 11:27:08.930  2022-02-13 11:27:15.106   \n",
       "4       5               2  2022-02-13 11:27:15.175  2022-02-13 11:27:20.095   \n",
       "\n",
       "   max_ch1_Hand0  ...  std_z_Hand1  std_AVx_Hand1  std_AVy_Hand1  \\\n",
       "0       0.293434  ...     0.034045       0.223631       0.400869   \n",
       "1       0.122884  ...     0.034718       0.102369       0.202003   \n",
       "2       0.159430  ...     0.045145       0.190866       0.258466   \n",
       "3       0.815143  ...     0.042501       0.307340       0.676318   \n",
       "4       0.597988  ...     0.038397       0.308847       0.553856   \n",
       "\n",
       "   std_AVz_Hand1  std_AAx_Hand1  std_AAy_Hand1  std_AAz_Hand1  std_AJx_Hand1  \\\n",
       "0       0.198252       5.807455      10.633557       4.886320     434.490981   \n",
       "1       0.215416       2.624330       4.994368       4.763141     163.059962   \n",
       "2       0.341591       4.035735       7.234644       6.105591     307.386108   \n",
       "3       0.321149       8.205791      18.275548       7.814122     633.186926   \n",
       "4       0.392333       6.602712      17.628923       9.375255     463.766340   \n",
       "\n",
       "   std_AJy_Hand1  std_AJz_Hand1  \n",
       "0     853.585591     445.739808  \n",
       "1     293.701684     359.806687  \n",
       "2     462.341199     430.277295  \n",
       "3    1362.201276     664.974739  \n",
       "4    1186.051852     711.834698  \n",
       "\n",
       "[5 rows x 189 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/niharawarawita/Desktop/MSc Project/Data/EMG_data_collection/combined_stats_nihara.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a8f95b-a007-4b51-9cb7-e8c60a0442ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated random seed is 95\n"
     ]
    }
   ],
   "source": [
    "# Initialise the random state\n",
    "num = random.randint(1, 500)\n",
    "print(f\"The generated random seed is {num}\") #451"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbef62a-e148-47c9-977c-78d300ba7179",
   "metadata": {},
   "source": [
    "## Section A) Physical properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9e058c-5834-4296-9e71-f1f762690f00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 1: Predicting the property based on the provided data (excluding enjoyment data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825bc35e-18f9-4be0-a3b4-0f9e4d81584c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_name</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>sub_window_num</th>\n",
       "      <th>subwindow_start_time</th>\n",
       "      <th>subwindow_end_time</th>\n",
       "      <th>max_ch1_Hand0</th>\n",
       "      <th>...</th>\n",
       "      <th>std_z_Hand1</th>\n",
       "      <th>std_AVx_Hand1</th>\n",
       "      <th>std_AVy_Hand1</th>\n",
       "      <th>std_AVz_Hand1</th>\n",
       "      <th>std_AAx_Hand1</th>\n",
       "      <th>std_AAy_Hand1</th>\n",
       "      <th>std_AAz_Hand1</th>\n",
       "      <th>std_AJx_Hand1</th>\n",
       "      <th>std_AJy_Hand1</th>\n",
       "      <th>std_AJz_Hand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-13 11:24:11.302</td>\n",
       "      <td>2022-02-13 11:24:17.236</td>\n",
       "      <td>0.293434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034045</td>\n",
       "      <td>0.223631</td>\n",
       "      <td>0.400869</td>\n",
       "      <td>0.198252</td>\n",
       "      <td>5.807455</td>\n",
       "      <td>10.633557</td>\n",
       "      <td>4.886320</td>\n",
       "      <td>434.490981</td>\n",
       "      <td>853.585591</td>\n",
       "      <td>445.739808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-13 11:24:17.266</td>\n",
       "      <td>2022-02-13 11:24:22.230</td>\n",
       "      <td>0.122884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034718</td>\n",
       "      <td>0.102369</td>\n",
       "      <td>0.202003</td>\n",
       "      <td>0.215416</td>\n",
       "      <td>2.624330</td>\n",
       "      <td>4.994368</td>\n",
       "      <td>4.763141</td>\n",
       "      <td>163.059962</td>\n",
       "      <td>293.701684</td>\n",
       "      <td>359.806687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>softness</td>\n",
       "      <td>119</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-02-13 11:24:22.250</td>\n",
       "      <td>2022-02-13 11:24:27.250</td>\n",
       "      <td>0.159430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045145</td>\n",
       "      <td>0.190866</td>\n",
       "      <td>0.258466</td>\n",
       "      <td>0.341591</td>\n",
       "      <td>4.035735</td>\n",
       "      <td>7.234644</td>\n",
       "      <td>6.105591</td>\n",
       "      <td>307.386108</td>\n",
       "      <td>462.341199</td>\n",
       "      <td>430.277295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>flexibility</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-13 11:27:08.930</td>\n",
       "      <td>2022-02-13 11:27:15.106</td>\n",
       "      <td>0.815143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042501</td>\n",
       "      <td>0.307340</td>\n",
       "      <td>0.676318</td>\n",
       "      <td>0.321149</td>\n",
       "      <td>8.205791</td>\n",
       "      <td>18.275548</td>\n",
       "      <td>7.814122</td>\n",
       "      <td>633.186926</td>\n",
       "      <td>1362.201276</td>\n",
       "      <td>664.974739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>flexibility</td>\n",
       "      <td>120</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-13 11:27:15.175</td>\n",
       "      <td>2022-02-13 11:27:20.095</td>\n",
       "      <td>0.597988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>0.308847</td>\n",
       "      <td>0.553856</td>\n",
       "      <td>0.392333</td>\n",
       "      <td>6.602712</td>\n",
       "      <td>17.628923</td>\n",
       "      <td>9.375255</td>\n",
       "      <td>463.766340</td>\n",
       "      <td>1186.051852</td>\n",
       "      <td>711.834698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  clothes_id  property_id property_name  interaction_id  \\\n",
       "0              19           3           16      softness             119   \n",
       "1              19           3           16      softness             119   \n",
       "2              19           3           16      softness             119   \n",
       "3              19           3           15   flexibility             120   \n",
       "4              19           3           15   flexibility             120   \n",
       "\n",
       "   rating  sub_window_num     subwindow_start_time       subwindow_end_time  \\\n",
       "0       6               1  2022-02-13 11:24:11.302  2022-02-13 11:24:17.236   \n",
       "1       6               2  2022-02-13 11:24:17.266  2022-02-13 11:24:22.230   \n",
       "2       6               3  2022-02-13 11:24:22.250  2022-02-13 11:24:27.250   \n",
       "3       5               1  2022-02-13 11:27:08.930  2022-02-13 11:27:15.106   \n",
       "4       5               2  2022-02-13 11:27:15.175  2022-02-13 11:27:20.095   \n",
       "\n",
       "   max_ch1_Hand0  ...  std_z_Hand1  std_AVx_Hand1  std_AVy_Hand1  \\\n",
       "0       0.293434  ...     0.034045       0.223631       0.400869   \n",
       "1       0.122884  ...     0.034718       0.102369       0.202003   \n",
       "2       0.159430  ...     0.045145       0.190866       0.258466   \n",
       "3       0.815143  ...     0.042501       0.307340       0.676318   \n",
       "4       0.597988  ...     0.038397       0.308847       0.553856   \n",
       "\n",
       "   std_AVz_Hand1  std_AAx_Hand1  std_AAy_Hand1  std_AAz_Hand1  std_AJx_Hand1  \\\n",
       "0       0.198252       5.807455      10.633557       4.886320     434.490981   \n",
       "1       0.215416       2.624330       4.994368       4.763141     163.059962   \n",
       "2       0.341591       4.035735       7.234644       6.105591     307.386108   \n",
       "3       0.321149       8.205791      18.275548       7.814122     633.186926   \n",
       "4       0.392333       6.602712      17.628923       9.375255     463.766340   \n",
       "\n",
       "   std_AJy_Hand1  std_AJz_Hand1  \n",
       "0     853.585591     445.739808  \n",
       "1     293.701684     359.806687  \n",
       "2     462.341199     430.277295  \n",
       "3    1362.201276     664.974739  \n",
       "4    1186.051852     711.834698  \n",
       "\n",
       "[5 rows x 189 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_data = data[data.property_name != 'enjoyment']\n",
    "physical_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b5fce3-d069-4715-b825-ce3c97dbdb1a",
   "metadata": {},
   "source": [
    "#### Step 1: Basic implementation, without CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c68e53c9-c4c1-4369-b36c-fa2130a6e37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy when predicting properties at random : 20.0% \n",
      "Classification accuracy for the test set when predicting properties: 46.3%\n"
     ]
    }
   ],
   "source": [
    "def rf_properties(data, random_state=num): #drop=None, \n",
    "    print(f'Classification accuracy when predicting properties at random : {round(1/len(data.property_id.unique())*100,2)}% ')\n",
    "\n",
    "    # Data preparation\n",
    "    y = data['property_id'].values\n",
    "    X = data.iloc[:,9:].values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle=True, random_state = num) \n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf_model = RandomForestClassifier(n_estimators = 1000, random_state = num) \n",
    "\n",
    "    # Train the model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Using the model, obtain predictions for the test data\n",
    "    predictions = rf_model.predict(X_test)\n",
    "\n",
    "    # Calculate the number of correct predictions\n",
    "    acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "    # Print out the percentage classification accuracy for the test set\n",
    "    print(f'Classification accuracy for the test set when predicting properties: {round(acc*100,2)}%')\n",
    "\n",
    "rf_properties(data=physical_data, random_state=num)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fe468-5290-4a82-9ab5-6fb19e352bab",
   "metadata": {},
   "source": [
    "#### Step 2: LOCOCV (Leave One Cloth(Sock) Out CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6184e9-cab9-4295-8ece-8febe9814a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper parameters that maximise accuracy: {'n_estimators': 500}\n",
      "When sock 1 was left out, the F1 score was 0.35 and the classification accuracy was 35.96%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When sock 2 was left out, the F1 score was 0.4 and the classification accuracy was 40.0%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When sock 3 was left out, the F1 score was 0.42 and the classification accuracy was 43.33%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When sock 4 was left out, the F1 score was 0.44 and the classification accuracy was 45.56%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When sock 5 was left out, the F1 score was 0.38 and the classification accuracy was 37.78%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 500}\n",
      "When sock 6 was left out, the F1 score was 0.41 and the classification accuracy was 42.22%\n",
      "Results for predicting the property when LOSOCV (Leave One Sock Out Cross Validation) was used: average f1 score = 0.4 and average classification accuracy = 40.81%\n"
     ]
    }
   ],
   "source": [
    "# Note: predicting_feature = 'property_id' or 'rating'\n",
    "\n",
    "def rf_LOCOCV_properties(data, num_inner_folds=5, predicting_feature = 'property_id', random_state=num):\n",
    "    f1_lst = []\n",
    "    acc_lst = []\n",
    "\n",
    "    for cloth_id in range(1,7):      \n",
    "        # Split the data into training and testing\n",
    "        training_data = data[data.clothes_id != cloth_id]\n",
    "        testing_data = data[data.clothes_id == cloth_id]\n",
    "        \n",
    "        # Data preparation\n",
    "        X_train = training_data.iloc[:,9:].values        \n",
    "        y_train = training_data[predicting_feature].values\n",
    "        X_test = testing_data.iloc[:,9:].values        \n",
    "        y_test = testing_data[predicting_feature].values\n",
    "        \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_inner_folds, shuffle=True, random_state=num)\n",
    "        \n",
    "        # Define the model\n",
    "        rf_model = RandomForestClassifier(random_state=num)\n",
    "        \n",
    "        # Create a dictionary with the hyperparameters to tune\n",
    "        features_dict = dict()\n",
    "        features_dict['n_estimators'] = [100, 500, 1000]\n",
    "        \n",
    "        # Define the Grid Search\n",
    "        search = GridSearchCV(rf_model, features_dict, scoring='accuracy', cv=cv_inner, refit=True) #accuracy\n",
    "        \n",
    "        # Execute the search\n",
    "        result = search.fit(X_train, y_train)\n",
    "        print(f\"Hyper parameters that maximise accuracy: {result.best_params_}\")    \n",
    "        \n",
    "        # Obtain the best performing model fit on the whole training set\n",
    "        best_rf_model = result.best_estimator_\n",
    "        \n",
    "        # Using the model, obtain predictions for the test data\n",
    "        predictions = best_rf_model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        f1_score_val = f1_score(y_test, predictions, average=None)\n",
    "        avg_f1_score_val = sum(f1_score_val) / len(f1_score_val)        \n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "        print(f\"When sock {cloth_id} was left out, the F1 score was {round(avg_f1_score_val,2)} and the classification accuracy was {round(acc*100,2)}%\")\n",
    "        \n",
    "        # store the result\n",
    "        f1_lst.append(avg_f1_score_val)        \n",
    "        acc_lst.append(acc)\n",
    "    \n",
    "\n",
    "    avg_f1_score = sum(f1_lst) / len(f1_lst)\n",
    "    avg_acc = sum(acc_lst) / len(acc_lst)   \n",
    "    \n",
    "    print(f\"Results for predicting the property when LOCOCV (Leave One Cloth Out Cross Validation) was used: average f1 score = {round(avg_f1_score,2)} and average classification accuracy = {round(avg_acc*100,2)}%\")\n",
    "            \n",
    "rf_LOCOCV_properties(data=physical_data, num_inner_folds=5, predicting_feature = 'property_id', random_state=num) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d0bf9-1c7f-40ac-ade9-07f47343d50d",
   "metadata": {},
   "source": [
    "#### Step 3: LOPOCV (Leave One Participant Out CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c283bb6c-bfb3-48ba-a21f-dc355c56bbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When participant 19 was left out, the F1 score was 0.21 and the classification accuracy was 30.0%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When participant 21 was left out, the F1 score was 0.14 and the classification accuracy was 20.0%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When participant 22 was left out, the F1 score was 0.26 and the classification accuracy was 30.0%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When participant 23 was left out, the F1 score was 0.37 and the classification accuracy was 42.22%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 500}\n",
      "When participant 24 was left out, the F1 score was 0.15 and the classification accuracy was 21.35%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 500}\n",
      "When participant 25 was left out, the F1 score was 0.29 and the classification accuracy was 33.33%\n",
      "Results for predicting the property when LOPOCV (Leave One Participant Out Cross Validation) was used: average f1 score = 0.24 and average classification accuracy = 29.48%\n"
     ]
    }
   ],
   "source": [
    "# Note: predicting_feature = 'property_id' or 'rating'\n",
    "\n",
    "def rf_LOPOCV_properties(data, num_inner_folds=5, predicting_feature = 'property_id', random_state=num):\n",
    "    f1_lst = []\n",
    "    acc_lst = []\n",
    "    for participant in range(19,26):    \n",
    "        if participant == 20:\n",
    "            pass\n",
    "        else:\n",
    "            # Split the data into training and testing\n",
    "            training_data = data[data.participant_id != participant]\n",
    "            testing_data = data[data.participant_id == participant]\n",
    "\n",
    "            # Data preparation\n",
    "            X_train = training_data.iloc[:,9:].values        \n",
    "            y_train = training_data[predicting_feature].values\n",
    "            X_test = testing_data.iloc[:,9:].values        \n",
    "            y_test = testing_data[predicting_feature].values\n",
    "\n",
    "            # Configure the cross-validation procedure\n",
    "            cv_inner = KFold(n_splits=num_inner_folds, shuffle=True, random_state=num)\n",
    "\n",
    "            # Define the model\n",
    "            rf_model = RandomForestClassifier(random_state=num)\n",
    "\n",
    "            # Create a dictionary with the hyperparameters to tune\n",
    "            features_dict = dict()\n",
    "            features_dict['n_estimators'] = [100, 500, 1000]\n",
    "\n",
    "            # Define the Grid Search\n",
    "            search = GridSearchCV(rf_model, features_dict, scoring='accuracy', cv=cv_inner, refit=True) #accuracy\n",
    "\n",
    "            # Execute the search\n",
    "            result = search.fit(X_train, y_train)\n",
    "            print(f\"Hyper parameters that maximise accuracy: {result.best_params_}\")    \n",
    "\n",
    "            # Obtain the best performing model fit on the whole training set\n",
    "            best_rf_model = result.best_estimator_\n",
    "\n",
    "            # Using the model, obtain predictions for the test data\n",
    "            predictions = best_rf_model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            f1_score_val = f1_score(y_test, predictions, average=None)\n",
    "            avg_f1_score_val = sum(f1_score_val) / len(f1_score_val)        \n",
    "            acc = accuracy_score(y_test, predictions)\n",
    "            print(f\"When participant {participant} was left out, the F1 score was {round(avg_f1_score_val,2)} and the classification accuracy was {round(acc*100,2)}%\")\n",
    "\n",
    "            # store the result\n",
    "            f1_lst.append(avg_f1_score_val)        \n",
    "            acc_lst.append(acc)\n",
    "\n",
    "\n",
    "    avg_f1_score = sum(f1_lst) / len(f1_lst)\n",
    "    avg_acc = sum(acc_lst) / len(acc_lst)   \n",
    "\n",
    "    print(f\"Results for predicting the property when LOPOCV (Leave One Participant Out Cross Validation) was used: average f1 score = {round(avg_f1_score,2)} and average classification accuracy = {round(avg_acc*100,2)}%\")\n",
    "\n",
    "            \n",
    "rf_predicting_properties_LOPOCV(data=physical_data, num_inner_folds=5, predicting_feature = 'property_id', random_state=num) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aaa351-3e3e-471e-a899-b0f686d7e25b",
   "metadata": {},
   "source": [
    "### Task 2: Predicting the rating of the property based on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110b4454-8c49-4e88-9af9-4a3bf3a96ce9",
   "metadata": {},
   "source": [
    "#### Step 1: Basic implementation, without CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765c32c0-affc-4429-a593-41ecb7cd300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy when predicting properties at random: 14.29% \n",
      "Classification accuracy for the test set when predicting the rating for smoothness: 39.39%\n",
      "__________________________________________\n",
      "Classification accuracy for the test set when predicting the rating for thickness: 39.39%\n",
      "__________________________________________\n",
      "Classification accuracy for the test set when predicting the rating for warmth: 54.55%\n",
      "__________________________________________\n",
      "Classification accuracy for the test set when predicting the rating for flexibility: 57.58%\n",
      "__________________________________________\n",
      "Classification accuracy for the test set when predicting the rating for softness: 39.39%\n",
      "__________________________________________\n"
     ]
    }
   ],
   "source": [
    "def rf_rating(data, random_state = num):\n",
    "    lst = ['smoothness', 'thickness', 'warmth', 'flexibility', 'softness']#, 'enjoyment']\n",
    "    print(f'Classification accuracy when predicting properties at random: {round((1/7)*100,2)}% ')\n",
    "    for prop in lst:\n",
    "        # Create dataset\n",
    "        property_data = data[data.property_name == prop]\n",
    "        \n",
    "        # Data preparation\n",
    "        y_property = property_data['rating'].values\n",
    "        X_property = property_data.iloc[:,9:].values\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_property, y_property, test_size = 0.3, shuffle=True, random_state = num) \n",
    "\n",
    "        # Instantiate model with 1000 decision trees\n",
    "        rf_model = RandomForestClassifier(n_estimators = 1000, random_state = num) \n",
    "\n",
    "        # Train the model on the training data\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Using the model, obtain predictions for the test data\n",
    "        predictions = rf_model.predict(X_test)\n",
    "\n",
    "        # Calculate the number of correct predictions\n",
    "        acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "        # Print out the percentage classification accuracy for the test set\n",
    "        print(f'Classification accuracy for the test set when predicting the rating for {prop}: {round(acc*100,2)}%')\n",
    "        print('__________________________________________')\n",
    "\n",
    "rf_rating(data=physical_data)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbf7f2f-4c96-46b7-a569-74f63ff433b0",
   "metadata": {},
   "source": [
    "#### Step 2: LOCOCV (Leave One Cloth(Sock) Out CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07bde540-be5a-4eb7-98a5-8a40edd7e1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy when predicting properties at random: 14.29% \n",
      "Classification accuracy for the test set when predicting the rating for smoothness: 39.39%\n",
      "__________________________________________\n",
      "Classification accuracy for the test set when predicting the rating for thickness: 39.39%\n",
      "__________________________________________\n",
      "Classification accuracy for the test set when predicting the rating for warmth: 54.55%\n",
      "__________________________________________\n",
      "Classification accuracy for the test set when predicting the rating for flexibility: 57.58%\n",
      "__________________________________________\n",
      "Classification accuracy for the test set when predicting the rating for softness: 39.39%\n",
      "__________________________________________\n"
     ]
    }
   ],
   "source": [
    "def rf_LOCOCV_rating(data, num_inner_folds=5, predicting_feature = 'rating', random_state=num):\n",
    "    lst = ['smoothness', 'thickness', 'warmth', 'flexibility', 'softness']#, 'enjoyment']\n",
    "    print(f'Classification accuracy when predicting properties at random: {round((1/7)*100,2)}% ')\n",
    "    for prop in lst:\n",
    "        # Create dataset\n",
    "        property_data = data[data.property_name == prop]\n",
    "        \n",
    "        print(f\"For {prop}:\")\n",
    "        rf_predicting_properties_LOCOCV(data=property_data, num_inner_folds=5, predicting_feature = 'rating', random_state=num)\n",
    "        print('__________________________________________')\n",
    "        \n",
    "\n",
    "rf_LOCOCV_rating(data=physical_data, num_inner_folds=5, predicting_feature = 'rating', random_state=num)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e0ac4-fe26-4633-9e65-0eeb575bc055",
   "metadata": {},
   "source": [
    "#### Step 3: LOPOCV (Leave One Participant Out CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23d3ec-0923-4a49-bcae-7c32c0ca346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy when predicting properties at random: 14.29% \n",
      "For smoothness:\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When participant 19 was left out, the F1 score was 0.0 and the classification accuracy was 0.0%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When participant 21 was left out, the F1 score was 0.16 and the classification accuracy was 22.22%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When participant 22 was left out, the F1 score was 0.04 and the classification accuracy was 5.56%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 500}\n",
      "When participant 23 was left out, the F1 score was 0.0 and the classification accuracy was 0.0%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When participant 24 was left out, the F1 score was 0.06 and the classification accuracy was 11.76%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When participant 25 was left out, the F1 score was 0.08 and the classification accuracy was 16.67%\n",
      "Results for predicting the property when LOPOCV (Leave One Participant Out Cross Validation) was used: average f1 score = 0.06 and average classification accuracy = 9.37%\n",
      "__________________________________________\n",
      "For thickness:\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When participant 19 was left out, the F1 score was 0.08 and the classification accuracy was 22.22%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When participant 21 was left out, the F1 score was 0.1 and the classification accuracy was 27.78%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When participant 22 was left out, the F1 score was 0.09 and the classification accuracy was 16.67%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When participant 23 was left out, the F1 score was 0.06 and the classification accuracy was 16.67%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 100}\n",
      "When participant 24 was left out, the F1 score was 0.13 and the classification accuracy was 33.33%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When participant 25 was left out, the F1 score was 0.18 and the classification accuracy was 55.56%\n",
      "Results for predicting the property when LOPOCV (Leave One Participant Out Cross Validation) was used: average f1 score = 0.11 and average classification accuracy = 28.7%\n",
      "__________________________________________\n",
      "For warmth:\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 500}\n",
      "When participant 19 was left out, the F1 score was 0.16 and the classification accuracy was 16.67%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 500}\n",
      "When participant 21 was left out, the F1 score was 0.0 and the classification accuracy was 0.0%\n",
      "Hyper parameters that maximise accuracy: {'n_estimators': 1000}\n",
      "When participant 22 was left out, the F1 score was 0.23 and the classification accuracy was 38.89%\n"
     ]
    }
   ],
   "source": [
    "def rf_LOPOCV_rating(data, num_inner_folds=5, predicting_feature = 'rating', random_state=num):\n",
    "    lst = ['smoothness', 'thickness', 'warmth', 'flexibility', 'softness']#, 'enjoyment']\n",
    "    print(f'Classification accuracy when predicting properties at random: {round((1/7)*100,2)}% ')\n",
    "    for prop in lst:\n",
    "        # Create dataset\n",
    "        property_data = data[data.property_name == prop]\n",
    "        \n",
    "        print(f\"For {prop}:\")\n",
    "        rf_predicting_properties_LOPOCV(data=property_data, num_inner_folds=5, predicting_feature = 'rating', random_state=num)\n",
    "        print('__________________________________________')\n",
    "        \n",
    "rf_LOPOCV_rating(data=physical_data, num_inner_folds=5, predicting_feature = 'rating', random_state=num)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a64d19-516b-4449-9f82-9e4c8c4d75c5",
   "metadata": {},
   "source": [
    "## Section B) Affective properties - Enjoyment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16409de9-c5b4-4430-9383-5ae82cf61935",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 1: Predicting the property based on the provided data (including enjoyment data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866507c0-e3c3-43b9-8cca-ca2e4875a9de",
   "metadata": {},
   "source": [
    "#### Step 1: Basic implementation, without CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbaeebf-449c-4f9c-aaae-0951eaf78d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predicting_properties(data, random_state=num)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a9ac6-73e5-48a8-8158-86985efcd298",
   "metadata": {},
   "source": [
    "#### Step 2: LOCOCV (Leave One Cloth(Sock) Out CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1fd99-8cdb-47f1-8638-e361f1af234e",
   "metadata": {},
   "source": [
    "### Task 2: Predicting the rating of the property based on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa598cb2-a1bb-411d-97ea-362b28a88e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "enjoyment_data = data[data.property_name == 'enjoyment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8460e289-f67c-445c-9ac2-e73f1d264417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_predicting_rating(data, random_state = num):\n",
    "    print(f'Classification accuracy when predicting properties at random: {round((1/7)*100,2)}% ')\n",
    "\n",
    "    # Data preparation\n",
    "    y_property = data['rating'].values\n",
    "    X_property = data.iloc[:,9:].values\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_property, y_property, test_size = 0.3, shuffle=True, random_state = num) \n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    rf_model = RandomForestClassifier(n_estimators = 1000, random_state = num) \n",
    "\n",
    "    # Train the model on the training data\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # Using the model, obtain predictions for the test data\n",
    "    predictions = rf_model.predict(X_test)\n",
    "\n",
    "    # Calculate the number of correct predictions\n",
    "    acc = accuracy_score(y_test, predictions)   \n",
    "\n",
    "    # Print out the percentage classification accuracy for the test set\n",
    "    print(f'Classification accuracy for the test set when predicting the rating for enjoyment: {round(acc*100,2)}%')\n",
    "\n",
    "rf_predicting_rating(enjoyment_data)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb0f2d-c94d-4a74-8b21-4e647ae68250",
   "metadata": {},
   "outputs": [],
   "source": [
    "gjvhkbjln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de517303-acd0-4275-b7e9-885a648d3171",
   "metadata": {},
   "source": [
    "#### First, consider only the physical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf6909f-7a7b-42a6-a412-4d57a87e9b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data = data[data.property_name != 'enjoyment']\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e14acb-005a-4cfd-870e-67ea33c8a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual nested cross-validation for random forest on a classification dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=1, n_informative=10, n_redundant=10)\n",
    "# configure the cross-validation procedure\n",
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "num_inner_folds = 5\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    # configure the cross-validation procedure\n",
    "    cv_inner = KFold(n_splits=num_inner_folds, shuffle=True, random_state=num)\n",
    "    # define the model\n",
    "    model = RandomForestClassifier(random_state=num)\n",
    "    # define search space\n",
    "    space = dict()\n",
    "    space['n_estimators'] = [10, 100, 500, 1000]\n",
    "    # define search\n",
    "    search = GridSearchCV(model, space, scoring='accuracy', cv=cv_inner, refit=True) #accuracy\n",
    "    # execute search\n",
    "    result = search.fit(X_train, y_train)\n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "    # evaluate model on the hold out dataset\n",
    "    yhat = best_model.predict(X_test)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
