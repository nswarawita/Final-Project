{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4c7b75",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Neural Network models - Leave One Participant Out CV to predict properties using 3 subwindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2d6b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7be36b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated random seed is 58\n"
     ]
    }
   ],
   "source": [
    "# Initialise the random state\n",
    "#num = random.randint(1, 500)\n",
    "num = 58\n",
    "torch.manual_seed(num)\n",
    "np.random.seed(num)\n",
    "print(f\"The generated random seed is {num}\") #347"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9ee2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e359b69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3038cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/niharawarawita/Desktop/MSc Project/Models/15 subwindows 3 slices'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b929b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_name</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_level</th>\n",
       "      <th>rating_level_num</th>\n",
       "      <th>sub_window_num</th>\n",
       "      <th>slice_num</th>\n",
       "      <th>max_ch1_hand0</th>\n",
       "      <th>max_ch2_hand0</th>\n",
       "      <th>max_ch3_hand0</th>\n",
       "      <th>max_ch4_hand0</th>\n",
       "      <th>max_ch5_hand0</th>\n",
       "      <th>max_ch6_hand0</th>\n",
       "      <th>max_ch7_hand0</th>\n",
       "      <th>max_ch8_hand0</th>\n",
       "      <th>mean_ch1_hand0</th>\n",
       "      <th>mean_ch2_hand0</th>\n",
       "      <th>mean_ch3_hand0</th>\n",
       "      <th>mean_ch4_hand0</th>\n",
       "      <th>mean_ch5_hand0</th>\n",
       "      <th>mean_ch6_hand0</th>\n",
       "      <th>mean_ch7_hand0</th>\n",
       "      <th>mean_ch8_hand0</th>\n",
       "      <th>std_ch1_hand0</th>\n",
       "      <th>std_ch2_hand0</th>\n",
       "      <th>std_ch3_hand0</th>\n",
       "      <th>std_ch4_hand0</th>\n",
       "      <th>std_ch5_hand0</th>\n",
       "      <th>std_ch6_hand0</th>\n",
       "      <th>std_ch7_hand0</th>\n",
       "      <th>std_ch8_hand0</th>\n",
       "      <th>max_ch1_hand1</th>\n",
       "      <th>max_ch2_hand1</th>\n",
       "      <th>max_ch3_hand1</th>\n",
       "      <th>max_ch4_hand1</th>\n",
       "      <th>max_ch5_hand1</th>\n",
       "      <th>max_ch6_hand1</th>\n",
       "      <th>max_ch7_hand1</th>\n",
       "      <th>max_ch8_hand1</th>\n",
       "      <th>mean_ch1_hand1</th>\n",
       "      <th>mean_ch2_hand1</th>\n",
       "      <th>mean_ch3_hand1</th>\n",
       "      <th>mean_ch4_hand1</th>\n",
       "      <th>mean_ch5_hand1</th>\n",
       "      <th>mean_ch6_hand1</th>\n",
       "      <th>mean_ch7_hand1</th>\n",
       "      <th>mean_ch8_hand1</th>\n",
       "      <th>std_ch1_hand1</th>\n",
       "      <th>std_ch2_hand1</th>\n",
       "      <th>std_ch3_hand1</th>\n",
       "      <th>std_ch4_hand1</th>\n",
       "      <th>std_ch5_hand1</th>\n",
       "      <th>std_ch6_hand1</th>\n",
       "      <th>std_ch7_hand1</th>\n",
       "      <th>std_ch8_hand1</th>\n",
       "      <th>max_Ax_hand0</th>\n",
       "      <th>max_Ay_hand0</th>\n",
       "      <th>max_Az_hand0</th>\n",
       "      <th>max_Vx_hand0</th>\n",
       "      <th>max_Vy_hand0</th>\n",
       "      <th>max_Vz_hand0</th>\n",
       "      <th>max_Jx_hand0</th>\n",
       "      <th>max_Jy_hand0</th>\n",
       "      <th>max_Jz_hand0</th>\n",
       "      <th>mean_Ax_hand0</th>\n",
       "      <th>mean_Ay_hand0</th>\n",
       "      <th>mean_Az_hand0</th>\n",
       "      <th>mean_Vx_hand0</th>\n",
       "      <th>mean_Vy_hand0</th>\n",
       "      <th>mean_Vz_hand0</th>\n",
       "      <th>mean_Jx_hand0</th>\n",
       "      <th>mean_Jy_hand0</th>\n",
       "      <th>mean_Jz_hand0</th>\n",
       "      <th>std_Ax_hand0</th>\n",
       "      <th>std_Ay_hand0</th>\n",
       "      <th>std_Az_hand0</th>\n",
       "      <th>std_Vx_hand0</th>\n",
       "      <th>std_Vy_hand0</th>\n",
       "      <th>std_Vz_hand0</th>\n",
       "      <th>std_Jx_hand0</th>\n",
       "      <th>std_Jy_hand0</th>\n",
       "      <th>std_Jz_hand0</th>\n",
       "      <th>max_Ax_hand1</th>\n",
       "      <th>max_Ay_hand1</th>\n",
       "      <th>max_Az_hand1</th>\n",
       "      <th>max_Vx_hand1</th>\n",
       "      <th>max_Vy_hand1</th>\n",
       "      <th>max_Vz_hand1</th>\n",
       "      <th>max_Jx_hand1</th>\n",
       "      <th>max_Jy_hand1</th>\n",
       "      <th>max_Jz_hand1</th>\n",
       "      <th>mean_Ax_hand1</th>\n",
       "      <th>mean_Ay_hand1</th>\n",
       "      <th>mean_Az_hand1</th>\n",
       "      <th>mean_Vx_hand1</th>\n",
       "      <th>mean_Vy_hand1</th>\n",
       "      <th>mean_Vz_hand1</th>\n",
       "      <th>mean_Jx_hand1</th>\n",
       "      <th>mean_Jy_hand1</th>\n",
       "      <th>mean_Jz_hand1</th>\n",
       "      <th>std_Ax_hand1</th>\n",
       "      <th>std_Ay_hand1</th>\n",
       "      <th>std_Az_hand1</th>\n",
       "      <th>std_Vx_hand1</th>\n",
       "      <th>std_Vy_hand1</th>\n",
       "      <th>std_Vz_hand1</th>\n",
       "      <th>std_Jx_hand1</th>\n",
       "      <th>std_Jy_hand1</th>\n",
       "      <th>std_Jz_hand1</th>\n",
       "      <th>max_w_hand0</th>\n",
       "      <th>max_x_hand0</th>\n",
       "      <th>max_y_hand0</th>\n",
       "      <th>max_z_hand0</th>\n",
       "      <th>max_AVx_hand0</th>\n",
       "      <th>max_AVy_hand0</th>\n",
       "      <th>max_AVz_hand0</th>\n",
       "      <th>max_AAx_hand0</th>\n",
       "      <th>max_AAy_hand0</th>\n",
       "      <th>max_AAz_hand0</th>\n",
       "      <th>max_AJx_hand0</th>\n",
       "      <th>max_AJy_hand0</th>\n",
       "      <th>max_AJz_hand0</th>\n",
       "      <th>mean_w_hand0</th>\n",
       "      <th>mean_x_hand0</th>\n",
       "      <th>mean_y_hand0</th>\n",
       "      <th>mean_z_hand0</th>\n",
       "      <th>mean_AVx_hand0</th>\n",
       "      <th>mean_AVy_hand0</th>\n",
       "      <th>mean_AVz_hand0</th>\n",
       "      <th>mean_AAx_hand0</th>\n",
       "      <th>mean_AAy_hand0</th>\n",
       "      <th>mean_AAz_hand0</th>\n",
       "      <th>mean_AJx_hand0</th>\n",
       "      <th>mean_AJy_hand0</th>\n",
       "      <th>mean_AJz_hand0</th>\n",
       "      <th>std_w_hand0</th>\n",
       "      <th>std_x_hand0</th>\n",
       "      <th>std_y_hand0</th>\n",
       "      <th>std_z_hand0</th>\n",
       "      <th>std_AVx_hand0</th>\n",
       "      <th>std_AVy_hand0</th>\n",
       "      <th>std_AVz_hand0</th>\n",
       "      <th>std_AAx_hand0</th>\n",
       "      <th>std_AAy_hand0</th>\n",
       "      <th>std_AAz_hand0</th>\n",
       "      <th>std_AJx_hand0</th>\n",
       "      <th>std_AJy_hand0</th>\n",
       "      <th>std_AJz_hand0</th>\n",
       "      <th>max_w_hand1</th>\n",
       "      <th>max_x_hand1</th>\n",
       "      <th>max_y_hand1</th>\n",
       "      <th>max_z_hand1</th>\n",
       "      <th>max_AVx_hand1</th>\n",
       "      <th>max_AVy_hand1</th>\n",
       "      <th>max_AVz_hand1</th>\n",
       "      <th>max_AAx_hand1</th>\n",
       "      <th>max_AAy_hand1</th>\n",
       "      <th>max_AAz_hand1</th>\n",
       "      <th>max_AJx_hand1</th>\n",
       "      <th>max_AJy_hand1</th>\n",
       "      <th>max_AJz_hand1</th>\n",
       "      <th>mean_w_hand1</th>\n",
       "      <th>mean_x_hand1</th>\n",
       "      <th>mean_y_hand1</th>\n",
       "      <th>mean_z_hand1</th>\n",
       "      <th>mean_AVx_hand1</th>\n",
       "      <th>mean_AVy_hand1</th>\n",
       "      <th>mean_AVz_hand1</th>\n",
       "      <th>mean_AAx_hand1</th>\n",
       "      <th>mean_AAy_hand1</th>\n",
       "      <th>mean_AAz_hand1</th>\n",
       "      <th>mean_AJx_hand1</th>\n",
       "      <th>mean_AJy_hand1</th>\n",
       "      <th>mean_AJz_hand1</th>\n",
       "      <th>std_w_hand1</th>\n",
       "      <th>std_x_hand1</th>\n",
       "      <th>std_y_hand1</th>\n",
       "      <th>std_z_hand1</th>\n",
       "      <th>std_AVx_hand1</th>\n",
       "      <th>std_AVy_hand1</th>\n",
       "      <th>std_AVz_hand1</th>\n",
       "      <th>std_AAx_hand1</th>\n",
       "      <th>std_AAy_hand1</th>\n",
       "      <th>std_AAz_hand1</th>\n",
       "      <th>std_AJx_hand1</th>\n",
       "      <th>std_AJy_hand1</th>\n",
       "      <th>std_AJz_hand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497558</td>\n",
       "      <td>0.612908</td>\n",
       "      <td>0.665979</td>\n",
       "      <td>0.492323</td>\n",
       "      <td>0.718373</td>\n",
       "      <td>0.636455</td>\n",
       "      <td>0.748970</td>\n",
       "      <td>0.661048</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.929578</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.648515</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.497131</td>\n",
       "      <td>0.848195</td>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.635252</td>\n",
       "      <td>0.491607</td>\n",
       "      <td>0.526964</td>\n",
       "      <td>0.597308</td>\n",
       "      <td>0.558093</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>0.015387</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>-0.852173</td>\n",
       "      <td>-0.068771</td>\n",
       "      <td>0.481033</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.906808</td>\n",
       "      <td>0.944010</td>\n",
       "      <td>1.878005</td>\n",
       "      <td>-0.863647</td>\n",
       "      <td>-0.092331</td>\n",
       "      <td>0.468185</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.090670</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.488839</td>\n",
       "      <td>0.644995</td>\n",
       "      <td>0.731794</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>-0.198410</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>1.448006</td>\n",
       "      <td>1.255580</td>\n",
       "      <td>2.343750</td>\n",
       "      <td>0.970749</td>\n",
       "      <td>-0.013306</td>\n",
       "      <td>-0.239548</td>\n",
       "      <td>3.039551e-05</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>-0.063439</td>\n",
       "      <td>0.154164</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>0.011627</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.865981</td>\n",
       "      <td>0.887638</td>\n",
       "      <td>1.211894</td>\n",
       "      <td>0.179352</td>\n",
       "      <td>0.486364</td>\n",
       "      <td>0.160615</td>\n",
       "      <td>-0.840857</td>\n",
       "      <td>0.133141</td>\n",
       "      <td>0.061469</td>\n",
       "      <td>0.117029</td>\n",
       "      <td>4.332320</td>\n",
       "      <td>2.887801</td>\n",
       "      <td>19.812834</td>\n",
       "      <td>554.574503</td>\n",
       "      <td>268.044509</td>\n",
       "      <td>1338.775861</td>\n",
       "      <td>0.176140</td>\n",
       "      <td>0.485378</td>\n",
       "      <td>0.158694</td>\n",
       "      <td>-0.841542</td>\n",
       "      <td>-0.003855</td>\n",
       "      <td>-0.006977</td>\n",
       "      <td>-0.063971</td>\n",
       "      <td>-0.440979</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>-0.200017</td>\n",
       "      <td>-49.406882</td>\n",
       "      <td>-39.838054</td>\n",
       "      <td>68.564941</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>0.033528</td>\n",
       "      <td>0.137260</td>\n",
       "      <td>2.915747</td>\n",
       "      <td>1.852018</td>\n",
       "      <td>9.040299</td>\n",
       "      <td>366.140398</td>\n",
       "      <td>183.977327</td>\n",
       "      <td>777.818352</td>\n",
       "      <td>0.613327</td>\n",
       "      <td>-0.175326</td>\n",
       "      <td>-0.758505</td>\n",
       "      <td>-0.128901</td>\n",
       "      <td>0.140072</td>\n",
       "      <td>0.440644</td>\n",
       "      <td>0.126734</td>\n",
       "      <td>5.745156</td>\n",
       "      <td>20.612016</td>\n",
       "      <td>10.404938</td>\n",
       "      <td>649.805789</td>\n",
       "      <td>1527.420437</td>\n",
       "      <td>579.105295</td>\n",
       "      <td>0.602803</td>\n",
       "      <td>-0.176687</td>\n",
       "      <td>-0.767038</td>\n",
       "      <td>-0.130432</td>\n",
       "      <td>0.044346</td>\n",
       "      <td>0.166936</td>\n",
       "      <td>-0.015194</td>\n",
       "      <td>0.369931</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>-0.768253</td>\n",
       "      <td>7.370830</td>\n",
       "      <td>-55.778711</td>\n",
       "      <td>-31.980447</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.067368</td>\n",
       "      <td>0.186562</td>\n",
       "      <td>0.113020</td>\n",
       "      <td>3.575537</td>\n",
       "      <td>10.023728</td>\n",
       "      <td>6.617085</td>\n",
       "      <td>245.110349</td>\n",
       "      <td>738.475924</td>\n",
       "      <td>504.671766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497598</td>\n",
       "      <td>0.612596</td>\n",
       "      <td>0.665782</td>\n",
       "      <td>0.492407</td>\n",
       "      <td>0.718562</td>\n",
       "      <td>0.637166</td>\n",
       "      <td>0.748672</td>\n",
       "      <td>0.660660</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.504098</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.677249</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.787755</td>\n",
       "      <td>0.638614</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.496903</td>\n",
       "      <td>0.848111</td>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.634861</td>\n",
       "      <td>0.491535</td>\n",
       "      <td>0.511201</td>\n",
       "      <td>0.596760</td>\n",
       "      <td>0.557892</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.112410</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>-0.850708</td>\n",
       "      <td>-0.075119</td>\n",
       "      <td>0.490311</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>1.269531</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>1.098633</td>\n",
       "      <td>-0.863087</td>\n",
       "      <td>-0.088216</td>\n",
       "      <td>0.469860</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.079838</td>\n",
       "      <td>-0.067655</td>\n",
       "      <td>0.037227</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.576461</td>\n",
       "      <td>0.332292</td>\n",
       "      <td>0.625069</td>\n",
       "      <td>1.023270</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>-0.178879</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>4.089355</td>\n",
       "      <td>4.516602</td>\n",
       "      <td>2.050781</td>\n",
       "      <td>0.972543</td>\n",
       "      <td>-0.014126</td>\n",
       "      <td>-0.223475</td>\n",
       "      <td>-8.610026e-05</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.125395</td>\n",
       "      <td>0.071997</td>\n",
       "      <td>-0.521592</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.606256</td>\n",
       "      <td>1.455990</td>\n",
       "      <td>2.292596</td>\n",
       "      <td>0.172172</td>\n",
       "      <td>0.487007</td>\n",
       "      <td>0.155308</td>\n",
       "      <td>-0.842296</td>\n",
       "      <td>0.051942</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>0.042930</td>\n",
       "      <td>2.314447</td>\n",
       "      <td>2.108342</td>\n",
       "      <td>11.379475</td>\n",
       "      <td>116.744319</td>\n",
       "      <td>285.209816</td>\n",
       "      <td>662.709244</td>\n",
       "      <td>0.171507</td>\n",
       "      <td>0.486343</td>\n",
       "      <td>0.154797</td>\n",
       "      <td>-0.842670</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>-0.013206</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.318994</td>\n",
       "      <td>-10.224520</td>\n",
       "      <td>5.586727</td>\n",
       "      <td>-32.269925</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.022519</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>0.057136</td>\n",
       "      <td>1.075061</td>\n",
       "      <td>1.239390</td>\n",
       "      <td>3.810758</td>\n",
       "      <td>96.909431</td>\n",
       "      <td>121.285133</td>\n",
       "      <td>445.406712</td>\n",
       "      <td>0.618680</td>\n",
       "      <td>-0.176746</td>\n",
       "      <td>-0.753378</td>\n",
       "      <td>-0.131839</td>\n",
       "      <td>0.173872</td>\n",
       "      <td>0.564510</td>\n",
       "      <td>0.275227</td>\n",
       "      <td>21.603607</td>\n",
       "      <td>56.450019</td>\n",
       "      <td>29.424453</td>\n",
       "      <td>2797.763022</td>\n",
       "      <td>9050.317251</td>\n",
       "      <td>2366.953044</td>\n",
       "      <td>0.608297</td>\n",
       "      <td>-0.178584</td>\n",
       "      <td>-0.761680</td>\n",
       "      <td>-0.133563</td>\n",
       "      <td>-0.060590</td>\n",
       "      <td>-0.221805</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.404595</td>\n",
       "      <td>-2.048076</td>\n",
       "      <td>-0.808920</td>\n",
       "      <td>126.811149</td>\n",
       "      <td>415.913816</td>\n",
       "      <td>-126.597961</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.182445</td>\n",
       "      <td>0.547463</td>\n",
       "      <td>0.138415</td>\n",
       "      <td>10.896145</td>\n",
       "      <td>27.572112</td>\n",
       "      <td>11.192973</td>\n",
       "      <td>1060.610623</td>\n",
       "      <td>2679.860678</td>\n",
       "      <td>1386.692345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497347</td>\n",
       "      <td>0.612820</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0.492135</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.637123</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>0.660448</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.497276</td>\n",
       "      <td>0.849152</td>\n",
       "      <td>0.692361</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>0.491582</td>\n",
       "      <td>0.497936</td>\n",
       "      <td>0.596169</td>\n",
       "      <td>0.558075</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.012065</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.102318</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>-0.856079</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>0.484940</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>1.220703</td>\n",
       "      <td>2.258301</td>\n",
       "      <td>-0.865184</td>\n",
       "      <td>-0.087125</td>\n",
       "      <td>0.466327</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.129092</td>\n",
       "      <td>-0.117662</td>\n",
       "      <td>0.054163</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.720689</td>\n",
       "      <td>0.840380</td>\n",
       "      <td>1.018423</td>\n",
       "      <td>0.992996</td>\n",
       "      <td>0.042786</td>\n",
       "      <td>-0.183762</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>3.417969</td>\n",
       "      <td>5.468750</td>\n",
       "      <td>3.271484</td>\n",
       "      <td>0.967148</td>\n",
       "      <td>-0.006561</td>\n",
       "      <td>-0.256119</td>\n",
       "      <td>-2.792358e-05</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.095838</td>\n",
       "      <td>-0.098997</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>0.018785</td>\n",
       "      <td>0.034782</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>1.235726</td>\n",
       "      <td>1.721460</td>\n",
       "      <td>2.255044</td>\n",
       "      <td>0.170321</td>\n",
       "      <td>0.488418</td>\n",
       "      <td>0.154120</td>\n",
       "      <td>-0.842468</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.074771</td>\n",
       "      <td>1.380191</td>\n",
       "      <td>2.377551</td>\n",
       "      <td>17.101885</td>\n",
       "      <td>142.026745</td>\n",
       "      <td>316.450316</td>\n",
       "      <td>946.725089</td>\n",
       "      <td>0.167272</td>\n",
       "      <td>0.487757</td>\n",
       "      <td>0.151733</td>\n",
       "      <td>-0.843257</td>\n",
       "      <td>-0.008024</td>\n",
       "      <td>-0.006670</td>\n",
       "      <td>-0.037785</td>\n",
       "      <td>0.098066</td>\n",
       "      <td>0.091191</td>\n",
       "      <td>0.496310</td>\n",
       "      <td>1.145841</td>\n",
       "      <td>14.267186</td>\n",
       "      <td>53.811503</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.015705</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.091587</td>\n",
       "      <td>0.830795</td>\n",
       "      <td>0.905251</td>\n",
       "      <td>6.214045</td>\n",
       "      <td>66.340108</td>\n",
       "      <td>88.938460</td>\n",
       "      <td>482.557393</td>\n",
       "      <td>0.601940</td>\n",
       "      <td>-0.175697</td>\n",
       "      <td>-0.767520</td>\n",
       "      <td>-0.129289</td>\n",
       "      <td>0.215491</td>\n",
       "      <td>0.583907</td>\n",
       "      <td>0.121185</td>\n",
       "      <td>10.175411</td>\n",
       "      <td>32.381460</td>\n",
       "      <td>10.444407</td>\n",
       "      <td>1816.649881</td>\n",
       "      <td>3178.222952</td>\n",
       "      <td>752.825555</td>\n",
       "      <td>0.597125</td>\n",
       "      <td>-0.176453</td>\n",
       "      <td>-0.771524</td>\n",
       "      <td>-0.130548</td>\n",
       "      <td>-0.010970</td>\n",
       "      <td>-0.027380</td>\n",
       "      <td>0.025762</td>\n",
       "      <td>-0.953930</td>\n",
       "      <td>-1.770620</td>\n",
       "      <td>0.301481</td>\n",
       "      <td>-89.444296</td>\n",
       "      <td>-117.306912</td>\n",
       "      <td>-2.283264</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.125296</td>\n",
       "      <td>0.339485</td>\n",
       "      <td>0.061387</td>\n",
       "      <td>9.044185</td>\n",
       "      <td>21.643801</td>\n",
       "      <td>4.656397</td>\n",
       "      <td>757.940949</td>\n",
       "      <td>1626.093435</td>\n",
       "      <td>437.046180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497443</td>\n",
       "      <td>0.612821</td>\n",
       "      <td>0.666131</td>\n",
       "      <td>0.492175</td>\n",
       "      <td>0.718675</td>\n",
       "      <td>0.637099</td>\n",
       "      <td>0.748906</td>\n",
       "      <td>0.660243</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.929578</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.661376</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0.848415</td>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.633830</td>\n",
       "      <td>0.491046</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>0.595730</td>\n",
       "      <td>0.557921</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.129979</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>-0.851685</td>\n",
       "      <td>-0.082443</td>\n",
       "      <td>0.481033</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>1.269531</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>-0.863260</td>\n",
       "      <td>-0.087556</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.032972</td>\n",
       "      <td>-0.127265</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.767609</td>\n",
       "      <td>0.315911</td>\n",
       "      <td>0.829373</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>-0.159836</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>3.255208</td>\n",
       "      <td>1.497396</td>\n",
       "      <td>4.882812</td>\n",
       "      <td>0.978578</td>\n",
       "      <td>-0.011643</td>\n",
       "      <td>-0.214437</td>\n",
       "      <td>4.428998e-05</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.033070</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>1.332562</td>\n",
       "      <td>1.412188</td>\n",
       "      <td>1.564734</td>\n",
       "      <td>0.164387</td>\n",
       "      <td>0.489069</td>\n",
       "      <td>0.149139</td>\n",
       "      <td>-0.843806</td>\n",
       "      <td>0.017119</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>1.069198</td>\n",
       "      <td>0.359047</td>\n",
       "      <td>3.737106</td>\n",
       "      <td>82.193580</td>\n",
       "      <td>32.208885</td>\n",
       "      <td>239.397135</td>\n",
       "      <td>0.163401</td>\n",
       "      <td>0.488814</td>\n",
       "      <td>0.148589</td>\n",
       "      <td>-0.843968</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>-0.015940</td>\n",
       "      <td>0.053926</td>\n",
       "      <td>-0.009795</td>\n",
       "      <td>-0.600410</td>\n",
       "      <td>5.515140</td>\n",
       "      <td>-2.263555</td>\n",
       "      <td>-78.920406</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.039351</td>\n",
       "      <td>0.349265</td>\n",
       "      <td>0.199957</td>\n",
       "      <td>3.356053</td>\n",
       "      <td>28.594942</td>\n",
       "      <td>22.130483</td>\n",
       "      <td>387.474946</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>-0.172680</td>\n",
       "      <td>-0.754349</td>\n",
       "      <td>-0.129973</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.639932</td>\n",
       "      <td>0.123348</td>\n",
       "      <td>6.634552</td>\n",
       "      <td>29.010612</td>\n",
       "      <td>8.634400</td>\n",
       "      <td>390.558345</td>\n",
       "      <td>1737.411968</td>\n",
       "      <td>1014.450133</td>\n",
       "      <td>0.612322</td>\n",
       "      <td>-0.174153</td>\n",
       "      <td>-0.759667</td>\n",
       "      <td>-0.132584</td>\n",
       "      <td>0.064927</td>\n",
       "      <td>0.173797</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.545506</td>\n",
       "      <td>0.469424</td>\n",
       "      <td>-38.355687</td>\n",
       "      <td>-116.846738</td>\n",
       "      <td>31.652380</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.081710</td>\n",
       "      <td>0.263328</td>\n",
       "      <td>0.059114</td>\n",
       "      <td>3.805955</td>\n",
       "      <td>14.013769</td>\n",
       "      <td>3.991494</td>\n",
       "      <td>286.560303</td>\n",
       "      <td>1163.025607</td>\n",
       "      <td>416.481477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497288</td>\n",
       "      <td>0.612981</td>\n",
       "      <td>0.666096</td>\n",
       "      <td>0.492485</td>\n",
       "      <td>0.718599</td>\n",
       "      <td>0.637199</td>\n",
       "      <td>0.748633</td>\n",
       "      <td>0.660694</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.497019</td>\n",
       "      <td>0.849392</td>\n",
       "      <td>0.694069</td>\n",
       "      <td>0.635642</td>\n",
       "      <td>0.491512</td>\n",
       "      <td>0.481447</td>\n",
       "      <td>0.598588</td>\n",
       "      <td>0.558258</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.248909</td>\n",
       "      <td>0.021109</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>-0.852661</td>\n",
       "      <td>-0.069260</td>\n",
       "      <td>0.488846</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>1.190186</td>\n",
       "      <td>3.580729</td>\n",
       "      <td>-0.863777</td>\n",
       "      <td>-0.083736</td>\n",
       "      <td>0.466213</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.153993</td>\n",
       "      <td>-0.121061</td>\n",
       "      <td>0.190012</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.786785</td>\n",
       "      <td>0.730909</td>\n",
       "      <td>1.224636</td>\n",
       "      <td>0.978836</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-0.194992</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>1.499721</td>\n",
       "      <td>3.320312</td>\n",
       "      <td>1.538086</td>\n",
       "      <td>0.960434</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>-0.283493</td>\n",
       "      <td>-1.559448e-05</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>-0.090111</td>\n",
       "      <td>-0.170325</td>\n",
       "      <td>-0.513206</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.647672</td>\n",
       "      <td>1.856248</td>\n",
       "      <td>1.061945</td>\n",
       "      <td>0.161008</td>\n",
       "      <td>0.491087</td>\n",
       "      <td>0.146981</td>\n",
       "      <td>-0.844000</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.074743</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>8.423988</td>\n",
       "      <td>6.857490</td>\n",
       "      <td>10.689540</td>\n",
       "      <td>2084.369900</td>\n",
       "      <td>445.379626</td>\n",
       "      <td>810.506826</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>0.490398</td>\n",
       "      <td>0.145404</td>\n",
       "      <td>-0.844300</td>\n",
       "      <td>-0.015225</td>\n",
       "      <td>-0.003469</td>\n",
       "      <td>-0.034162</td>\n",
       "      <td>-0.120960</td>\n",
       "      <td>0.290009</td>\n",
       "      <td>0.374324</td>\n",
       "      <td>93.112872</td>\n",
       "      <td>-17.906684</td>\n",
       "      <td>-89.828683</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.053938</td>\n",
       "      <td>0.034739</td>\n",
       "      <td>0.102911</td>\n",
       "      <td>3.290633</td>\n",
       "      <td>2.509275</td>\n",
       "      <td>5.346618</td>\n",
       "      <td>569.794893</td>\n",
       "      <td>233.907640</td>\n",
       "      <td>724.458119</td>\n",
       "      <td>0.616119</td>\n",
       "      <td>-0.150822</td>\n",
       "      <td>-0.756967</td>\n",
       "      <td>-0.114060</td>\n",
       "      <td>0.127904</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>0.553013</td>\n",
       "      <td>11.380460</td>\n",
       "      <td>19.065811</td>\n",
       "      <td>33.358820</td>\n",
       "      <td>2752.365093</td>\n",
       "      <td>6546.331906</td>\n",
       "      <td>2181.850987</td>\n",
       "      <td>0.589230</td>\n",
       "      <td>-0.162392</td>\n",
       "      <td>-0.781897</td>\n",
       "      <td>-0.120935</td>\n",
       "      <td>-0.114952</td>\n",
       "      <td>-0.433918</td>\n",
       "      <td>0.152484</td>\n",
       "      <td>-1.879316</td>\n",
       "      <td>-0.969483</td>\n",
       "      <td>-0.855661</td>\n",
       "      <td>-52.559265</td>\n",
       "      <td>182.877900</td>\n",
       "      <td>-68.388209</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.013219</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.194634</td>\n",
       "      <td>0.334024</td>\n",
       "      <td>0.186514</td>\n",
       "      <td>10.515282</td>\n",
       "      <td>18.821526</td>\n",
       "      <td>13.561651</td>\n",
       "      <td>1118.669177</td>\n",
       "      <td>2037.005773</td>\n",
       "      <td>1044.511045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.657754</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497511</td>\n",
       "      <td>0.612587</td>\n",
       "      <td>0.666010</td>\n",
       "      <td>0.491924</td>\n",
       "      <td>0.719400</td>\n",
       "      <td>0.637275</td>\n",
       "      <td>0.748935</td>\n",
       "      <td>0.660354</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.005740</td>\n",
       "      <td>0.004257</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.887324</td>\n",
       "      <td>0.722543</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.653465</td>\n",
       "      <td>0.585254</td>\n",
       "      <td>0.496875</td>\n",
       "      <td>0.848812</td>\n",
       "      <td>0.691908</td>\n",
       "      <td>0.634260</td>\n",
       "      <td>0.491046</td>\n",
       "      <td>0.522679</td>\n",
       "      <td>0.596504</td>\n",
       "      <td>0.557978</td>\n",
       "      <td>0.003575</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.008408</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>0.041378</td>\n",
       "      <td>0.010894</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>-0.846313</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>0.479080</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.325521</td>\n",
       "      <td>1.302083</td>\n",
       "      <td>-0.863664</td>\n",
       "      <td>-0.083062</td>\n",
       "      <td>0.462251</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.059776</td>\n",
       "      <td>-0.037833</td>\n",
       "      <td>0.059628</td>\n",
       "      <td>0.007247</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.577617</td>\n",
       "      <td>0.343243</td>\n",
       "      <td>0.682317</td>\n",
       "      <td>0.994949</td>\n",
       "      <td>0.027161</td>\n",
       "      <td>-0.223312</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>2.175071</td>\n",
       "      <td>1.144409</td>\n",
       "      <td>3.104074</td>\n",
       "      <td>0.958587</td>\n",
       "      <td>0.010186</td>\n",
       "      <td>-0.281044</td>\n",
       "      <td>6.422335e-05</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.163814</td>\n",
       "      <td>-0.132560</td>\n",
       "      <td>0.493872</td>\n",
       "      <td>0.016352</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.031257</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.000439</td>\n",
       "      <td>1.462215</td>\n",
       "      <td>1.002923</td>\n",
       "      <td>1.187661</td>\n",
       "      <td>0.159110</td>\n",
       "      <td>0.492346</td>\n",
       "      <td>0.144649</td>\n",
       "      <td>-0.843863</td>\n",
       "      <td>0.020003</td>\n",
       "      <td>0.009362</td>\n",
       "      <td>0.070254</td>\n",
       "      <td>1.521065</td>\n",
       "      <td>1.709388</td>\n",
       "      <td>6.909558</td>\n",
       "      <td>99.147826</td>\n",
       "      <td>157.946614</td>\n",
       "      <td>639.950362</td>\n",
       "      <td>0.157338</td>\n",
       "      <td>0.491849</td>\n",
       "      <td>0.143626</td>\n",
       "      <td>-0.844214</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>-0.006414</td>\n",
       "      <td>-0.004642</td>\n",
       "      <td>-0.048017</td>\n",
       "      <td>-0.041078</td>\n",
       "      <td>0.243305</td>\n",
       "      <td>-16.319848</td>\n",
       "      <td>-3.389182</td>\n",
       "      <td>16.979455</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>0.014307</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>0.687294</td>\n",
       "      <td>0.791024</td>\n",
       "      <td>3.449586</td>\n",
       "      <td>72.483032</td>\n",
       "      <td>58.745670</td>\n",
       "      <td>330.757144</td>\n",
       "      <td>0.601539</td>\n",
       "      <td>-0.151561</td>\n",
       "      <td>-0.772521</td>\n",
       "      <td>-0.117352</td>\n",
       "      <td>0.383834</td>\n",
       "      <td>0.784153</td>\n",
       "      <td>0.048875</td>\n",
       "      <td>11.275214</td>\n",
       "      <td>24.436428</td>\n",
       "      <td>14.075721</td>\n",
       "      <td>843.392290</td>\n",
       "      <td>1224.011969</td>\n",
       "      <td>1736.925658</td>\n",
       "      <td>0.586602</td>\n",
       "      <td>-0.153457</td>\n",
       "      <td>-0.785929</td>\n",
       "      <td>-0.120401</td>\n",
       "      <td>0.107695</td>\n",
       "      <td>0.275052</td>\n",
       "      <td>-0.101141</td>\n",
       "      <td>-1.532278</td>\n",
       "      <td>-0.618235</td>\n",
       "      <td>0.399040</td>\n",
       "      <td>-178.849206</td>\n",
       "      <td>-245.278270</td>\n",
       "      <td>135.870817</td>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.001868</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>0.118714</td>\n",
       "      <td>0.246888</td>\n",
       "      <td>0.148803</td>\n",
       "      <td>6.749870</td>\n",
       "      <td>12.095357</td>\n",
       "      <td>8.193030</td>\n",
       "      <td>654.286569</td>\n",
       "      <td>1065.186993</td>\n",
       "      <td>772.374383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.657754</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497347</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.666264</td>\n",
       "      <td>0.492065</td>\n",
       "      <td>0.718784</td>\n",
       "      <td>0.636698</td>\n",
       "      <td>0.748366</td>\n",
       "      <td>0.660795</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.006079</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.512295</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.774566</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.678218</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.496978</td>\n",
       "      <td>0.848812</td>\n",
       "      <td>0.692775</td>\n",
       "      <td>0.634127</td>\n",
       "      <td>0.491454</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.594987</td>\n",
       "      <td>0.557546</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.015676</td>\n",
       "      <td>0.021029</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.034418</td>\n",
       "      <td>0.017312</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.852173</td>\n",
       "      <td>-0.068771</td>\n",
       "      <td>0.480057</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>1.014123</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>1.464844</td>\n",
       "      <td>-0.863777</td>\n",
       "      <td>-0.084138</td>\n",
       "      <td>0.463886</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>0.098243</td>\n",
       "      <td>0.109735</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>0.006952</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0.009140</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.531656</td>\n",
       "      <td>0.826441</td>\n",
       "      <td>0.831860</td>\n",
       "      <td>1.007645</td>\n",
       "      <td>0.052551</td>\n",
       "      <td>-0.147629</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>3.240412</td>\n",
       "      <td>2.463601</td>\n",
       "      <td>4.448785</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>-0.005382</td>\n",
       "      <td>-0.240718</td>\n",
       "      <td>6.614775e-05</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>-0.000182</td>\n",
       "      <td>-0.113776</td>\n",
       "      <td>-0.210365</td>\n",
       "      <td>0.263679</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>0.022628</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>1.640795</td>\n",
       "      <td>1.629092</td>\n",
       "      <td>2.311830</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.492664</td>\n",
       "      <td>0.142912</td>\n",
       "      <td>-0.844341</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.026547</td>\n",
       "      <td>0.152225</td>\n",
       "      <td>2.837695</td>\n",
       "      <td>3.017070</td>\n",
       "      <td>11.020076</td>\n",
       "      <td>262.734068</td>\n",
       "      <td>415.655987</td>\n",
       "      <td>759.394792</td>\n",
       "      <td>0.155190</td>\n",
       "      <td>0.492335</td>\n",
       "      <td>0.142047</td>\n",
       "      <td>-0.844597</td>\n",
       "      <td>-0.007047</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.013177</td>\n",
       "      <td>-0.117981</td>\n",
       "      <td>0.096800</td>\n",
       "      <td>-0.221939</td>\n",
       "      <td>-5.878979</td>\n",
       "      <td>7.096824</td>\n",
       "      <td>-9.915992</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.009855</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>1.405983</td>\n",
       "      <td>1.003714</td>\n",
       "      <td>5.387111</td>\n",
       "      <td>157.397882</td>\n",
       "      <td>124.998339</td>\n",
       "      <td>468.755457</td>\n",
       "      <td>0.619135</td>\n",
       "      <td>-0.137663</td>\n",
       "      <td>-0.759638</td>\n",
       "      <td>-0.107313</td>\n",
       "      <td>0.239053</td>\n",
       "      <td>0.615255</td>\n",
       "      <td>1.122907</td>\n",
       "      <td>10.739232</td>\n",
       "      <td>25.303288</td>\n",
       "      <td>55.484971</td>\n",
       "      <td>564.093163</td>\n",
       "      <td>2531.056401</td>\n",
       "      <td>3366.960886</td>\n",
       "      <td>0.605811</td>\n",
       "      <td>-0.151132</td>\n",
       "      <td>-0.772182</td>\n",
       "      <td>-0.116743</td>\n",
       "      <td>-0.004393</td>\n",
       "      <td>-0.045766</td>\n",
       "      <td>0.155849</td>\n",
       "      <td>-0.934704</td>\n",
       "      <td>-3.034639</td>\n",
       "      <td>2.374281</td>\n",
       "      <td>-144.461061</td>\n",
       "      <td>-333.421950</td>\n",
       "      <td>126.530407</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.009071</td>\n",
       "      <td>0.006842</td>\n",
       "      <td>0.180948</td>\n",
       "      <td>0.396362</td>\n",
       "      <td>0.336171</td>\n",
       "      <td>7.824720</td>\n",
       "      <td>19.459550</td>\n",
       "      <td>17.568686</td>\n",
       "      <td>752.278104</td>\n",
       "      <td>1674.717882</td>\n",
       "      <td>1446.856625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.753012</td>\n",
       "      <td>0.657754</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497288</td>\n",
       "      <td>0.612821</td>\n",
       "      <td>0.666096</td>\n",
       "      <td>0.492201</td>\n",
       "      <td>0.718599</td>\n",
       "      <td>0.637066</td>\n",
       "      <td>0.748672</td>\n",
       "      <td>0.660729</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.002270</td>\n",
       "      <td>0.006095</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.728324</td>\n",
       "      <td>0.645503</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.644898</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.566820</td>\n",
       "      <td>0.497003</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>0.691691</td>\n",
       "      <td>0.634326</td>\n",
       "      <td>0.491225</td>\n",
       "      <td>0.494056</td>\n",
       "      <td>0.594895</td>\n",
       "      <td>0.557892</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.006268</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.033987</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.002720</td>\n",
       "      <td>-0.850708</td>\n",
       "      <td>-0.068283</td>\n",
       "      <td>0.476639</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.878906</td>\n",
       "      <td>0.749860</td>\n",
       "      <td>-0.861594</td>\n",
       "      <td>-0.083018</td>\n",
       "      <td>0.465868</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>-0.083918</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.493537</td>\n",
       "      <td>0.551965</td>\n",
       "      <td>0.662042</td>\n",
       "      <td>0.984695</td>\n",
       "      <td>0.030579</td>\n",
       "      <td>-0.216965</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>3.662109</td>\n",
       "      <td>1.120175</td>\n",
       "      <td>1.901727</td>\n",
       "      <td>0.967893</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>-0.254850</td>\n",
       "      <td>1.019646e-05</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.076528</td>\n",
       "      <td>-0.072177</td>\n",
       "      <td>0.131622</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.011594</td>\n",
       "      <td>0.020218</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>1.137515</td>\n",
       "      <td>0.522935</td>\n",
       "      <td>1.115761</td>\n",
       "      <td>0.156397</td>\n",
       "      <td>0.492486</td>\n",
       "      <td>0.142331</td>\n",
       "      <td>-0.844299</td>\n",
       "      <td>0.029131</td>\n",
       "      <td>0.041039</td>\n",
       "      <td>0.050319</td>\n",
       "      <td>1.124746</td>\n",
       "      <td>1.452930</td>\n",
       "      <td>7.206869</td>\n",
       "      <td>134.931097</td>\n",
       "      <td>130.770345</td>\n",
       "      <td>642.226289</td>\n",
       "      <td>0.155326</td>\n",
       "      <td>0.492178</td>\n",
       "      <td>0.142018</td>\n",
       "      <td>-0.844668</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>-0.006437</td>\n",
       "      <td>-0.092761</td>\n",
       "      <td>0.074259</td>\n",
       "      <td>-0.131651</td>\n",
       "      <td>-6.453342</td>\n",
       "      <td>7.585678</td>\n",
       "      <td>13.406893</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.010846</td>\n",
       "      <td>0.013257</td>\n",
       "      <td>0.038866</td>\n",
       "      <td>0.771183</td>\n",
       "      <td>0.571619</td>\n",
       "      <td>3.269126</td>\n",
       "      <td>65.403057</td>\n",
       "      <td>47.648876</td>\n",
       "      <td>353.264356</td>\n",
       "      <td>0.610686</td>\n",
       "      <td>-0.136257</td>\n",
       "      <td>-0.772141</td>\n",
       "      <td>-0.107207</td>\n",
       "      <td>0.057619</td>\n",
       "      <td>0.441277</td>\n",
       "      <td>0.063929</td>\n",
       "      <td>1.752601</td>\n",
       "      <td>11.499215</td>\n",
       "      <td>3.521783</td>\n",
       "      <td>199.074344</td>\n",
       "      <td>830.558323</td>\n",
       "      <td>301.612020</td>\n",
       "      <td>0.601790</td>\n",
       "      <td>-0.137024</td>\n",
       "      <td>-0.779321</td>\n",
       "      <td>-0.108158</td>\n",
       "      <td>0.012927</td>\n",
       "      <td>0.161791</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>-0.203191</td>\n",
       "      <td>1.554559</td>\n",
       "      <td>-0.133609</td>\n",
       "      <td>-7.024635</td>\n",
       "      <td>-55.127257</td>\n",
       "      <td>27.599429</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.029979</td>\n",
       "      <td>0.169440</td>\n",
       "      <td>0.042887</td>\n",
       "      <td>1.381130</td>\n",
       "      <td>7.599409</td>\n",
       "      <td>2.042983</td>\n",
       "      <td>109.196705</td>\n",
       "      <td>465.078753</td>\n",
       "      <td>151.858299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497446</td>\n",
       "      <td>0.612714</td>\n",
       "      <td>0.666317</td>\n",
       "      <td>0.492482</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.637181</td>\n",
       "      <td>0.748655</td>\n",
       "      <td>0.660648</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.003236</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.866197</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.645503</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.669388</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.594470</td>\n",
       "      <td>0.496491</td>\n",
       "      <td>0.848283</td>\n",
       "      <td>0.692016</td>\n",
       "      <td>0.633929</td>\n",
       "      <td>0.491046</td>\n",
       "      <td>0.497806</td>\n",
       "      <td>0.594678</td>\n",
       "      <td>0.557575</td>\n",
       "      <td>0.003786</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.003854</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.032627</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>-0.857056</td>\n",
       "      <td>-0.075607</td>\n",
       "      <td>0.470779</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.358073</td>\n",
       "      <td>0.700577</td>\n",
       "      <td>0.793457</td>\n",
       "      <td>-0.862817</td>\n",
       "      <td>-0.083452</td>\n",
       "      <td>0.462544</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.009758</td>\n",
       "      <td>-0.021112</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.291630</td>\n",
       "      <td>0.407908</td>\n",
       "      <td>0.504651</td>\n",
       "      <td>1.005692</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>-0.134933</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>1.314603</td>\n",
       "      <td>1.743862</td>\n",
       "      <td>3.906250</td>\n",
       "      <td>0.980626</td>\n",
       "      <td>-0.009460</td>\n",
       "      <td>-0.185910</td>\n",
       "      <td>9.137370e-05</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.057025</td>\n",
       "      <td>0.054412</td>\n",
       "      <td>0.090793</td>\n",
       "      <td>0.015381</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.028968</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.899503</td>\n",
       "      <td>0.924358</td>\n",
       "      <td>1.396223</td>\n",
       "      <td>0.154080</td>\n",
       "      <td>0.492354</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>-0.844912</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.046422</td>\n",
       "      <td>0.354183</td>\n",
       "      <td>0.187746</td>\n",
       "      <td>3.768103</td>\n",
       "      <td>31.322420</td>\n",
       "      <td>24.401772</td>\n",
       "      <td>167.225957</td>\n",
       "      <td>0.153366</td>\n",
       "      <td>0.492273</td>\n",
       "      <td>0.141251</td>\n",
       "      <td>-0.845100</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.001881</td>\n",
       "      <td>-0.002782</td>\n",
       "      <td>0.013617</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.067088</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>1.288645</td>\n",
       "      <td>10.801729</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.029842</td>\n",
       "      <td>0.147379</td>\n",
       "      <td>0.107996</td>\n",
       "      <td>1.662063</td>\n",
       "      <td>14.383388</td>\n",
       "      <td>10.589203</td>\n",
       "      <td>119.549573</td>\n",
       "      <td>0.634738</td>\n",
       "      <td>-0.139466</td>\n",
       "      <td>-0.750588</td>\n",
       "      <td>-0.106797</td>\n",
       "      <td>0.356971</td>\n",
       "      <td>0.679273</td>\n",
       "      <td>0.017453</td>\n",
       "      <td>10.488112</td>\n",
       "      <td>13.681511</td>\n",
       "      <td>8.429024</td>\n",
       "      <td>660.032496</td>\n",
       "      <td>1037.114565</td>\n",
       "      <td>871.283649</td>\n",
       "      <td>0.626729</td>\n",
       "      <td>-0.141813</td>\n",
       "      <td>-0.757882</td>\n",
       "      <td>-0.112287</td>\n",
       "      <td>0.081234</td>\n",
       "      <td>0.207578</td>\n",
       "      <td>-0.064932</td>\n",
       "      <td>-0.755288</td>\n",
       "      <td>-2.186404</td>\n",
       "      <td>0.069853</td>\n",
       "      <td>-109.273345</td>\n",
       "      <td>-123.374086</td>\n",
       "      <td>-8.926341</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.120965</td>\n",
       "      <td>0.258327</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>5.809162</td>\n",
       "      <td>10.924840</td>\n",
       "      <td>3.446990</td>\n",
       "      <td>584.050208</td>\n",
       "      <td>950.666554</td>\n",
       "      <td>334.566951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497547</td>\n",
       "      <td>0.612788</td>\n",
       "      <td>0.665921</td>\n",
       "      <td>0.492097</td>\n",
       "      <td>0.718675</td>\n",
       "      <td>0.636965</td>\n",
       "      <td>0.749219</td>\n",
       "      <td>0.660764</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.859155</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.645503</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>0.638614</td>\n",
       "      <td>0.603687</td>\n",
       "      <td>0.497029</td>\n",
       "      <td>0.848680</td>\n",
       "      <td>0.691799</td>\n",
       "      <td>0.634193</td>\n",
       "      <td>0.490893</td>\n",
       "      <td>0.493546</td>\n",
       "      <td>0.595080</td>\n",
       "      <td>0.557805</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.037195</td>\n",
       "      <td>0.011961</td>\n",
       "      <td>0.010980</td>\n",
       "      <td>-0.856079</td>\n",
       "      <td>-0.076584</td>\n",
       "      <td>0.475174</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.901442</td>\n",
       "      <td>0.563401</td>\n",
       "      <td>1.185826</td>\n",
       "      <td>-0.865601</td>\n",
       "      <td>-0.085220</td>\n",
       "      <td>0.463760</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.058726</td>\n",
       "      <td>0.015109</td>\n",
       "      <td>-0.013393</td>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.004442</td>\n",
       "      <td>0.008257</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.412341</td>\n",
       "      <td>0.381773</td>\n",
       "      <td>0.735427</td>\n",
       "      <td>1.013504</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>-0.120773</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>1.708984</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>2.685547</td>\n",
       "      <td>0.985249</td>\n",
       "      <td>-0.007475</td>\n",
       "      <td>-0.162538</td>\n",
       "      <td>1.627604e-07</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.045195</td>\n",
       "      <td>-0.036384</td>\n",
       "      <td>0.191980</td>\n",
       "      <td>0.013549</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.026047</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.889100</td>\n",
       "      <td>0.549782</td>\n",
       "      <td>1.211194</td>\n",
       "      <td>0.154020</td>\n",
       "      <td>0.492702</td>\n",
       "      <td>0.141577</td>\n",
       "      <td>-0.844911</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.231021</td>\n",
       "      <td>0.435377</td>\n",
       "      <td>2.724098</td>\n",
       "      <td>14.562569</td>\n",
       "      <td>28.246488</td>\n",
       "      <td>169.499262</td>\n",
       "      <td>0.153462</td>\n",
       "      <td>0.492477</td>\n",
       "      <td>0.141234</td>\n",
       "      <td>-0.844967</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>-0.001413</td>\n",
       "      <td>-0.011402</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>-0.012111</td>\n",
       "      <td>-0.008516</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>9.039524</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>0.097931</td>\n",
       "      <td>0.184863</td>\n",
       "      <td>1.497644</td>\n",
       "      <td>9.080951</td>\n",
       "      <td>14.824817</td>\n",
       "      <td>116.170808</td>\n",
       "      <td>0.643538</td>\n",
       "      <td>-0.138385</td>\n",
       "      <td>-0.743662</td>\n",
       "      <td>-0.112882</td>\n",
       "      <td>0.123585</td>\n",
       "      <td>0.349237</td>\n",
       "      <td>0.247995</td>\n",
       "      <td>3.993563</td>\n",
       "      <td>20.749833</td>\n",
       "      <td>13.410377</td>\n",
       "      <td>223.411684</td>\n",
       "      <td>1042.507247</td>\n",
       "      <td>713.012835</td>\n",
       "      <td>0.637137</td>\n",
       "      <td>-0.140918</td>\n",
       "      <td>-0.749012</td>\n",
       "      <td>-0.114627</td>\n",
       "      <td>0.007547</td>\n",
       "      <td>0.023908</td>\n",
       "      <td>0.012885</td>\n",
       "      <td>0.011279</td>\n",
       "      <td>-0.196785</td>\n",
       "      <td>0.158355</td>\n",
       "      <td>7.618471</td>\n",
       "      <td>10.950691</td>\n",
       "      <td>11.151266</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.061034</td>\n",
       "      <td>0.199596</td>\n",
       "      <td>0.099788</td>\n",
       "      <td>1.938927</td>\n",
       "      <td>7.191168</td>\n",
       "      <td>5.037935</td>\n",
       "      <td>93.629660</td>\n",
       "      <td>466.118908</td>\n",
       "      <td>323.177102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  clothes_id  property_id property_name  interaction_id  \\\n",
       "0               7          14            0    smoothness               1   \n",
       "1               7          14            0    smoothness               1   \n",
       "2               7          14            0    smoothness               1   \n",
       "3               7          14            0    smoothness               1   \n",
       "4               7          14            0    smoothness               1   \n",
       "5               7          14            0    smoothness               1   \n",
       "6               7          14            0    smoothness               1   \n",
       "7               7          14            0    smoothness               1   \n",
       "8               7          14            0    smoothness               1   \n",
       "9               7          14            0    smoothness               1   \n",
       "\n",
       "   rating rating_level  rating_level_num  sub_window_num  slice_num  \\\n",
       "0       3       medium                 2               1          1   \n",
       "1       3       medium                 2               1          2   \n",
       "2       3       medium                 2               1          3   \n",
       "3       3       medium                 2               2          1   \n",
       "4       3       medium                 2               2          2   \n",
       "5       3       medium                 2               2          3   \n",
       "6       3       medium                 2               3          1   \n",
       "7       3       medium                 2               3          2   \n",
       "8       3       medium                 2               3          3   \n",
       "9       3       medium                 2               4          1   \n",
       "\n",
       "   max_ch1_hand0  max_ch2_hand0  max_ch3_hand0  max_ch4_hand0  max_ch5_hand0  \\\n",
       "0       0.500000       0.620513       0.675978       0.495868       0.759036   \n",
       "1       0.504132       0.615385       0.675978       0.495868       0.746988   \n",
       "2       0.500000       0.620513       0.670391       0.500000       0.740964   \n",
       "3       0.500000       0.620513       0.675978       0.495868       0.759036   \n",
       "4       0.504132       0.620513       0.675978       0.500000       0.746988   \n",
       "5       0.500000       0.620513       0.675978       0.495868       0.759036   \n",
       "6       0.500000       0.615385       0.670391       0.495868       0.753012   \n",
       "7       0.500000       0.615385       0.670391       0.500000       0.753012   \n",
       "8       0.500000       0.620513       0.670391       0.495868       0.740964   \n",
       "9       0.500000       0.620513       0.675978       0.495868       0.746988   \n",
       "\n",
       "   max_ch6_hand0  max_ch7_hand0  max_ch8_hand0  mean_ch1_hand0  \\\n",
       "0       0.652406        0.76250       0.666667        0.497558   \n",
       "1       0.652406        0.76250       0.666667        0.497598   \n",
       "2       0.652406        0.75625       0.666667        0.497347   \n",
       "3       0.663102        0.75625       0.666667        0.497443   \n",
       "4       0.652406        0.75625       0.666667        0.497288   \n",
       "5       0.657754        0.75625       0.666667        0.497511   \n",
       "6       0.657754        0.75625       0.666667        0.497347   \n",
       "7       0.657754        0.75625       0.666667        0.497288   \n",
       "8       0.647059        0.75625       0.666667        0.497446   \n",
       "9       0.652406        0.75625       0.666667        0.497547   \n",
       "\n",
       "   mean_ch2_hand0  mean_ch3_hand0  mean_ch4_hand0  mean_ch5_hand0  \\\n",
       "0        0.612908        0.665979        0.492323        0.718373   \n",
       "1        0.612596        0.665782        0.492407        0.718562   \n",
       "2        0.612820        0.665915        0.492135        0.718647   \n",
       "3        0.612821        0.666131        0.492175        0.718675   \n",
       "4        0.612981        0.666096        0.492485        0.718599   \n",
       "5        0.612587        0.666010        0.491924        0.719400   \n",
       "6        0.612500        0.666264        0.492065        0.718784   \n",
       "7        0.612821        0.666096        0.492201        0.718599   \n",
       "8        0.612714        0.666317        0.492482        0.718750   \n",
       "9        0.612788        0.665921        0.492097        0.718675   \n",
       "\n",
       "   mean_ch6_hand0  mean_ch7_hand0  mean_ch8_hand0  std_ch1_hand0  \\\n",
       "0        0.636455        0.748970        0.661048       0.002307   \n",
       "1        0.637166        0.748672        0.660660       0.002384   \n",
       "2        0.637123        0.748899        0.660448       0.002305   \n",
       "3        0.637099        0.748906        0.660243       0.002216   \n",
       "4        0.637199        0.748633        0.660694       0.002410   \n",
       "5        0.637275        0.748935        0.660354       0.002341   \n",
       "6        0.636698        0.748366        0.660795       0.002129   \n",
       "7        0.637066        0.748672        0.660729       0.002410   \n",
       "8        0.637181        0.748655        0.660648       0.002130   \n",
       "9        0.636965        0.749219        0.660764       0.002237   \n",
       "\n",
       "   std_ch2_hand0  std_ch3_hand0  std_ch4_hand0  std_ch5_hand0  std_ch6_hand0  \\\n",
       "0       0.002685       0.003138       0.002326       0.007215       0.004555   \n",
       "1       0.002809       0.003041       0.002118       0.005858       0.004164   \n",
       "2       0.002796       0.002866       0.002150       0.005362       0.004111   \n",
       "3       0.002933       0.002905       0.001944       0.006295       0.004133   \n",
       "4       0.002631       0.002747       0.002533       0.007066       0.004893   \n",
       "5       0.002786       0.002795       0.002201       0.005740       0.004257   \n",
       "6       0.002777       0.002925       0.001948       0.006079       0.004049   \n",
       "7       0.002698       0.003019       0.002270       0.006095       0.004073   \n",
       "8       0.002970       0.002661       0.002053       0.004697       0.003811   \n",
       "9       0.002989       0.002992       0.001876       0.004043       0.003392   \n",
       "\n",
       "   std_ch7_hand0  std_ch8_hand0  max_ch1_hand1  max_ch2_hand1  max_ch3_hand1  \\\n",
       "0       0.003543       0.002655       0.508197       0.929578       0.757225   \n",
       "1       0.004050       0.002641       0.504098       0.880282       0.739884   \n",
       "2       0.003325       0.002466       0.508197       0.908451       0.757225   \n",
       "3       0.002764       0.002610       0.508197       0.929578       0.809249   \n",
       "4       0.003338       0.002610       0.508197       0.957746       0.809249   \n",
       "5       0.002869       0.002613       0.508197       0.887324       0.722543   \n",
       "6       0.003061       0.002033       0.512295       0.908451       0.774566   \n",
       "7       0.003006       0.002257       0.508197       0.866197       0.728324   \n",
       "8       0.003236       0.002587       0.508197       0.866197       0.699422   \n",
       "9       0.003115       0.002545       0.508197       0.859155       0.699422   \n",
       "\n",
       "   max_ch4_hand1  max_ch5_hand1  max_ch6_hand1  max_ch7_hand1  max_ch8_hand1  \\\n",
       "0       0.730159       0.497959       0.995918       0.648515       0.576037   \n",
       "1       0.677249       0.493878       0.787755       0.638614       0.576037   \n",
       "2       0.714286       0.497959       0.714286       0.663366       0.580645   \n",
       "3       0.661376       0.493878       0.820408       0.623762       0.571429   \n",
       "4       0.746032       0.497959       0.995918       0.683168       0.576037   \n",
       "5       0.666667       0.493878       0.669388       0.653465       0.585254   \n",
       "6       0.703704       0.493878       0.628571       0.678218       0.571429   \n",
       "7       0.645503       0.493878       0.644898       0.623762       0.566820   \n",
       "8       0.645503       0.493878       0.669388       0.623762       0.594470   \n",
       "9       0.645503       0.493878       0.595918       0.638614       0.603687   \n",
       "\n",
       "   mean_ch1_hand1  mean_ch2_hand1  mean_ch3_hand1  mean_ch4_hand1  \\\n",
       "0        0.497131        0.848195        0.691944        0.635252   \n",
       "1        0.496903        0.848111        0.691901        0.634861   \n",
       "2        0.497276        0.849152        0.692361        0.634500   \n",
       "3        0.496850        0.848415        0.691944        0.633830   \n",
       "4        0.497019        0.849392        0.694069        0.635642   \n",
       "5        0.496875        0.848812        0.691908        0.634260   \n",
       "6        0.496978        0.848812        0.692775        0.634127   \n",
       "7        0.497003        0.848724        0.691691        0.634326   \n",
       "8        0.496491        0.848283        0.692016        0.633929   \n",
       "9        0.497029        0.848680        0.691799        0.634193   \n",
       "\n",
       "   mean_ch5_hand1  mean_ch6_hand1  mean_ch7_hand1  mean_ch8_hand1  \\\n",
       "0        0.491607        0.526964        0.597308        0.558093   \n",
       "1        0.491535        0.511201        0.596760        0.557892   \n",
       "2        0.491582        0.497936        0.596169        0.558075   \n",
       "3        0.491046        0.475204        0.595730        0.557921   \n",
       "4        0.491512        0.481447        0.598588        0.558258   \n",
       "5        0.491046        0.522679        0.596504        0.557978   \n",
       "6        0.491454        0.493827        0.594987        0.557546   \n",
       "7        0.491225        0.494056        0.594895        0.557892   \n",
       "8        0.491046        0.497806        0.594678        0.557575   \n",
       "9        0.490893        0.493546        0.595080        0.557805   \n",
       "\n",
       "   std_ch1_hand1  std_ch2_hand1  std_ch3_hand1  std_ch4_hand1  std_ch5_hand1  \\\n",
       "0       0.003403       0.011867       0.012139       0.020191       0.002323   \n",
       "1       0.002710       0.007046       0.009382       0.011783       0.002204   \n",
       "2       0.003055       0.010252       0.012065       0.015567       0.002336   \n",
       "3       0.002842       0.009768       0.012697       0.006141       0.002243   \n",
       "4       0.004213       0.017909       0.026751       0.023597       0.002201   \n",
       "5       0.003575       0.006265       0.006212       0.008408       0.002195   \n",
       "6       0.003940       0.015676       0.021029       0.016436       0.002257   \n",
       "7       0.002376       0.006268       0.006414       0.004519       0.002108   \n",
       "8       0.003786       0.005464       0.003053       0.003854       0.002047   \n",
       "9       0.003082       0.004804       0.003329       0.003584       0.002084   \n",
       "\n",
       "   std_ch6_hand1  std_ch7_hand1  std_ch8_hand1  max_Ax_hand0  max_Ay_hand0  \\\n",
       "0       0.156897       0.015387       0.005509     -0.852173     -0.068771   \n",
       "1       0.112410       0.012228       0.005028     -0.850708     -0.075119   \n",
       "2       0.102318       0.015758       0.004804     -0.856079     -0.077072   \n",
       "3       0.129979       0.007751       0.004568     -0.851685     -0.082443   \n",
       "4       0.248909       0.021109       0.005739     -0.852661     -0.069260   \n",
       "5       0.041378       0.010894       0.010311     -0.846313     -0.077072   \n",
       "6       0.034418       0.017312       0.004876     -0.852173     -0.068771   \n",
       "7       0.033987       0.007072       0.002720     -0.850708     -0.068283   \n",
       "8       0.032627       0.010905       0.012049     -0.857056     -0.075607   \n",
       "9       0.037195       0.011961       0.010980     -0.856079     -0.076584   \n",
       "\n",
       "   max_Az_hand0  max_Vx_hand0  max_Vy_hand0  max_Vz_hand0  max_Jx_hand0  \\\n",
       "0      0.481033      0.000330      0.000281      0.000349      0.906808   \n",
       "1      0.490311      0.000403      0.000406      0.000343      1.269531   \n",
       "2      0.484940      0.000525      0.000313      0.000903      0.839844   \n",
       "3      0.481033      0.000448      0.000117      0.000328      1.269531   \n",
       "4      0.488846      0.000316      0.000305      0.000813      2.929688   \n",
       "5      0.479080      0.000545      0.000176      0.000500      0.732422   \n",
       "6      0.480057      0.000306      0.000246      0.000371      1.014123   \n",
       "7      0.476639      0.000574      0.000369      0.000588      0.917969   \n",
       "8      0.470779      0.000232      0.000371      0.000270      0.358073   \n",
       "9      0.475174      0.000193      0.000305      0.000523      0.901442   \n",
       "\n",
       "   max_Jy_hand0  max_Jz_hand0  mean_Ax_hand0  mean_Ay_hand0  mean_Az_hand0  \\\n",
       "0      0.944010      1.878005      -0.863647      -0.092331       0.468185   \n",
       "1      0.600962      1.098633      -0.863087      -0.088216       0.469860   \n",
       "2      1.220703      2.258301      -0.865184      -0.087125       0.466327   \n",
       "3      0.683594      1.171875      -0.863260      -0.087556       0.466011   \n",
       "4      1.190186      3.580729      -0.863777      -0.083736       0.466213   \n",
       "5      0.325521      1.302083      -0.863664      -0.083062       0.462251   \n",
       "6      2.929688      1.464844      -0.863777      -0.084138       0.463886   \n",
       "7      0.878906      0.749860      -0.861594      -0.083018       0.465868   \n",
       "8      0.700577      0.793457      -0.862817      -0.083452       0.462544   \n",
       "9      0.563401      1.185826      -0.865601      -0.085220       0.463760   \n",
       "\n",
       "   mean_Vx_hand0  mean_Vy_hand0  mean_Vz_hand0  mean_Jx_hand0  mean_Jy_hand0  \\\n",
       "0      -0.000014       0.000033      -0.000021       0.018182       0.033422   \n",
       "1       0.000011      -0.000004      -0.000019       0.079838      -0.067655   \n",
       "2      -0.000012       0.000017       0.000004      -0.129092      -0.117662   \n",
       "3      -0.000028      -0.000003      -0.000023       0.038070       0.032972   \n",
       "4       0.000008       0.000003      -0.000002       0.153993      -0.121061   \n",
       "5       0.000001       0.000007       0.000019      -0.059776      -0.037833   \n",
       "6      -0.000003      -0.000020      -0.000054       0.098243       0.109735   \n",
       "7      -0.000012       0.000018       0.000046      -0.045145       0.002736   \n",
       "8       0.000005      -0.000004       0.000002      -0.009758      -0.021112   \n",
       "9      -0.000013       0.000004      -0.000037       0.058726       0.015109   \n",
       "\n",
       "   mean_Jz_hand0  std_Ax_hand0  std_Ay_hand0  std_Az_hand0  std_Vx_hand0  \\\n",
       "0       0.090670      0.006859      0.010176      0.008799      0.000187   \n",
       "1       0.037227      0.006643      0.006718      0.009974      0.000201   \n",
       "2       0.054163      0.007685      0.007728      0.011771      0.000223   \n",
       "3      -0.127265      0.007256      0.003642      0.009516      0.000249   \n",
       "4       0.190012      0.006393      0.005995      0.011556      0.000169   \n",
       "5       0.059628      0.007247      0.004182      0.008216      0.000305   \n",
       "6       0.052387      0.006952      0.008461      0.009140      0.000163   \n",
       "7      -0.083918      0.006144      0.007608      0.007077      0.000199   \n",
       "8       0.004881      0.003756      0.005241      0.006730      0.000129   \n",
       "9      -0.013393      0.005675      0.004442      0.008257      0.000164   \n",
       "\n",
       "   std_Vy_hand0  std_Vz_hand0  std_Jx_hand0  std_Jy_hand0  std_Jz_hand0  \\\n",
       "0      0.000229      0.000238      0.488839      0.644995      0.731794   \n",
       "1      0.000152      0.000263      0.576461      0.332292      0.625069   \n",
       "2      0.000161      0.000317      0.720689      0.840380      1.018423   \n",
       "3      0.000092      0.000241      0.767609      0.315911      0.829373   \n",
       "4      0.000144      0.000347      0.786785      0.730909      1.224636   \n",
       "5      0.000117      0.000311      0.577617      0.343243      0.682317   \n",
       "6      0.000167      0.000290      0.531656      0.826441      0.831860   \n",
       "7      0.000227      0.000229      0.493537      0.551965      0.662042   \n",
       "8      0.000195      0.000226      0.291630      0.407908      0.504651   \n",
       "9      0.000165      0.000239      0.412341      0.381773      0.735427   \n",
       "\n",
       "   max_Ax_hand1  max_Ay_hand1  max_Az_hand1  max_Vx_hand1  max_Vy_hand1  \\\n",
       "0      0.992020      0.013489     -0.198410      0.001218      0.000510   \n",
       "1      1.023270      0.007141     -0.178879      0.000690      0.000342   \n",
       "2      0.992996      0.042786     -0.183762      0.000722      0.001529   \n",
       "3      0.999344      0.010071     -0.159836      0.001031      0.000981   \n",
       "4      0.978836      0.062317     -0.194992      0.000294      0.001328   \n",
       "5      0.994949      0.027161     -0.223312      0.001187      0.001172   \n",
       "6      1.007645      0.052551     -0.147629      0.001466      0.001483   \n",
       "7      0.984695      0.030579     -0.216965      0.000460      0.000324   \n",
       "8      1.005692      0.009094     -0.134933      0.001418      0.000569   \n",
       "9      1.013504      0.009094     -0.120773      0.000647      0.000422   \n",
       "\n",
       "   max_Vz_hand1  max_Jx_hand1  max_Jy_hand1  max_Jz_hand1  mean_Ax_hand1  \\\n",
       "0      0.001187      1.448006      1.255580      2.343750       0.970749   \n",
       "1      0.001220      4.089355      4.516602      2.050781       0.972543   \n",
       "2      0.001429      3.417969      5.468750      3.271484       0.967148   \n",
       "3      0.001074      3.255208      1.497396      4.882812       0.978578   \n",
       "4      0.000615      1.499721      3.320312      1.538086       0.960434   \n",
       "5      0.000848      2.175071      1.144409      3.104074       0.958587   \n",
       "6      0.001220      3.240412      2.463601      4.448785       0.972000   \n",
       "7      0.000765      3.662109      1.120175      1.901727       0.967893   \n",
       "8      0.001129      1.314603      1.743862      3.906250       0.980626   \n",
       "9      0.000687      1.708984      0.732422      2.685547       0.985249   \n",
       "\n",
       "   mean_Ay_hand1  mean_Az_hand1  mean_Vx_hand1  mean_Vy_hand1  mean_Vz_hand1  \\\n",
       "0      -0.013306      -0.239548   3.039551e-05      -0.000022       0.000121   \n",
       "1      -0.014126      -0.223475  -8.610026e-05      -0.000022       0.000048   \n",
       "2      -0.006561      -0.256119  -2.792358e-05       0.000021       0.000029   \n",
       "3      -0.011643      -0.214437   4.428998e-05       0.000030       0.000044   \n",
       "4      -0.001343      -0.283493  -1.559448e-05       0.000107      -0.000194   \n",
       "5       0.010186      -0.281044   6.422335e-05       0.000058       0.000067   \n",
       "6      -0.005382      -0.240718   6.614775e-05       0.000070      -0.000182   \n",
       "7       0.005705      -0.254850   1.019646e-05      -0.000043      -0.000003   \n",
       "8      -0.009460      -0.185910   9.137370e-05       0.000029       0.000057   \n",
       "9      -0.007475      -0.162538   1.627604e-07      -0.000008       0.000062   \n",
       "\n",
       "   mean_Jx_hand1  mean_Jy_hand1  mean_Jz_hand1  std_Ax_hand1  std_Ay_hand1  \\\n",
       "0       0.039065      -0.063439       0.154164      0.016338      0.011627   \n",
       "1       0.125395       0.071997      -0.521592      0.017047      0.013548   \n",
       "2       0.011150       0.095838      -0.098997      0.018756      0.018785   \n",
       "3      -0.033070      -0.195312       0.415176      0.012129      0.011884   \n",
       "4      -0.090111      -0.170325      -0.513206      0.009143      0.024698   \n",
       "5      -0.163814      -0.132560       0.493872      0.016352      0.012772   \n",
       "6      -0.113776      -0.210365       0.263679      0.017331      0.022628   \n",
       "7       0.076528      -0.072177       0.131622      0.009375      0.011594   \n",
       "8       0.057025       0.054412       0.090793      0.015381      0.013230   \n",
       "9      -0.045195      -0.036384       0.191980      0.013549      0.007748   \n",
       "\n",
       "   std_Az_hand1  std_Vx_hand1  std_Vy_hand1  std_Vz_hand1  std_Jx_hand1  \\\n",
       "0      0.024494      0.000461      0.000354      0.000641      0.865981   \n",
       "1      0.035703      0.000446      0.000254      0.000520      1.606256   \n",
       "2      0.034782      0.000430      0.000606      0.000787      1.235726   \n",
       "3      0.025199      0.000345      0.000351      0.000478      1.332562   \n",
       "4      0.045012      0.000182      0.000575      0.000444      0.647672   \n",
       "5      0.031257      0.000432      0.000452      0.000439      1.462215   \n",
       "6      0.047469      0.000537      0.000576      0.000712      1.640795   \n",
       "7      0.020218      0.000246      0.000188      0.000460      1.137515   \n",
       "8      0.028968      0.000535      0.000359      0.000523      0.899503   \n",
       "9      0.026047      0.000367      0.000307      0.000410      0.889100   \n",
       "\n",
       "   std_Jy_hand1  std_Jz_hand1  max_w_hand0  max_x_hand0  max_y_hand0  \\\n",
       "0      0.887638      1.211894     0.179352     0.486364     0.160615   \n",
       "1      1.455990      2.292596     0.172172     0.487007     0.155308   \n",
       "2      1.721460      2.255044     0.170321     0.488418     0.154120   \n",
       "3      1.412188      1.564734     0.164387     0.489069     0.149139   \n",
       "4      1.856248      1.061945     0.161008     0.491087     0.146981   \n",
       "5      1.002923      1.187661     0.159110     0.492346     0.144649   \n",
       "6      1.629092      2.311830     0.156524     0.492664     0.142912   \n",
       "7      0.522935      1.115761     0.156397     0.492486     0.142331   \n",
       "8      0.924358      1.396223     0.154080     0.492354     0.141700   \n",
       "9      0.549782      1.211194     0.154020     0.492702     0.141577   \n",
       "\n",
       "   max_z_hand0  max_AVx_hand0  max_AVy_hand0  max_AVz_hand0  max_AAx_hand0  \\\n",
       "0    -0.840857       0.133141       0.061469       0.117029       4.332320   \n",
       "1    -0.842296       0.051942       0.046418       0.042930       2.314447   \n",
       "2    -0.842468       0.019373       0.020976       0.074771       1.380191   \n",
       "3    -0.843806       0.017119       0.003250       0.031410       1.069198   \n",
       "4    -0.844000       0.051026       0.074743       0.071737       8.423988   \n",
       "5    -0.843863       0.020003       0.009362       0.070254       1.521065   \n",
       "6    -0.844341       0.009619       0.026547       0.152225       2.837695   \n",
       "7    -0.844299       0.029131       0.041039       0.050319       1.124746   \n",
       "8    -0.844912       0.004024      -0.000045       0.046422       0.354183   \n",
       "9    -0.844911       0.002624       0.003048       0.011722       0.231021   \n",
       "\n",
       "   max_AAy_hand0  max_AAz_hand0  max_AJx_hand0  max_AJy_hand0  max_AJz_hand0  \\\n",
       "0       2.887801      19.812834     554.574503     268.044509    1338.775861   \n",
       "1       2.108342      11.379475     116.744319     285.209816     662.709244   \n",
       "2       2.377551      17.101885     142.026745     316.450316     946.725089   \n",
       "3       0.359047       3.737106      82.193580      32.208885     239.397135   \n",
       "4       6.857490      10.689540    2084.369900     445.379626     810.506826   \n",
       "5       1.709388       6.909558      99.147826     157.946614     639.950362   \n",
       "6       3.017070      11.020076     262.734068     415.655987     759.394792   \n",
       "7       1.452930       7.206869     134.931097     130.770345     642.226289   \n",
       "8       0.187746       3.768103      31.322420      24.401772     167.225957   \n",
       "9       0.435377       2.724098      14.562569      28.246488     169.499262   \n",
       "\n",
       "   mean_w_hand0  mean_x_hand0  mean_y_hand0  mean_z_hand0  mean_AVx_hand0  \\\n",
       "0      0.176140      0.485378      0.158694     -0.841542       -0.003855   \n",
       "1      0.171507      0.486343      0.154797     -0.842670        0.004716   \n",
       "2      0.167272      0.487757      0.151733     -0.843257       -0.008024   \n",
       "3      0.163401      0.488814      0.148589     -0.843968        0.000744   \n",
       "4      0.159754      0.490398      0.145404     -0.844300       -0.015225   \n",
       "5      0.157338      0.491849      0.143626     -0.844214        0.002516   \n",
       "6      0.155190      0.492335      0.142047     -0.844597       -0.007047   \n",
       "7      0.155326      0.492178      0.142018     -0.844668        0.004093   \n",
       "8      0.153366      0.492273      0.141251     -0.845100       -0.000200   \n",
       "9      0.153462      0.492477      0.141234     -0.844967        0.000207   \n",
       "\n",
       "   mean_AVy_hand0  mean_AVz_hand0  mean_AAx_hand0  mean_AAy_hand0  \\\n",
       "0       -0.006977       -0.063971       -0.440979        0.013134   \n",
       "1       -0.005843       -0.013206        0.113415        0.014472   \n",
       "2       -0.006670       -0.037785        0.098066        0.091191   \n",
       "3       -0.001663       -0.015940        0.053926       -0.009795   \n",
       "4       -0.003469       -0.034162       -0.120960        0.290009   \n",
       "5       -0.006414       -0.004642       -0.048017       -0.041078   \n",
       "6       -0.000468       -0.013177       -0.117981        0.096800   \n",
       "7        0.002962       -0.006437       -0.092761        0.074259   \n",
       "8       -0.001881       -0.002782        0.013617        0.000202   \n",
       "9       -0.001413       -0.011402        0.008149        0.003122   \n",
       "\n",
       "   mean_AAz_hand0  mean_AJx_hand0  mean_AJy_hand0  mean_AJz_hand0  \\\n",
       "0       -0.200017      -49.406882      -39.838054       68.564941   \n",
       "1        0.318994      -10.224520        5.586727      -32.269925   \n",
       "2        0.496310        1.145841       14.267186       53.811503   \n",
       "3       -0.600410        5.515140       -2.263555      -78.920406   \n",
       "4        0.374324       93.112872      -17.906684      -89.828683   \n",
       "5        0.243305      -16.319848       -3.389182       16.979455   \n",
       "6       -0.221939       -5.878979        7.096824       -9.915992   \n",
       "7       -0.131651       -6.453342        7.585678       13.406893   \n",
       "8        0.067088        0.697987        1.288645       10.801729   \n",
       "9       -0.012111       -0.008516        0.041416        9.039524   \n",
       "\n",
       "   std_w_hand0  std_x_hand0  std_y_hand0  std_z_hand0  std_AVx_hand0  \\\n",
       "0     0.002032     0.000740     0.001425     0.000338       0.053708   \n",
       "1     0.000346     0.000413     0.000428     0.000225       0.022519   \n",
       "2     0.002303     0.000457     0.001921     0.000555       0.015705   \n",
       "3     0.000710     0.000178     0.000382     0.000108       0.005741   \n",
       "4     0.001106     0.000628     0.001142     0.000149       0.053938   \n",
       "5     0.001474     0.000410     0.000848     0.000238       0.007498   \n",
       "6     0.001175     0.000224     0.000698     0.000205       0.015679   \n",
       "7     0.000870     0.000238     0.000285     0.000286       0.010846   \n",
       "8     0.000415     0.000073     0.000229     0.000101       0.001765   \n",
       "9     0.000411     0.000134     0.000239     0.000039       0.001457   \n",
       "\n",
       "   std_AVy_hand0  std_AVz_hand0  std_AAx_hand0  std_AAy_hand0  std_AAz_hand0  \\\n",
       "0       0.033528       0.137260       2.915747       1.852018       9.040299   \n",
       "1       0.031592       0.057136       1.075061       1.239390       3.810758   \n",
       "2       0.015094       0.091587       0.830795       0.905251       6.214045   \n",
       "3       0.003118       0.039351       0.349265       0.199957       3.356053   \n",
       "4       0.034739       0.102911       3.290633       2.509275       5.346618   \n",
       "5       0.014307       0.041097       0.687294       0.791024       3.449586   \n",
       "6       0.009855       0.094595       1.405983       1.003714       5.387111   \n",
       "7       0.013257       0.038866       0.771183       0.571619       3.269126   \n",
       "8       0.001490       0.029842       0.147379       0.107996       1.662063   \n",
       "9       0.002433       0.022282       0.097931       0.184863       1.497644   \n",
       "\n",
       "   std_AJx_hand0  std_AJy_hand0  std_AJz_hand0  max_w_hand1  max_x_hand1  \\\n",
       "0     366.140398     183.977327     777.818352     0.613327    -0.175326   \n",
       "1      96.909431     121.285133     445.406712     0.618680    -0.176746   \n",
       "2      66.340108      88.938460     482.557393     0.601940    -0.175697   \n",
       "3      28.594942      22.130483     387.474946     0.618863    -0.172680   \n",
       "4     569.794893     233.907640     724.458119     0.616119    -0.150822   \n",
       "5      72.483032      58.745670     330.757144     0.601539    -0.151561   \n",
       "6     157.397882     124.998339     468.755457     0.619135    -0.137663   \n",
       "7      65.403057      47.648876     353.264356     0.610686    -0.136257   \n",
       "8      14.383388      10.589203     119.549573     0.634738    -0.139466   \n",
       "9       9.080951      14.824817     116.170808     0.643538    -0.138385   \n",
       "\n",
       "   max_y_hand1  max_z_hand1  max_AVx_hand1  max_AVy_hand1  max_AVz_hand1  \\\n",
       "0    -0.758505    -0.128901       0.140072       0.440644       0.126734   \n",
       "1    -0.753378    -0.131839       0.173872       0.564510       0.275227   \n",
       "2    -0.767520    -0.129289       0.215491       0.583907       0.121185   \n",
       "3    -0.754349    -0.129973       0.196768       0.639932       0.123348   \n",
       "4    -0.756967    -0.114060       0.127904       0.027888       0.553013   \n",
       "5    -0.772521    -0.117352       0.383834       0.784153       0.048875   \n",
       "6    -0.759638    -0.107313       0.239053       0.615255       1.122907   \n",
       "7    -0.772141    -0.107207       0.057619       0.441277       0.063929   \n",
       "8    -0.750588    -0.106797       0.356971       0.679273       0.017453   \n",
       "9    -0.743662    -0.112882       0.123585       0.349237       0.247995   \n",
       "\n",
       "   max_AAx_hand1  max_AAy_hand1  max_AAz_hand1  max_AJx_hand1  max_AJy_hand1  \\\n",
       "0       5.745156      20.612016      10.404938     649.805789    1527.420437   \n",
       "1      21.603607      56.450019      29.424453    2797.763022    9050.317251   \n",
       "2      10.175411      32.381460      10.444407    1816.649881    3178.222952   \n",
       "3       6.634552      29.010612       8.634400     390.558345    1737.411968   \n",
       "4      11.380460      19.065811      33.358820    2752.365093    6546.331906   \n",
       "5      11.275214      24.436428      14.075721     843.392290    1224.011969   \n",
       "6      10.739232      25.303288      55.484971     564.093163    2531.056401   \n",
       "7       1.752601      11.499215       3.521783     199.074344     830.558323   \n",
       "8      10.488112      13.681511       8.429024     660.032496    1037.114565   \n",
       "9       3.993563      20.749833      13.410377     223.411684    1042.507247   \n",
       "\n",
       "   max_AJz_hand1  mean_w_hand1  mean_x_hand1  mean_y_hand1  mean_z_hand1  \\\n",
       "0     579.105295      0.602803     -0.176687     -0.767038     -0.130432   \n",
       "1    2366.953044      0.608297     -0.178584     -0.761680     -0.133563   \n",
       "2     752.825555      0.597125     -0.176453     -0.771524     -0.130548   \n",
       "3    1014.450133      0.612322     -0.174153     -0.759667     -0.132584   \n",
       "4    2181.850987      0.589230     -0.162392     -0.781897     -0.120935   \n",
       "5    1736.925658      0.586602     -0.153457     -0.785929     -0.120401   \n",
       "6    3366.960886      0.605811     -0.151132     -0.772182     -0.116743   \n",
       "7     301.612020      0.601790     -0.137024     -0.779321     -0.108158   \n",
       "8     871.283649      0.626729     -0.141813     -0.757882     -0.112287   \n",
       "9     713.012835      0.637137     -0.140918     -0.749012     -0.114627   \n",
       "\n",
       "   mean_AVx_hand1  mean_AVy_hand1  mean_AVz_hand1  mean_AAx_hand1  \\\n",
       "0        0.044346        0.166936       -0.015194        0.369931   \n",
       "1       -0.060590       -0.221805       -0.010201       -1.404595   \n",
       "2       -0.010970       -0.027380        0.025762       -0.953930   \n",
       "3        0.064927        0.173797       -0.004880        0.031692   \n",
       "4       -0.114952       -0.433918        0.152484       -1.879316   \n",
       "5        0.107695        0.275052       -0.101141       -1.532278   \n",
       "6       -0.004393       -0.045766        0.155849       -0.934704   \n",
       "7        0.012927        0.161791       -0.003148       -0.203191   \n",
       "8        0.081234        0.207578       -0.064932       -0.755288   \n",
       "9        0.007547        0.023908        0.012885        0.011279   \n",
       "\n",
       "   mean_AAy_hand1  mean_AAz_hand1  mean_AJx_hand1  mean_AJy_hand1  \\\n",
       "0        0.966866       -0.768253        7.370830      -55.778711   \n",
       "1       -2.048076       -0.808920      126.811149      415.913816   \n",
       "2       -1.770620        0.301481      -89.444296     -117.306912   \n",
       "3        0.545506        0.469424      -38.355687     -116.846738   \n",
       "4       -0.969483       -0.855661      -52.559265      182.877900   \n",
       "5       -0.618235        0.399040     -178.849206     -245.278270   \n",
       "6       -3.034639        2.374281     -144.461061     -333.421950   \n",
       "7        1.554559       -0.133609       -7.024635      -55.127257   \n",
       "8       -2.186404        0.069853     -109.273345     -123.374086   \n",
       "9       -0.196785        0.158355        7.618471       10.950691   \n",
       "\n",
       "   mean_AJz_hand1  std_w_hand1  std_x_hand1  std_y_hand1  std_z_hand1  \\\n",
       "0      -31.980447     0.005596     0.000748     0.004593     0.001061   \n",
       "1     -126.597961     0.007344     0.001289     0.005919     0.000823   \n",
       "2       -2.283264     0.002735     0.000653     0.002287     0.001059   \n",
       "3       31.652380     0.006002     0.001024     0.004882     0.001771   \n",
       "4      -68.388209     0.013831     0.008176     0.013219     0.006777   \n",
       "5      135.870817     0.009799     0.001868     0.008120     0.003641   \n",
       "6      126.530407     0.008699     0.008256     0.009071     0.006842   \n",
       "7       27.599429     0.004666     0.000733     0.003640     0.000579   \n",
       "8       -8.926341     0.007500     0.001091     0.006797     0.003117   \n",
       "9       11.151266     0.004883     0.001846     0.003867     0.000647   \n",
       "\n",
       "   std_AVx_hand1  std_AVy_hand1  std_AVz_hand1  std_AAx_hand1  std_AAy_hand1  \\\n",
       "0       0.067368       0.186562       0.113020       3.575537      10.023728   \n",
       "1       0.182445       0.547463       0.138415      10.896145      27.572112   \n",
       "2       0.125296       0.339485       0.061387       9.044185      21.643801   \n",
       "3       0.081710       0.263328       0.059114       3.805955      14.013769   \n",
       "4       0.194634       0.334024       0.186514      10.515282      18.821526   \n",
       "5       0.118714       0.246888       0.148803       6.749870      12.095357   \n",
       "6       0.180948       0.396362       0.336171       7.824720      19.459550   \n",
       "7       0.029979       0.169440       0.042887       1.381130       7.599409   \n",
       "8       0.120965       0.258327       0.069006       5.809162      10.924840   \n",
       "9       0.061034       0.199596       0.099788       1.938927       7.191168   \n",
       "\n",
       "   std_AAz_hand1  std_AJx_hand1  std_AJy_hand1  std_AJz_hand1  \n",
       "0       6.617085     245.110349     738.475924     504.671766  \n",
       "1      11.192973    1060.610623    2679.860678    1386.692345  \n",
       "2       4.656397     757.940949    1626.093435     437.046180  \n",
       "3       3.991494     286.560303    1163.025607     416.481477  \n",
       "4      13.561651    1118.669177    2037.005773    1044.511045  \n",
       "5       8.193030     654.286569    1065.186993     772.374383  \n",
       "6      17.568686     752.278104    1674.717882    1446.856625  \n",
       "7       2.042983     109.196705     465.078753     151.858299  \n",
       "8       3.446990     584.050208     950.666554     334.566951  \n",
       "9       5.037935      93.629660     466.118908     323.177102  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/niharawarawita/Desktop/MSc Project/Models/15 subwindows 3 slices/complete_dataset_15subwindows_3slices.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec199894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22679, 190)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18899, 190)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove enjoyment as we are only considering physical properties\n",
    "print(df.shape)\n",
    "physical_df = df[df.property_name!='enjoyment']\n",
    "physical_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afcfaad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_name</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_level</th>\n",
       "      <th>rating_level_num</th>\n",
       "      <th>sub_window_num</th>\n",
       "      <th>slice_num</th>\n",
       "      <th>max_ch1_hand0</th>\n",
       "      <th>max_ch2_hand0</th>\n",
       "      <th>max_ch3_hand0</th>\n",
       "      <th>max_ch4_hand0</th>\n",
       "      <th>max_ch5_hand0</th>\n",
       "      <th>max_ch6_hand0</th>\n",
       "      <th>max_ch7_hand0</th>\n",
       "      <th>max_ch8_hand0</th>\n",
       "      <th>mean_ch1_hand0</th>\n",
       "      <th>mean_ch2_hand0</th>\n",
       "      <th>mean_ch3_hand0</th>\n",
       "      <th>mean_ch4_hand0</th>\n",
       "      <th>mean_ch5_hand0</th>\n",
       "      <th>mean_ch6_hand0</th>\n",
       "      <th>mean_ch7_hand0</th>\n",
       "      <th>mean_ch8_hand0</th>\n",
       "      <th>std_ch1_hand0</th>\n",
       "      <th>std_ch2_hand0</th>\n",
       "      <th>std_ch3_hand0</th>\n",
       "      <th>std_ch4_hand0</th>\n",
       "      <th>std_ch5_hand0</th>\n",
       "      <th>std_ch6_hand0</th>\n",
       "      <th>std_ch7_hand0</th>\n",
       "      <th>std_ch8_hand0</th>\n",
       "      <th>max_ch1_hand1</th>\n",
       "      <th>max_ch2_hand1</th>\n",
       "      <th>max_ch3_hand1</th>\n",
       "      <th>max_ch4_hand1</th>\n",
       "      <th>max_ch5_hand1</th>\n",
       "      <th>max_ch6_hand1</th>\n",
       "      <th>max_ch7_hand1</th>\n",
       "      <th>max_ch8_hand1</th>\n",
       "      <th>mean_ch1_hand1</th>\n",
       "      <th>mean_ch2_hand1</th>\n",
       "      <th>mean_ch3_hand1</th>\n",
       "      <th>mean_ch4_hand1</th>\n",
       "      <th>mean_ch5_hand1</th>\n",
       "      <th>mean_ch6_hand1</th>\n",
       "      <th>mean_ch7_hand1</th>\n",
       "      <th>mean_ch8_hand1</th>\n",
       "      <th>std_ch1_hand1</th>\n",
       "      <th>std_ch2_hand1</th>\n",
       "      <th>std_ch3_hand1</th>\n",
       "      <th>std_ch4_hand1</th>\n",
       "      <th>std_ch5_hand1</th>\n",
       "      <th>std_ch6_hand1</th>\n",
       "      <th>std_ch7_hand1</th>\n",
       "      <th>std_ch8_hand1</th>\n",
       "      <th>max_Ax_hand0</th>\n",
       "      <th>max_Ay_hand0</th>\n",
       "      <th>max_Az_hand0</th>\n",
       "      <th>max_Vx_hand0</th>\n",
       "      <th>max_Vy_hand0</th>\n",
       "      <th>max_Vz_hand0</th>\n",
       "      <th>max_Jx_hand0</th>\n",
       "      <th>max_Jy_hand0</th>\n",
       "      <th>max_Jz_hand0</th>\n",
       "      <th>mean_Ax_hand0</th>\n",
       "      <th>mean_Ay_hand0</th>\n",
       "      <th>mean_Az_hand0</th>\n",
       "      <th>mean_Vx_hand0</th>\n",
       "      <th>mean_Vy_hand0</th>\n",
       "      <th>mean_Vz_hand0</th>\n",
       "      <th>mean_Jx_hand0</th>\n",
       "      <th>mean_Jy_hand0</th>\n",
       "      <th>mean_Jz_hand0</th>\n",
       "      <th>std_Ax_hand0</th>\n",
       "      <th>std_Ay_hand0</th>\n",
       "      <th>std_Az_hand0</th>\n",
       "      <th>std_Vx_hand0</th>\n",
       "      <th>std_Vy_hand0</th>\n",
       "      <th>std_Vz_hand0</th>\n",
       "      <th>std_Jx_hand0</th>\n",
       "      <th>std_Jy_hand0</th>\n",
       "      <th>std_Jz_hand0</th>\n",
       "      <th>max_Ax_hand1</th>\n",
       "      <th>max_Ay_hand1</th>\n",
       "      <th>max_Az_hand1</th>\n",
       "      <th>max_Vx_hand1</th>\n",
       "      <th>max_Vy_hand1</th>\n",
       "      <th>max_Vz_hand1</th>\n",
       "      <th>max_Jx_hand1</th>\n",
       "      <th>max_Jy_hand1</th>\n",
       "      <th>max_Jz_hand1</th>\n",
       "      <th>mean_Ax_hand1</th>\n",
       "      <th>mean_Ay_hand1</th>\n",
       "      <th>mean_Az_hand1</th>\n",
       "      <th>mean_Vx_hand1</th>\n",
       "      <th>mean_Vy_hand1</th>\n",
       "      <th>mean_Vz_hand1</th>\n",
       "      <th>mean_Jx_hand1</th>\n",
       "      <th>mean_Jy_hand1</th>\n",
       "      <th>mean_Jz_hand1</th>\n",
       "      <th>std_Ax_hand1</th>\n",
       "      <th>std_Ay_hand1</th>\n",
       "      <th>std_Az_hand1</th>\n",
       "      <th>std_Vx_hand1</th>\n",
       "      <th>std_Vy_hand1</th>\n",
       "      <th>std_Vz_hand1</th>\n",
       "      <th>std_Jx_hand1</th>\n",
       "      <th>std_Jy_hand1</th>\n",
       "      <th>std_Jz_hand1</th>\n",
       "      <th>max_w_hand0</th>\n",
       "      <th>max_x_hand0</th>\n",
       "      <th>max_y_hand0</th>\n",
       "      <th>max_z_hand0</th>\n",
       "      <th>max_AVx_hand0</th>\n",
       "      <th>max_AVy_hand0</th>\n",
       "      <th>max_AVz_hand0</th>\n",
       "      <th>max_AAx_hand0</th>\n",
       "      <th>max_AAy_hand0</th>\n",
       "      <th>max_AAz_hand0</th>\n",
       "      <th>max_AJx_hand0</th>\n",
       "      <th>max_AJy_hand0</th>\n",
       "      <th>max_AJz_hand0</th>\n",
       "      <th>mean_w_hand0</th>\n",
       "      <th>mean_x_hand0</th>\n",
       "      <th>mean_y_hand0</th>\n",
       "      <th>mean_z_hand0</th>\n",
       "      <th>mean_AVx_hand0</th>\n",
       "      <th>mean_AVy_hand0</th>\n",
       "      <th>mean_AVz_hand0</th>\n",
       "      <th>mean_AAx_hand0</th>\n",
       "      <th>mean_AAy_hand0</th>\n",
       "      <th>mean_AAz_hand0</th>\n",
       "      <th>mean_AJx_hand0</th>\n",
       "      <th>mean_AJy_hand0</th>\n",
       "      <th>mean_AJz_hand0</th>\n",
       "      <th>std_w_hand0</th>\n",
       "      <th>std_x_hand0</th>\n",
       "      <th>std_y_hand0</th>\n",
       "      <th>std_z_hand0</th>\n",
       "      <th>std_AVx_hand0</th>\n",
       "      <th>std_AVy_hand0</th>\n",
       "      <th>std_AVz_hand0</th>\n",
       "      <th>std_AAx_hand0</th>\n",
       "      <th>std_AAy_hand0</th>\n",
       "      <th>std_AAz_hand0</th>\n",
       "      <th>std_AJx_hand0</th>\n",
       "      <th>std_AJy_hand0</th>\n",
       "      <th>std_AJz_hand0</th>\n",
       "      <th>max_w_hand1</th>\n",
       "      <th>max_x_hand1</th>\n",
       "      <th>max_y_hand1</th>\n",
       "      <th>max_z_hand1</th>\n",
       "      <th>max_AVx_hand1</th>\n",
       "      <th>max_AVy_hand1</th>\n",
       "      <th>max_AVz_hand1</th>\n",
       "      <th>max_AAx_hand1</th>\n",
       "      <th>max_AAy_hand1</th>\n",
       "      <th>max_AAz_hand1</th>\n",
       "      <th>max_AJx_hand1</th>\n",
       "      <th>max_AJy_hand1</th>\n",
       "      <th>max_AJz_hand1</th>\n",
       "      <th>mean_w_hand1</th>\n",
       "      <th>mean_x_hand1</th>\n",
       "      <th>mean_y_hand1</th>\n",
       "      <th>mean_z_hand1</th>\n",
       "      <th>mean_AVx_hand1</th>\n",
       "      <th>mean_AVy_hand1</th>\n",
       "      <th>mean_AVz_hand1</th>\n",
       "      <th>mean_AAx_hand1</th>\n",
       "      <th>mean_AAy_hand1</th>\n",
       "      <th>mean_AAz_hand1</th>\n",
       "      <th>mean_AJx_hand1</th>\n",
       "      <th>mean_AJy_hand1</th>\n",
       "      <th>mean_AJz_hand1</th>\n",
       "      <th>std_w_hand1</th>\n",
       "      <th>std_x_hand1</th>\n",
       "      <th>std_y_hand1</th>\n",
       "      <th>std_z_hand1</th>\n",
       "      <th>std_AVx_hand1</th>\n",
       "      <th>std_AVy_hand1</th>\n",
       "      <th>std_AVz_hand1</th>\n",
       "      <th>std_AAx_hand1</th>\n",
       "      <th>std_AAy_hand1</th>\n",
       "      <th>std_AAz_hand1</th>\n",
       "      <th>std_AJx_hand1</th>\n",
       "      <th>std_AJy_hand1</th>\n",
       "      <th>std_AJz_hand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497558</td>\n",
       "      <td>0.612908</td>\n",
       "      <td>0.665979</td>\n",
       "      <td>0.492323</td>\n",
       "      <td>0.718373</td>\n",
       "      <td>0.636455</td>\n",
       "      <td>0.748970</td>\n",
       "      <td>0.661048</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.929578</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.648515</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.497131</td>\n",
       "      <td>0.848195</td>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.635252</td>\n",
       "      <td>0.491607</td>\n",
       "      <td>0.526964</td>\n",
       "      <td>0.597308</td>\n",
       "      <td>0.558093</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>0.015387</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>-0.852173</td>\n",
       "      <td>-0.068771</td>\n",
       "      <td>0.481033</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.906808</td>\n",
       "      <td>0.944010</td>\n",
       "      <td>1.878005</td>\n",
       "      <td>-0.863647</td>\n",
       "      <td>-0.092331</td>\n",
       "      <td>0.468185</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.090670</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.488839</td>\n",
       "      <td>0.644995</td>\n",
       "      <td>0.731794</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>-0.198410</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>1.448006</td>\n",
       "      <td>1.255580</td>\n",
       "      <td>2.343750</td>\n",
       "      <td>0.970749</td>\n",
       "      <td>-0.013306</td>\n",
       "      <td>-0.239548</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>-0.063439</td>\n",
       "      <td>0.154164</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>0.011627</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.865981</td>\n",
       "      <td>0.887638</td>\n",
       "      <td>1.211894</td>\n",
       "      <td>0.179352</td>\n",
       "      <td>0.486364</td>\n",
       "      <td>0.160615</td>\n",
       "      <td>-0.840857</td>\n",
       "      <td>0.133141</td>\n",
       "      <td>0.061469</td>\n",
       "      <td>0.117029</td>\n",
       "      <td>4.332320</td>\n",
       "      <td>2.887801</td>\n",
       "      <td>19.812834</td>\n",
       "      <td>554.574503</td>\n",
       "      <td>268.044509</td>\n",
       "      <td>1338.775861</td>\n",
       "      <td>0.176140</td>\n",
       "      <td>0.485378</td>\n",
       "      <td>0.158694</td>\n",
       "      <td>-0.841542</td>\n",
       "      <td>-0.003855</td>\n",
       "      <td>-0.006977</td>\n",
       "      <td>-0.063971</td>\n",
       "      <td>-0.440979</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>-0.200017</td>\n",
       "      <td>-49.406882</td>\n",
       "      <td>-39.838054</td>\n",
       "      <td>68.564941</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>0.033528</td>\n",
       "      <td>0.137260</td>\n",
       "      <td>2.915747</td>\n",
       "      <td>1.852018</td>\n",
       "      <td>9.040299</td>\n",
       "      <td>366.140398</td>\n",
       "      <td>183.977327</td>\n",
       "      <td>777.818352</td>\n",
       "      <td>0.613327</td>\n",
       "      <td>-0.175326</td>\n",
       "      <td>-0.758505</td>\n",
       "      <td>-0.128901</td>\n",
       "      <td>0.140072</td>\n",
       "      <td>0.440644</td>\n",
       "      <td>0.126734</td>\n",
       "      <td>5.745156</td>\n",
       "      <td>20.612016</td>\n",
       "      <td>10.404938</td>\n",
       "      <td>649.805789</td>\n",
       "      <td>1527.420437</td>\n",
       "      <td>579.105295</td>\n",
       "      <td>0.602803</td>\n",
       "      <td>-0.176687</td>\n",
       "      <td>-0.767038</td>\n",
       "      <td>-0.130432</td>\n",
       "      <td>0.044346</td>\n",
       "      <td>0.166936</td>\n",
       "      <td>-0.015194</td>\n",
       "      <td>0.369931</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>-0.768253</td>\n",
       "      <td>7.370830</td>\n",
       "      <td>-55.778711</td>\n",
       "      <td>-31.980447</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.067368</td>\n",
       "      <td>0.186562</td>\n",
       "      <td>0.113020</td>\n",
       "      <td>3.575537</td>\n",
       "      <td>10.023728</td>\n",
       "      <td>6.617085</td>\n",
       "      <td>245.110349</td>\n",
       "      <td>738.475924</td>\n",
       "      <td>504.671766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497598</td>\n",
       "      <td>0.612596</td>\n",
       "      <td>0.665782</td>\n",
       "      <td>0.492407</td>\n",
       "      <td>0.718562</td>\n",
       "      <td>0.637166</td>\n",
       "      <td>0.748672</td>\n",
       "      <td>0.660660</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.504098</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.677249</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.787755</td>\n",
       "      <td>0.638614</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.496903</td>\n",
       "      <td>0.848111</td>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.634861</td>\n",
       "      <td>0.491535</td>\n",
       "      <td>0.511201</td>\n",
       "      <td>0.596760</td>\n",
       "      <td>0.557892</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.112410</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>-0.850708</td>\n",
       "      <td>-0.075119</td>\n",
       "      <td>0.490311</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>1.269531</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>1.098633</td>\n",
       "      <td>-0.863087</td>\n",
       "      <td>-0.088216</td>\n",
       "      <td>0.469860</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.079838</td>\n",
       "      <td>-0.067655</td>\n",
       "      <td>0.037227</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.576461</td>\n",
       "      <td>0.332292</td>\n",
       "      <td>0.625069</td>\n",
       "      <td>1.023270</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>-0.178879</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>4.089355</td>\n",
       "      <td>4.516602</td>\n",
       "      <td>2.050781</td>\n",
       "      <td>0.972543</td>\n",
       "      <td>-0.014126</td>\n",
       "      <td>-0.223475</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.125395</td>\n",
       "      <td>0.071997</td>\n",
       "      <td>-0.521592</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.606256</td>\n",
       "      <td>1.455990</td>\n",
       "      <td>2.292596</td>\n",
       "      <td>0.172172</td>\n",
       "      <td>0.487007</td>\n",
       "      <td>0.155308</td>\n",
       "      <td>-0.842296</td>\n",
       "      <td>0.051942</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>0.042930</td>\n",
       "      <td>2.314447</td>\n",
       "      <td>2.108342</td>\n",
       "      <td>11.379475</td>\n",
       "      <td>116.744319</td>\n",
       "      <td>285.209816</td>\n",
       "      <td>662.709244</td>\n",
       "      <td>0.171507</td>\n",
       "      <td>0.486343</td>\n",
       "      <td>0.154797</td>\n",
       "      <td>-0.842670</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>-0.013206</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.318994</td>\n",
       "      <td>-10.224520</td>\n",
       "      <td>5.586727</td>\n",
       "      <td>-32.269925</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.022519</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>0.057136</td>\n",
       "      <td>1.075061</td>\n",
       "      <td>1.239390</td>\n",
       "      <td>3.810758</td>\n",
       "      <td>96.909431</td>\n",
       "      <td>121.285133</td>\n",
       "      <td>445.406712</td>\n",
       "      <td>0.618680</td>\n",
       "      <td>-0.176746</td>\n",
       "      <td>-0.753378</td>\n",
       "      <td>-0.131839</td>\n",
       "      <td>0.173872</td>\n",
       "      <td>0.564510</td>\n",
       "      <td>0.275227</td>\n",
       "      <td>21.603607</td>\n",
       "      <td>56.450019</td>\n",
       "      <td>29.424453</td>\n",
       "      <td>2797.763022</td>\n",
       "      <td>9050.317251</td>\n",
       "      <td>2366.953044</td>\n",
       "      <td>0.608297</td>\n",
       "      <td>-0.178584</td>\n",
       "      <td>-0.761680</td>\n",
       "      <td>-0.133563</td>\n",
       "      <td>-0.060590</td>\n",
       "      <td>-0.221805</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.404595</td>\n",
       "      <td>-2.048076</td>\n",
       "      <td>-0.808920</td>\n",
       "      <td>126.811149</td>\n",
       "      <td>415.913816</td>\n",
       "      <td>-126.597961</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.182445</td>\n",
       "      <td>0.547463</td>\n",
       "      <td>0.138415</td>\n",
       "      <td>10.896145</td>\n",
       "      <td>27.572112</td>\n",
       "      <td>11.192973</td>\n",
       "      <td>1060.610623</td>\n",
       "      <td>2679.860678</td>\n",
       "      <td>1386.692345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497347</td>\n",
       "      <td>0.612820</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0.492135</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.637123</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>0.660448</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.497276</td>\n",
       "      <td>0.849152</td>\n",
       "      <td>0.692361</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>0.491582</td>\n",
       "      <td>0.497936</td>\n",
       "      <td>0.596169</td>\n",
       "      <td>0.558075</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.012065</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.102318</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>-0.856079</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>0.484940</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>1.220703</td>\n",
       "      <td>2.258301</td>\n",
       "      <td>-0.865184</td>\n",
       "      <td>-0.087125</td>\n",
       "      <td>0.466327</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.129092</td>\n",
       "      <td>-0.117662</td>\n",
       "      <td>0.054163</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.720689</td>\n",
       "      <td>0.840380</td>\n",
       "      <td>1.018423</td>\n",
       "      <td>0.992996</td>\n",
       "      <td>0.042786</td>\n",
       "      <td>-0.183762</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>3.417969</td>\n",
       "      <td>5.468750</td>\n",
       "      <td>3.271484</td>\n",
       "      <td>0.967148</td>\n",
       "      <td>-0.006561</td>\n",
       "      <td>-0.256119</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.095838</td>\n",
       "      <td>-0.098997</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>0.018785</td>\n",
       "      <td>0.034782</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>1.235726</td>\n",
       "      <td>1.721460</td>\n",
       "      <td>2.255044</td>\n",
       "      <td>0.170321</td>\n",
       "      <td>0.488418</td>\n",
       "      <td>0.154120</td>\n",
       "      <td>-0.842468</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.074771</td>\n",
       "      <td>1.380191</td>\n",
       "      <td>2.377551</td>\n",
       "      <td>17.101885</td>\n",
       "      <td>142.026745</td>\n",
       "      <td>316.450316</td>\n",
       "      <td>946.725089</td>\n",
       "      <td>0.167272</td>\n",
       "      <td>0.487757</td>\n",
       "      <td>0.151733</td>\n",
       "      <td>-0.843257</td>\n",
       "      <td>-0.008024</td>\n",
       "      <td>-0.006670</td>\n",
       "      <td>-0.037785</td>\n",
       "      <td>0.098066</td>\n",
       "      <td>0.091191</td>\n",
       "      <td>0.496310</td>\n",
       "      <td>1.145841</td>\n",
       "      <td>14.267186</td>\n",
       "      <td>53.811503</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.015705</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.091587</td>\n",
       "      <td>0.830795</td>\n",
       "      <td>0.905251</td>\n",
       "      <td>6.214045</td>\n",
       "      <td>66.340108</td>\n",
       "      <td>88.938460</td>\n",
       "      <td>482.557393</td>\n",
       "      <td>0.601940</td>\n",
       "      <td>-0.175697</td>\n",
       "      <td>-0.767520</td>\n",
       "      <td>-0.129289</td>\n",
       "      <td>0.215491</td>\n",
       "      <td>0.583907</td>\n",
       "      <td>0.121185</td>\n",
       "      <td>10.175411</td>\n",
       "      <td>32.381460</td>\n",
       "      <td>10.444407</td>\n",
       "      <td>1816.649881</td>\n",
       "      <td>3178.222952</td>\n",
       "      <td>752.825555</td>\n",
       "      <td>0.597125</td>\n",
       "      <td>-0.176453</td>\n",
       "      <td>-0.771524</td>\n",
       "      <td>-0.130548</td>\n",
       "      <td>-0.010970</td>\n",
       "      <td>-0.027380</td>\n",
       "      <td>0.025762</td>\n",
       "      <td>-0.953930</td>\n",
       "      <td>-1.770620</td>\n",
       "      <td>0.301481</td>\n",
       "      <td>-89.444296</td>\n",
       "      <td>-117.306912</td>\n",
       "      <td>-2.283264</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.125296</td>\n",
       "      <td>0.339485</td>\n",
       "      <td>0.061387</td>\n",
       "      <td>9.044185</td>\n",
       "      <td>21.643801</td>\n",
       "      <td>4.656397</td>\n",
       "      <td>757.940949</td>\n",
       "      <td>1626.093435</td>\n",
       "      <td>437.046180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497443</td>\n",
       "      <td>0.612821</td>\n",
       "      <td>0.666131</td>\n",
       "      <td>0.492175</td>\n",
       "      <td>0.718675</td>\n",
       "      <td>0.637099</td>\n",
       "      <td>0.748906</td>\n",
       "      <td>0.660243</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.929578</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.661376</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0.848415</td>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.633830</td>\n",
       "      <td>0.491046</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>0.595730</td>\n",
       "      <td>0.557921</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.129979</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>-0.851685</td>\n",
       "      <td>-0.082443</td>\n",
       "      <td>0.481033</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>1.269531</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>-0.863260</td>\n",
       "      <td>-0.087556</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.032972</td>\n",
       "      <td>-0.127265</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.767609</td>\n",
       "      <td>0.315911</td>\n",
       "      <td>0.829373</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>-0.159836</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>3.255208</td>\n",
       "      <td>1.497396</td>\n",
       "      <td>4.882812</td>\n",
       "      <td>0.978578</td>\n",
       "      <td>-0.011643</td>\n",
       "      <td>-0.214437</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.033070</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>1.332562</td>\n",
       "      <td>1.412188</td>\n",
       "      <td>1.564734</td>\n",
       "      <td>0.164387</td>\n",
       "      <td>0.489069</td>\n",
       "      <td>0.149139</td>\n",
       "      <td>-0.843806</td>\n",
       "      <td>0.017119</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>1.069198</td>\n",
       "      <td>0.359047</td>\n",
       "      <td>3.737106</td>\n",
       "      <td>82.193580</td>\n",
       "      <td>32.208885</td>\n",
       "      <td>239.397135</td>\n",
       "      <td>0.163401</td>\n",
       "      <td>0.488814</td>\n",
       "      <td>0.148589</td>\n",
       "      <td>-0.843968</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>-0.015940</td>\n",
       "      <td>0.053926</td>\n",
       "      <td>-0.009795</td>\n",
       "      <td>-0.600410</td>\n",
       "      <td>5.515140</td>\n",
       "      <td>-2.263555</td>\n",
       "      <td>-78.920406</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.039351</td>\n",
       "      <td>0.349265</td>\n",
       "      <td>0.199957</td>\n",
       "      <td>3.356053</td>\n",
       "      <td>28.594942</td>\n",
       "      <td>22.130483</td>\n",
       "      <td>387.474946</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>-0.172680</td>\n",
       "      <td>-0.754349</td>\n",
       "      <td>-0.129973</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.639932</td>\n",
       "      <td>0.123348</td>\n",
       "      <td>6.634552</td>\n",
       "      <td>29.010612</td>\n",
       "      <td>8.634400</td>\n",
       "      <td>390.558345</td>\n",
       "      <td>1737.411968</td>\n",
       "      <td>1014.450133</td>\n",
       "      <td>0.612322</td>\n",
       "      <td>-0.174153</td>\n",
       "      <td>-0.759667</td>\n",
       "      <td>-0.132584</td>\n",
       "      <td>0.064927</td>\n",
       "      <td>0.173797</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.545506</td>\n",
       "      <td>0.469424</td>\n",
       "      <td>-38.355687</td>\n",
       "      <td>-116.846738</td>\n",
       "      <td>31.652380</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.081710</td>\n",
       "      <td>0.263328</td>\n",
       "      <td>0.059114</td>\n",
       "      <td>3.805955</td>\n",
       "      <td>14.013769</td>\n",
       "      <td>3.991494</td>\n",
       "      <td>286.560303</td>\n",
       "      <td>1163.025607</td>\n",
       "      <td>416.481477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497288</td>\n",
       "      <td>0.612981</td>\n",
       "      <td>0.666096</td>\n",
       "      <td>0.492485</td>\n",
       "      <td>0.718599</td>\n",
       "      <td>0.637199</td>\n",
       "      <td>0.748633</td>\n",
       "      <td>0.660694</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.497019</td>\n",
       "      <td>0.849392</td>\n",
       "      <td>0.694069</td>\n",
       "      <td>0.635642</td>\n",
       "      <td>0.491512</td>\n",
       "      <td>0.481447</td>\n",
       "      <td>0.598588</td>\n",
       "      <td>0.558258</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.248909</td>\n",
       "      <td>0.021109</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>-0.852661</td>\n",
       "      <td>-0.069260</td>\n",
       "      <td>0.488846</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>1.190186</td>\n",
       "      <td>3.580729</td>\n",
       "      <td>-0.863777</td>\n",
       "      <td>-0.083736</td>\n",
       "      <td>0.466213</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.153993</td>\n",
       "      <td>-0.121061</td>\n",
       "      <td>0.190012</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.786785</td>\n",
       "      <td>0.730909</td>\n",
       "      <td>1.224636</td>\n",
       "      <td>0.978836</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-0.194992</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>1.499721</td>\n",
       "      <td>3.320312</td>\n",
       "      <td>1.538086</td>\n",
       "      <td>0.960434</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>-0.283493</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>-0.090111</td>\n",
       "      <td>-0.170325</td>\n",
       "      <td>-0.513206</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.647672</td>\n",
       "      <td>1.856248</td>\n",
       "      <td>1.061945</td>\n",
       "      <td>0.161008</td>\n",
       "      <td>0.491087</td>\n",
       "      <td>0.146981</td>\n",
       "      <td>-0.844000</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.074743</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>8.423988</td>\n",
       "      <td>6.857490</td>\n",
       "      <td>10.689540</td>\n",
       "      <td>2084.369900</td>\n",
       "      <td>445.379626</td>\n",
       "      <td>810.506826</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>0.490398</td>\n",
       "      <td>0.145404</td>\n",
       "      <td>-0.844300</td>\n",
       "      <td>-0.015225</td>\n",
       "      <td>-0.003469</td>\n",
       "      <td>-0.034162</td>\n",
       "      <td>-0.120960</td>\n",
       "      <td>0.290009</td>\n",
       "      <td>0.374324</td>\n",
       "      <td>93.112872</td>\n",
       "      <td>-17.906684</td>\n",
       "      <td>-89.828683</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.053938</td>\n",
       "      <td>0.034739</td>\n",
       "      <td>0.102911</td>\n",
       "      <td>3.290633</td>\n",
       "      <td>2.509275</td>\n",
       "      <td>5.346618</td>\n",
       "      <td>569.794893</td>\n",
       "      <td>233.907640</td>\n",
       "      <td>724.458119</td>\n",
       "      <td>0.616119</td>\n",
       "      <td>-0.150822</td>\n",
       "      <td>-0.756967</td>\n",
       "      <td>-0.114060</td>\n",
       "      <td>0.127904</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>0.553013</td>\n",
       "      <td>11.380460</td>\n",
       "      <td>19.065811</td>\n",
       "      <td>33.358820</td>\n",
       "      <td>2752.365093</td>\n",
       "      <td>6546.331906</td>\n",
       "      <td>2181.850987</td>\n",
       "      <td>0.589230</td>\n",
       "      <td>-0.162392</td>\n",
       "      <td>-0.781897</td>\n",
       "      <td>-0.120935</td>\n",
       "      <td>-0.114952</td>\n",
       "      <td>-0.433918</td>\n",
       "      <td>0.152484</td>\n",
       "      <td>-1.879316</td>\n",
       "      <td>-0.969483</td>\n",
       "      <td>-0.855661</td>\n",
       "      <td>-52.559265</td>\n",
       "      <td>182.877900</td>\n",
       "      <td>-68.388209</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.013219</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.194634</td>\n",
       "      <td>0.334024</td>\n",
       "      <td>0.186514</td>\n",
       "      <td>10.515282</td>\n",
       "      <td>18.821526</td>\n",
       "      <td>13.561651</td>\n",
       "      <td>1118.669177</td>\n",
       "      <td>2037.005773</td>\n",
       "      <td>1044.511045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  clothes_id  property_id property_name  interaction_id  \\\n",
       "0               7          14            0    smoothness               1   \n",
       "1               7          14            0    smoothness               1   \n",
       "2               7          14            0    smoothness               1   \n",
       "3               7          14            0    smoothness               1   \n",
       "4               7          14            0    smoothness               1   \n",
       "\n",
       "   rating rating_level  rating_level_num  sub_window_num  slice_num  \\\n",
       "0       3       medium                 2               1          1   \n",
       "1       3       medium                 2               1          2   \n",
       "2       3       medium                 2               1          3   \n",
       "3       3       medium                 2               2          1   \n",
       "4       3       medium                 2               2          2   \n",
       "\n",
       "   max_ch1_hand0  max_ch2_hand0  max_ch3_hand0  max_ch4_hand0  max_ch5_hand0  \\\n",
       "0       0.500000       0.620513       0.675978       0.495868       0.759036   \n",
       "1       0.504132       0.615385       0.675978       0.495868       0.746988   \n",
       "2       0.500000       0.620513       0.670391       0.500000       0.740964   \n",
       "3       0.500000       0.620513       0.675978       0.495868       0.759036   \n",
       "4       0.504132       0.620513       0.675978       0.500000       0.746988   \n",
       "\n",
       "   max_ch6_hand0  max_ch7_hand0  max_ch8_hand0  mean_ch1_hand0  \\\n",
       "0       0.652406        0.76250       0.666667        0.497558   \n",
       "1       0.652406        0.76250       0.666667        0.497598   \n",
       "2       0.652406        0.75625       0.666667        0.497347   \n",
       "3       0.663102        0.75625       0.666667        0.497443   \n",
       "4       0.652406        0.75625       0.666667        0.497288   \n",
       "\n",
       "   mean_ch2_hand0  mean_ch3_hand0  mean_ch4_hand0  mean_ch5_hand0  \\\n",
       "0        0.612908        0.665979        0.492323        0.718373   \n",
       "1        0.612596        0.665782        0.492407        0.718562   \n",
       "2        0.612820        0.665915        0.492135        0.718647   \n",
       "3        0.612821        0.666131        0.492175        0.718675   \n",
       "4        0.612981        0.666096        0.492485        0.718599   \n",
       "\n",
       "   mean_ch6_hand0  mean_ch7_hand0  mean_ch8_hand0  std_ch1_hand0  \\\n",
       "0        0.636455        0.748970        0.661048       0.002307   \n",
       "1        0.637166        0.748672        0.660660       0.002384   \n",
       "2        0.637123        0.748899        0.660448       0.002305   \n",
       "3        0.637099        0.748906        0.660243       0.002216   \n",
       "4        0.637199        0.748633        0.660694       0.002410   \n",
       "\n",
       "   std_ch2_hand0  std_ch3_hand0  std_ch4_hand0  std_ch5_hand0  std_ch6_hand0  \\\n",
       "0       0.002685       0.003138       0.002326       0.007215       0.004555   \n",
       "1       0.002809       0.003041       0.002118       0.005858       0.004164   \n",
       "2       0.002796       0.002866       0.002150       0.005362       0.004111   \n",
       "3       0.002933       0.002905       0.001944       0.006295       0.004133   \n",
       "4       0.002631       0.002747       0.002533       0.007066       0.004893   \n",
       "\n",
       "   std_ch7_hand0  std_ch8_hand0  max_ch1_hand1  max_ch2_hand1  max_ch3_hand1  \\\n",
       "0       0.003543       0.002655       0.508197       0.929578       0.757225   \n",
       "1       0.004050       0.002641       0.504098       0.880282       0.739884   \n",
       "2       0.003325       0.002466       0.508197       0.908451       0.757225   \n",
       "3       0.002764       0.002610       0.508197       0.929578       0.809249   \n",
       "4       0.003338       0.002610       0.508197       0.957746       0.809249   \n",
       "\n",
       "   max_ch4_hand1  max_ch5_hand1  max_ch6_hand1  max_ch7_hand1  max_ch8_hand1  \\\n",
       "0       0.730159       0.497959       0.995918       0.648515       0.576037   \n",
       "1       0.677249       0.493878       0.787755       0.638614       0.576037   \n",
       "2       0.714286       0.497959       0.714286       0.663366       0.580645   \n",
       "3       0.661376       0.493878       0.820408       0.623762       0.571429   \n",
       "4       0.746032       0.497959       0.995918       0.683168       0.576037   \n",
       "\n",
       "   mean_ch1_hand1  mean_ch2_hand1  mean_ch3_hand1  mean_ch4_hand1  \\\n",
       "0        0.497131        0.848195        0.691944        0.635252   \n",
       "1        0.496903        0.848111        0.691901        0.634861   \n",
       "2        0.497276        0.849152        0.692361        0.634500   \n",
       "3        0.496850        0.848415        0.691944        0.633830   \n",
       "4        0.497019        0.849392        0.694069        0.635642   \n",
       "\n",
       "   mean_ch5_hand1  mean_ch6_hand1  mean_ch7_hand1  mean_ch8_hand1  \\\n",
       "0        0.491607        0.526964        0.597308        0.558093   \n",
       "1        0.491535        0.511201        0.596760        0.557892   \n",
       "2        0.491582        0.497936        0.596169        0.558075   \n",
       "3        0.491046        0.475204        0.595730        0.557921   \n",
       "4        0.491512        0.481447        0.598588        0.558258   \n",
       "\n",
       "   std_ch1_hand1  std_ch2_hand1  std_ch3_hand1  std_ch4_hand1  std_ch5_hand1  \\\n",
       "0       0.003403       0.011867       0.012139       0.020191       0.002323   \n",
       "1       0.002710       0.007046       0.009382       0.011783       0.002204   \n",
       "2       0.003055       0.010252       0.012065       0.015567       0.002336   \n",
       "3       0.002842       0.009768       0.012697       0.006141       0.002243   \n",
       "4       0.004213       0.017909       0.026751       0.023597       0.002201   \n",
       "\n",
       "   std_ch6_hand1  std_ch7_hand1  std_ch8_hand1  max_Ax_hand0  max_Ay_hand0  \\\n",
       "0       0.156897       0.015387       0.005509     -0.852173     -0.068771   \n",
       "1       0.112410       0.012228       0.005028     -0.850708     -0.075119   \n",
       "2       0.102318       0.015758       0.004804     -0.856079     -0.077072   \n",
       "3       0.129979       0.007751       0.004568     -0.851685     -0.082443   \n",
       "4       0.248909       0.021109       0.005739     -0.852661     -0.069260   \n",
       "\n",
       "   max_Az_hand0  max_Vx_hand0  max_Vy_hand0  max_Vz_hand0  max_Jx_hand0  \\\n",
       "0      0.481033      0.000330      0.000281      0.000349      0.906808   \n",
       "1      0.490311      0.000403      0.000406      0.000343      1.269531   \n",
       "2      0.484940      0.000525      0.000313      0.000903      0.839844   \n",
       "3      0.481033      0.000448      0.000117      0.000328      1.269531   \n",
       "4      0.488846      0.000316      0.000305      0.000813      2.929688   \n",
       "\n",
       "   max_Jy_hand0  max_Jz_hand0  mean_Ax_hand0  mean_Ay_hand0  mean_Az_hand0  \\\n",
       "0      0.944010      1.878005      -0.863647      -0.092331       0.468185   \n",
       "1      0.600962      1.098633      -0.863087      -0.088216       0.469860   \n",
       "2      1.220703      2.258301      -0.865184      -0.087125       0.466327   \n",
       "3      0.683594      1.171875      -0.863260      -0.087556       0.466011   \n",
       "4      1.190186      3.580729      -0.863777      -0.083736       0.466213   \n",
       "\n",
       "   mean_Vx_hand0  mean_Vy_hand0  mean_Vz_hand0  mean_Jx_hand0  mean_Jy_hand0  \\\n",
       "0      -0.000014       0.000033      -0.000021       0.018182       0.033422   \n",
       "1       0.000011      -0.000004      -0.000019       0.079838      -0.067655   \n",
       "2      -0.000012       0.000017       0.000004      -0.129092      -0.117662   \n",
       "3      -0.000028      -0.000003      -0.000023       0.038070       0.032972   \n",
       "4       0.000008       0.000003      -0.000002       0.153993      -0.121061   \n",
       "\n",
       "   mean_Jz_hand0  std_Ax_hand0  std_Ay_hand0  std_Az_hand0  std_Vx_hand0  \\\n",
       "0       0.090670      0.006859      0.010176      0.008799      0.000187   \n",
       "1       0.037227      0.006643      0.006718      0.009974      0.000201   \n",
       "2       0.054163      0.007685      0.007728      0.011771      0.000223   \n",
       "3      -0.127265      0.007256      0.003642      0.009516      0.000249   \n",
       "4       0.190012      0.006393      0.005995      0.011556      0.000169   \n",
       "\n",
       "   std_Vy_hand0  std_Vz_hand0  std_Jx_hand0  std_Jy_hand0  std_Jz_hand0  \\\n",
       "0      0.000229      0.000238      0.488839      0.644995      0.731794   \n",
       "1      0.000152      0.000263      0.576461      0.332292      0.625069   \n",
       "2      0.000161      0.000317      0.720689      0.840380      1.018423   \n",
       "3      0.000092      0.000241      0.767609      0.315911      0.829373   \n",
       "4      0.000144      0.000347      0.786785      0.730909      1.224636   \n",
       "\n",
       "   max_Ax_hand1  max_Ay_hand1  max_Az_hand1  max_Vx_hand1  max_Vy_hand1  \\\n",
       "0      0.992020      0.013489     -0.198410      0.001218      0.000510   \n",
       "1      1.023270      0.007141     -0.178879      0.000690      0.000342   \n",
       "2      0.992996      0.042786     -0.183762      0.000722      0.001529   \n",
       "3      0.999344      0.010071     -0.159836      0.001031      0.000981   \n",
       "4      0.978836      0.062317     -0.194992      0.000294      0.001328   \n",
       "\n",
       "   max_Vz_hand1  max_Jx_hand1  max_Jy_hand1  max_Jz_hand1  mean_Ax_hand1  \\\n",
       "0      0.001187      1.448006      1.255580      2.343750       0.970749   \n",
       "1      0.001220      4.089355      4.516602      2.050781       0.972543   \n",
       "2      0.001429      3.417969      5.468750      3.271484       0.967148   \n",
       "3      0.001074      3.255208      1.497396      4.882812       0.978578   \n",
       "4      0.000615      1.499721      3.320312      1.538086       0.960434   \n",
       "\n",
       "   mean_Ay_hand1  mean_Az_hand1  mean_Vx_hand1  mean_Vy_hand1  mean_Vz_hand1  \\\n",
       "0      -0.013306      -0.239548       0.000030      -0.000022       0.000121   \n",
       "1      -0.014126      -0.223475      -0.000086      -0.000022       0.000048   \n",
       "2      -0.006561      -0.256119      -0.000028       0.000021       0.000029   \n",
       "3      -0.011643      -0.214437       0.000044       0.000030       0.000044   \n",
       "4      -0.001343      -0.283493      -0.000016       0.000107      -0.000194   \n",
       "\n",
       "   mean_Jx_hand1  mean_Jy_hand1  mean_Jz_hand1  std_Ax_hand1  std_Ay_hand1  \\\n",
       "0       0.039065      -0.063439       0.154164      0.016338      0.011627   \n",
       "1       0.125395       0.071997      -0.521592      0.017047      0.013548   \n",
       "2       0.011150       0.095838      -0.098997      0.018756      0.018785   \n",
       "3      -0.033070      -0.195312       0.415176      0.012129      0.011884   \n",
       "4      -0.090111      -0.170325      -0.513206      0.009143      0.024698   \n",
       "\n",
       "   std_Az_hand1  std_Vx_hand1  std_Vy_hand1  std_Vz_hand1  std_Jx_hand1  \\\n",
       "0      0.024494      0.000461      0.000354      0.000641      0.865981   \n",
       "1      0.035703      0.000446      0.000254      0.000520      1.606256   \n",
       "2      0.034782      0.000430      0.000606      0.000787      1.235726   \n",
       "3      0.025199      0.000345      0.000351      0.000478      1.332562   \n",
       "4      0.045012      0.000182      0.000575      0.000444      0.647672   \n",
       "\n",
       "   std_Jy_hand1  std_Jz_hand1  max_w_hand0  max_x_hand0  max_y_hand0  \\\n",
       "0      0.887638      1.211894     0.179352     0.486364     0.160615   \n",
       "1      1.455990      2.292596     0.172172     0.487007     0.155308   \n",
       "2      1.721460      2.255044     0.170321     0.488418     0.154120   \n",
       "3      1.412188      1.564734     0.164387     0.489069     0.149139   \n",
       "4      1.856248      1.061945     0.161008     0.491087     0.146981   \n",
       "\n",
       "   max_z_hand0  max_AVx_hand0  max_AVy_hand0  max_AVz_hand0  max_AAx_hand0  \\\n",
       "0    -0.840857       0.133141       0.061469       0.117029       4.332320   \n",
       "1    -0.842296       0.051942       0.046418       0.042930       2.314447   \n",
       "2    -0.842468       0.019373       0.020976       0.074771       1.380191   \n",
       "3    -0.843806       0.017119       0.003250       0.031410       1.069198   \n",
       "4    -0.844000       0.051026       0.074743       0.071737       8.423988   \n",
       "\n",
       "   max_AAy_hand0  max_AAz_hand0  max_AJx_hand0  max_AJy_hand0  max_AJz_hand0  \\\n",
       "0       2.887801      19.812834     554.574503     268.044509    1338.775861   \n",
       "1       2.108342      11.379475     116.744319     285.209816     662.709244   \n",
       "2       2.377551      17.101885     142.026745     316.450316     946.725089   \n",
       "3       0.359047       3.737106      82.193580      32.208885     239.397135   \n",
       "4       6.857490      10.689540    2084.369900     445.379626     810.506826   \n",
       "\n",
       "   mean_w_hand0  mean_x_hand0  mean_y_hand0  mean_z_hand0  mean_AVx_hand0  \\\n",
       "0      0.176140      0.485378      0.158694     -0.841542       -0.003855   \n",
       "1      0.171507      0.486343      0.154797     -0.842670        0.004716   \n",
       "2      0.167272      0.487757      0.151733     -0.843257       -0.008024   \n",
       "3      0.163401      0.488814      0.148589     -0.843968        0.000744   \n",
       "4      0.159754      0.490398      0.145404     -0.844300       -0.015225   \n",
       "\n",
       "   mean_AVy_hand0  mean_AVz_hand0  mean_AAx_hand0  mean_AAy_hand0  \\\n",
       "0       -0.006977       -0.063971       -0.440979        0.013134   \n",
       "1       -0.005843       -0.013206        0.113415        0.014472   \n",
       "2       -0.006670       -0.037785        0.098066        0.091191   \n",
       "3       -0.001663       -0.015940        0.053926       -0.009795   \n",
       "4       -0.003469       -0.034162       -0.120960        0.290009   \n",
       "\n",
       "   mean_AAz_hand0  mean_AJx_hand0  mean_AJy_hand0  mean_AJz_hand0  \\\n",
       "0       -0.200017      -49.406882      -39.838054       68.564941   \n",
       "1        0.318994      -10.224520        5.586727      -32.269925   \n",
       "2        0.496310        1.145841       14.267186       53.811503   \n",
       "3       -0.600410        5.515140       -2.263555      -78.920406   \n",
       "4        0.374324       93.112872      -17.906684      -89.828683   \n",
       "\n",
       "   std_w_hand0  std_x_hand0  std_y_hand0  std_z_hand0  std_AVx_hand0  \\\n",
       "0     0.002032     0.000740     0.001425     0.000338       0.053708   \n",
       "1     0.000346     0.000413     0.000428     0.000225       0.022519   \n",
       "2     0.002303     0.000457     0.001921     0.000555       0.015705   \n",
       "3     0.000710     0.000178     0.000382     0.000108       0.005741   \n",
       "4     0.001106     0.000628     0.001142     0.000149       0.053938   \n",
       "\n",
       "   std_AVy_hand0  std_AVz_hand0  std_AAx_hand0  std_AAy_hand0  std_AAz_hand0  \\\n",
       "0       0.033528       0.137260       2.915747       1.852018       9.040299   \n",
       "1       0.031592       0.057136       1.075061       1.239390       3.810758   \n",
       "2       0.015094       0.091587       0.830795       0.905251       6.214045   \n",
       "3       0.003118       0.039351       0.349265       0.199957       3.356053   \n",
       "4       0.034739       0.102911       3.290633       2.509275       5.346618   \n",
       "\n",
       "   std_AJx_hand0  std_AJy_hand0  std_AJz_hand0  max_w_hand1  max_x_hand1  \\\n",
       "0     366.140398     183.977327     777.818352     0.613327    -0.175326   \n",
       "1      96.909431     121.285133     445.406712     0.618680    -0.176746   \n",
       "2      66.340108      88.938460     482.557393     0.601940    -0.175697   \n",
       "3      28.594942      22.130483     387.474946     0.618863    -0.172680   \n",
       "4     569.794893     233.907640     724.458119     0.616119    -0.150822   \n",
       "\n",
       "   max_y_hand1  max_z_hand1  max_AVx_hand1  max_AVy_hand1  max_AVz_hand1  \\\n",
       "0    -0.758505    -0.128901       0.140072       0.440644       0.126734   \n",
       "1    -0.753378    -0.131839       0.173872       0.564510       0.275227   \n",
       "2    -0.767520    -0.129289       0.215491       0.583907       0.121185   \n",
       "3    -0.754349    -0.129973       0.196768       0.639932       0.123348   \n",
       "4    -0.756967    -0.114060       0.127904       0.027888       0.553013   \n",
       "\n",
       "   max_AAx_hand1  max_AAy_hand1  max_AAz_hand1  max_AJx_hand1  max_AJy_hand1  \\\n",
       "0       5.745156      20.612016      10.404938     649.805789    1527.420437   \n",
       "1      21.603607      56.450019      29.424453    2797.763022    9050.317251   \n",
       "2      10.175411      32.381460      10.444407    1816.649881    3178.222952   \n",
       "3       6.634552      29.010612       8.634400     390.558345    1737.411968   \n",
       "4      11.380460      19.065811      33.358820    2752.365093    6546.331906   \n",
       "\n",
       "   max_AJz_hand1  mean_w_hand1  mean_x_hand1  mean_y_hand1  mean_z_hand1  \\\n",
       "0     579.105295      0.602803     -0.176687     -0.767038     -0.130432   \n",
       "1    2366.953044      0.608297     -0.178584     -0.761680     -0.133563   \n",
       "2     752.825555      0.597125     -0.176453     -0.771524     -0.130548   \n",
       "3    1014.450133      0.612322     -0.174153     -0.759667     -0.132584   \n",
       "4    2181.850987      0.589230     -0.162392     -0.781897     -0.120935   \n",
       "\n",
       "   mean_AVx_hand1  mean_AVy_hand1  mean_AVz_hand1  mean_AAx_hand1  \\\n",
       "0        0.044346        0.166936       -0.015194        0.369931   \n",
       "1       -0.060590       -0.221805       -0.010201       -1.404595   \n",
       "2       -0.010970       -0.027380        0.025762       -0.953930   \n",
       "3        0.064927        0.173797       -0.004880        0.031692   \n",
       "4       -0.114952       -0.433918        0.152484       -1.879316   \n",
       "\n",
       "   mean_AAy_hand1  mean_AAz_hand1  mean_AJx_hand1  mean_AJy_hand1  \\\n",
       "0        0.966866       -0.768253        7.370830      -55.778711   \n",
       "1       -2.048076       -0.808920      126.811149      415.913816   \n",
       "2       -1.770620        0.301481      -89.444296     -117.306912   \n",
       "3        0.545506        0.469424      -38.355687     -116.846738   \n",
       "4       -0.969483       -0.855661      -52.559265      182.877900   \n",
       "\n",
       "   mean_AJz_hand1  std_w_hand1  std_x_hand1  std_y_hand1  std_z_hand1  \\\n",
       "0      -31.980447     0.005596     0.000748     0.004593     0.001061   \n",
       "1     -126.597961     0.007344     0.001289     0.005919     0.000823   \n",
       "2       -2.283264     0.002735     0.000653     0.002287     0.001059   \n",
       "3       31.652380     0.006002     0.001024     0.004882     0.001771   \n",
       "4      -68.388209     0.013831     0.008176     0.013219     0.006777   \n",
       "\n",
       "   std_AVx_hand1  std_AVy_hand1  std_AVz_hand1  std_AAx_hand1  std_AAy_hand1  \\\n",
       "0       0.067368       0.186562       0.113020       3.575537      10.023728   \n",
       "1       0.182445       0.547463       0.138415      10.896145      27.572112   \n",
       "2       0.125296       0.339485       0.061387       9.044185      21.643801   \n",
       "3       0.081710       0.263328       0.059114       3.805955      14.013769   \n",
       "4       0.194634       0.334024       0.186514      10.515282      18.821526   \n",
       "\n",
       "   std_AAz_hand1  std_AJx_hand1  std_AJy_hand1  std_AJz_hand1  \n",
       "0       6.617085     245.110349     738.475924     504.671766  \n",
       "1      11.192973    1060.610623    2679.860678    1386.692345  \n",
       "2       4.656397     757.940949    1626.093435     437.046180  \n",
       "3       3.991494     286.560303    1163.025607     416.481477  \n",
       "4      13.561651    1118.669177    2037.005773    1044.511045  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5904c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af1e878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_ch1_hand0</th>\n",
       "      <th>max_ch2_hand0</th>\n",
       "      <th>max_ch3_hand0</th>\n",
       "      <th>max_ch4_hand0</th>\n",
       "      <th>max_ch5_hand0</th>\n",
       "      <th>max_ch6_hand0</th>\n",
       "      <th>max_ch7_hand0</th>\n",
       "      <th>max_ch8_hand0</th>\n",
       "      <th>mean_ch1_hand0</th>\n",
       "      <th>mean_ch2_hand0</th>\n",
       "      <th>mean_ch3_hand0</th>\n",
       "      <th>mean_ch4_hand0</th>\n",
       "      <th>mean_ch5_hand0</th>\n",
       "      <th>mean_ch6_hand0</th>\n",
       "      <th>mean_ch7_hand0</th>\n",
       "      <th>mean_ch8_hand0</th>\n",
       "      <th>std_ch1_hand0</th>\n",
       "      <th>std_ch2_hand0</th>\n",
       "      <th>std_ch3_hand0</th>\n",
       "      <th>std_ch4_hand0</th>\n",
       "      <th>std_ch5_hand0</th>\n",
       "      <th>std_ch6_hand0</th>\n",
       "      <th>std_ch7_hand0</th>\n",
       "      <th>std_ch8_hand0</th>\n",
       "      <th>max_ch1_hand1</th>\n",
       "      <th>max_ch2_hand1</th>\n",
       "      <th>max_ch3_hand1</th>\n",
       "      <th>max_ch4_hand1</th>\n",
       "      <th>max_ch5_hand1</th>\n",
       "      <th>max_ch6_hand1</th>\n",
       "      <th>max_ch7_hand1</th>\n",
       "      <th>max_ch8_hand1</th>\n",
       "      <th>mean_ch1_hand1</th>\n",
       "      <th>mean_ch2_hand1</th>\n",
       "      <th>mean_ch3_hand1</th>\n",
       "      <th>mean_ch4_hand1</th>\n",
       "      <th>mean_ch5_hand1</th>\n",
       "      <th>mean_ch6_hand1</th>\n",
       "      <th>mean_ch7_hand1</th>\n",
       "      <th>mean_ch8_hand1</th>\n",
       "      <th>std_ch1_hand1</th>\n",
       "      <th>std_ch2_hand1</th>\n",
       "      <th>std_ch3_hand1</th>\n",
       "      <th>std_ch4_hand1</th>\n",
       "      <th>std_ch5_hand1</th>\n",
       "      <th>std_ch6_hand1</th>\n",
       "      <th>std_ch7_hand1</th>\n",
       "      <th>std_ch8_hand1</th>\n",
       "      <th>max_Ax_hand0</th>\n",
       "      <th>max_Ay_hand0</th>\n",
       "      <th>max_Az_hand0</th>\n",
       "      <th>max_Vx_hand0</th>\n",
       "      <th>max_Vy_hand0</th>\n",
       "      <th>max_Vz_hand0</th>\n",
       "      <th>max_Jx_hand0</th>\n",
       "      <th>max_Jy_hand0</th>\n",
       "      <th>max_Jz_hand0</th>\n",
       "      <th>mean_Ax_hand0</th>\n",
       "      <th>mean_Ay_hand0</th>\n",
       "      <th>mean_Az_hand0</th>\n",
       "      <th>mean_Vx_hand0</th>\n",
       "      <th>mean_Vy_hand0</th>\n",
       "      <th>mean_Vz_hand0</th>\n",
       "      <th>mean_Jx_hand0</th>\n",
       "      <th>mean_Jy_hand0</th>\n",
       "      <th>mean_Jz_hand0</th>\n",
       "      <th>std_Ax_hand0</th>\n",
       "      <th>std_Ay_hand0</th>\n",
       "      <th>std_Az_hand0</th>\n",
       "      <th>std_Vx_hand0</th>\n",
       "      <th>std_Vy_hand0</th>\n",
       "      <th>std_Vz_hand0</th>\n",
       "      <th>std_Jx_hand0</th>\n",
       "      <th>std_Jy_hand0</th>\n",
       "      <th>std_Jz_hand0</th>\n",
       "      <th>max_Ax_hand1</th>\n",
       "      <th>max_Ay_hand1</th>\n",
       "      <th>max_Az_hand1</th>\n",
       "      <th>max_Vx_hand1</th>\n",
       "      <th>max_Vy_hand1</th>\n",
       "      <th>max_Vz_hand1</th>\n",
       "      <th>max_Jx_hand1</th>\n",
       "      <th>max_Jy_hand1</th>\n",
       "      <th>max_Jz_hand1</th>\n",
       "      <th>mean_Ax_hand1</th>\n",
       "      <th>mean_Ay_hand1</th>\n",
       "      <th>mean_Az_hand1</th>\n",
       "      <th>mean_Vx_hand1</th>\n",
       "      <th>mean_Vy_hand1</th>\n",
       "      <th>mean_Vz_hand1</th>\n",
       "      <th>mean_Jx_hand1</th>\n",
       "      <th>mean_Jy_hand1</th>\n",
       "      <th>mean_Jz_hand1</th>\n",
       "      <th>std_Ax_hand1</th>\n",
       "      <th>std_Ay_hand1</th>\n",
       "      <th>std_Az_hand1</th>\n",
       "      <th>std_Vx_hand1</th>\n",
       "      <th>std_Vy_hand1</th>\n",
       "      <th>std_Vz_hand1</th>\n",
       "      <th>std_Jx_hand1</th>\n",
       "      <th>std_Jy_hand1</th>\n",
       "      <th>std_Jz_hand1</th>\n",
       "      <th>max_w_hand0</th>\n",
       "      <th>max_x_hand0</th>\n",
       "      <th>max_y_hand0</th>\n",
       "      <th>max_z_hand0</th>\n",
       "      <th>max_AVx_hand0</th>\n",
       "      <th>max_AVy_hand0</th>\n",
       "      <th>max_AVz_hand0</th>\n",
       "      <th>max_AAx_hand0</th>\n",
       "      <th>max_AAy_hand0</th>\n",
       "      <th>max_AAz_hand0</th>\n",
       "      <th>max_AJx_hand0</th>\n",
       "      <th>max_AJy_hand0</th>\n",
       "      <th>max_AJz_hand0</th>\n",
       "      <th>mean_w_hand0</th>\n",
       "      <th>mean_x_hand0</th>\n",
       "      <th>mean_y_hand0</th>\n",
       "      <th>mean_z_hand0</th>\n",
       "      <th>mean_AVx_hand0</th>\n",
       "      <th>mean_AVy_hand0</th>\n",
       "      <th>mean_AVz_hand0</th>\n",
       "      <th>mean_AAx_hand0</th>\n",
       "      <th>mean_AAy_hand0</th>\n",
       "      <th>mean_AAz_hand0</th>\n",
       "      <th>mean_AJx_hand0</th>\n",
       "      <th>mean_AJy_hand0</th>\n",
       "      <th>mean_AJz_hand0</th>\n",
       "      <th>std_w_hand0</th>\n",
       "      <th>std_x_hand0</th>\n",
       "      <th>std_y_hand0</th>\n",
       "      <th>std_z_hand0</th>\n",
       "      <th>std_AVx_hand0</th>\n",
       "      <th>std_AVy_hand0</th>\n",
       "      <th>std_AVz_hand0</th>\n",
       "      <th>std_AAx_hand0</th>\n",
       "      <th>std_AAy_hand0</th>\n",
       "      <th>std_AAz_hand0</th>\n",
       "      <th>std_AJx_hand0</th>\n",
       "      <th>std_AJy_hand0</th>\n",
       "      <th>std_AJz_hand0</th>\n",
       "      <th>max_w_hand1</th>\n",
       "      <th>max_x_hand1</th>\n",
       "      <th>max_y_hand1</th>\n",
       "      <th>max_z_hand1</th>\n",
       "      <th>max_AVx_hand1</th>\n",
       "      <th>max_AVy_hand1</th>\n",
       "      <th>max_AVz_hand1</th>\n",
       "      <th>max_AAx_hand1</th>\n",
       "      <th>max_AAy_hand1</th>\n",
       "      <th>max_AAz_hand1</th>\n",
       "      <th>max_AJx_hand1</th>\n",
       "      <th>max_AJy_hand1</th>\n",
       "      <th>max_AJz_hand1</th>\n",
       "      <th>mean_w_hand1</th>\n",
       "      <th>mean_x_hand1</th>\n",
       "      <th>mean_y_hand1</th>\n",
       "      <th>mean_z_hand1</th>\n",
       "      <th>mean_AVx_hand1</th>\n",
       "      <th>mean_AVy_hand1</th>\n",
       "      <th>mean_AVz_hand1</th>\n",
       "      <th>mean_AAx_hand1</th>\n",
       "      <th>mean_AAy_hand1</th>\n",
       "      <th>mean_AAz_hand1</th>\n",
       "      <th>mean_AJx_hand1</th>\n",
       "      <th>mean_AJy_hand1</th>\n",
       "      <th>mean_AJz_hand1</th>\n",
       "      <th>std_w_hand1</th>\n",
       "      <th>std_x_hand1</th>\n",
       "      <th>std_y_hand1</th>\n",
       "      <th>std_z_hand1</th>\n",
       "      <th>std_AVx_hand1</th>\n",
       "      <th>std_AVy_hand1</th>\n",
       "      <th>std_AVz_hand1</th>\n",
       "      <th>std_AAx_hand1</th>\n",
       "      <th>std_AAy_hand1</th>\n",
       "      <th>std_AAz_hand1</th>\n",
       "      <th>std_AJx_hand1</th>\n",
       "      <th>std_AJy_hand1</th>\n",
       "      <th>std_AJz_hand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497558</td>\n",
       "      <td>0.612908</td>\n",
       "      <td>0.665979</td>\n",
       "      <td>0.492323</td>\n",
       "      <td>0.718373</td>\n",
       "      <td>0.636455</td>\n",
       "      <td>0.748970</td>\n",
       "      <td>0.661048</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.007215</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.929578</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.648515</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.497131</td>\n",
       "      <td>0.848195</td>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.635252</td>\n",
       "      <td>0.491607</td>\n",
       "      <td>0.526964</td>\n",
       "      <td>0.597308</td>\n",
       "      <td>0.558093</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.011867</td>\n",
       "      <td>0.012139</td>\n",
       "      <td>0.020191</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.156897</td>\n",
       "      <td>0.015387</td>\n",
       "      <td>0.005509</td>\n",
       "      <td>-0.852173</td>\n",
       "      <td>-0.068771</td>\n",
       "      <td>0.481033</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.906808</td>\n",
       "      <td>0.944010</td>\n",
       "      <td>1.878005</td>\n",
       "      <td>-0.863647</td>\n",
       "      <td>-0.092331</td>\n",
       "      <td>0.468185</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.090670</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.488839</td>\n",
       "      <td>0.644995</td>\n",
       "      <td>0.731794</td>\n",
       "      <td>0.992020</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>-0.198410</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.001187</td>\n",
       "      <td>1.448006</td>\n",
       "      <td>1.255580</td>\n",
       "      <td>2.343750</td>\n",
       "      <td>0.970749</td>\n",
       "      <td>-0.013306</td>\n",
       "      <td>-0.239548</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.039065</td>\n",
       "      <td>-0.063439</td>\n",
       "      <td>0.154164</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>0.011627</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.865981</td>\n",
       "      <td>0.887638</td>\n",
       "      <td>1.211894</td>\n",
       "      <td>0.179352</td>\n",
       "      <td>0.486364</td>\n",
       "      <td>0.160615</td>\n",
       "      <td>-0.840857</td>\n",
       "      <td>0.133141</td>\n",
       "      <td>0.061469</td>\n",
       "      <td>0.117029</td>\n",
       "      <td>4.332320</td>\n",
       "      <td>2.887801</td>\n",
       "      <td>19.812834</td>\n",
       "      <td>554.574503</td>\n",
       "      <td>268.044509</td>\n",
       "      <td>1338.775861</td>\n",
       "      <td>0.176140</td>\n",
       "      <td>0.485378</td>\n",
       "      <td>0.158694</td>\n",
       "      <td>-0.841542</td>\n",
       "      <td>-0.003855</td>\n",
       "      <td>-0.006977</td>\n",
       "      <td>-0.063971</td>\n",
       "      <td>-0.440979</td>\n",
       "      <td>0.013134</td>\n",
       "      <td>-0.200017</td>\n",
       "      <td>-49.406882</td>\n",
       "      <td>-39.838054</td>\n",
       "      <td>68.564941</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>0.001425</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>0.033528</td>\n",
       "      <td>0.137260</td>\n",
       "      <td>2.915747</td>\n",
       "      <td>1.852018</td>\n",
       "      <td>9.040299</td>\n",
       "      <td>366.140398</td>\n",
       "      <td>183.977327</td>\n",
       "      <td>777.818352</td>\n",
       "      <td>0.613327</td>\n",
       "      <td>-0.175326</td>\n",
       "      <td>-0.758505</td>\n",
       "      <td>-0.128901</td>\n",
       "      <td>0.140072</td>\n",
       "      <td>0.440644</td>\n",
       "      <td>0.126734</td>\n",
       "      <td>5.745156</td>\n",
       "      <td>20.612016</td>\n",
       "      <td>10.404938</td>\n",
       "      <td>649.805789</td>\n",
       "      <td>1527.420437</td>\n",
       "      <td>579.105295</td>\n",
       "      <td>0.602803</td>\n",
       "      <td>-0.176687</td>\n",
       "      <td>-0.767038</td>\n",
       "      <td>-0.130432</td>\n",
       "      <td>0.044346</td>\n",
       "      <td>0.166936</td>\n",
       "      <td>-0.015194</td>\n",
       "      <td>0.369931</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>-0.768253</td>\n",
       "      <td>7.370830</td>\n",
       "      <td>-55.778711</td>\n",
       "      <td>-31.980447</td>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.067368</td>\n",
       "      <td>0.186562</td>\n",
       "      <td>0.113020</td>\n",
       "      <td>3.575537</td>\n",
       "      <td>10.023728</td>\n",
       "      <td>6.617085</td>\n",
       "      <td>245.110349</td>\n",
       "      <td>738.475924</td>\n",
       "      <td>504.671766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.76250</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497598</td>\n",
       "      <td>0.612596</td>\n",
       "      <td>0.665782</td>\n",
       "      <td>0.492407</td>\n",
       "      <td>0.718562</td>\n",
       "      <td>0.637166</td>\n",
       "      <td>0.748672</td>\n",
       "      <td>0.660660</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.504098</td>\n",
       "      <td>0.880282</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.677249</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.787755</td>\n",
       "      <td>0.638614</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.496903</td>\n",
       "      <td>0.848111</td>\n",
       "      <td>0.691901</td>\n",
       "      <td>0.634861</td>\n",
       "      <td>0.491535</td>\n",
       "      <td>0.511201</td>\n",
       "      <td>0.596760</td>\n",
       "      <td>0.557892</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.007046</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.112410</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.005028</td>\n",
       "      <td>-0.850708</td>\n",
       "      <td>-0.075119</td>\n",
       "      <td>0.490311</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>1.269531</td>\n",
       "      <td>0.600962</td>\n",
       "      <td>1.098633</td>\n",
       "      <td>-0.863087</td>\n",
       "      <td>-0.088216</td>\n",
       "      <td>0.469860</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.079838</td>\n",
       "      <td>-0.067655</td>\n",
       "      <td>0.037227</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.006718</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.576461</td>\n",
       "      <td>0.332292</td>\n",
       "      <td>0.625069</td>\n",
       "      <td>1.023270</td>\n",
       "      <td>0.007141</td>\n",
       "      <td>-0.178879</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>4.089355</td>\n",
       "      <td>4.516602</td>\n",
       "      <td>2.050781</td>\n",
       "      <td>0.972543</td>\n",
       "      <td>-0.014126</td>\n",
       "      <td>-0.223475</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.125395</td>\n",
       "      <td>0.071997</td>\n",
       "      <td>-0.521592</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>1.606256</td>\n",
       "      <td>1.455990</td>\n",
       "      <td>2.292596</td>\n",
       "      <td>0.172172</td>\n",
       "      <td>0.487007</td>\n",
       "      <td>0.155308</td>\n",
       "      <td>-0.842296</td>\n",
       "      <td>0.051942</td>\n",
       "      <td>0.046418</td>\n",
       "      <td>0.042930</td>\n",
       "      <td>2.314447</td>\n",
       "      <td>2.108342</td>\n",
       "      <td>11.379475</td>\n",
       "      <td>116.744319</td>\n",
       "      <td>285.209816</td>\n",
       "      <td>662.709244</td>\n",
       "      <td>0.171507</td>\n",
       "      <td>0.486343</td>\n",
       "      <td>0.154797</td>\n",
       "      <td>-0.842670</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>-0.005843</td>\n",
       "      <td>-0.013206</td>\n",
       "      <td>0.113415</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.318994</td>\n",
       "      <td>-10.224520</td>\n",
       "      <td>5.586727</td>\n",
       "      <td>-32.269925</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.022519</td>\n",
       "      <td>0.031592</td>\n",
       "      <td>0.057136</td>\n",
       "      <td>1.075061</td>\n",
       "      <td>1.239390</td>\n",
       "      <td>3.810758</td>\n",
       "      <td>96.909431</td>\n",
       "      <td>121.285133</td>\n",
       "      <td>445.406712</td>\n",
       "      <td>0.618680</td>\n",
       "      <td>-0.176746</td>\n",
       "      <td>-0.753378</td>\n",
       "      <td>-0.131839</td>\n",
       "      <td>0.173872</td>\n",
       "      <td>0.564510</td>\n",
       "      <td>0.275227</td>\n",
       "      <td>21.603607</td>\n",
       "      <td>56.450019</td>\n",
       "      <td>29.424453</td>\n",
       "      <td>2797.763022</td>\n",
       "      <td>9050.317251</td>\n",
       "      <td>2366.953044</td>\n",
       "      <td>0.608297</td>\n",
       "      <td>-0.178584</td>\n",
       "      <td>-0.761680</td>\n",
       "      <td>-0.133563</td>\n",
       "      <td>-0.060590</td>\n",
       "      <td>-0.221805</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.404595</td>\n",
       "      <td>-2.048076</td>\n",
       "      <td>-0.808920</td>\n",
       "      <td>126.811149</td>\n",
       "      <td>415.913816</td>\n",
       "      <td>-126.597961</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.005919</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>0.182445</td>\n",
       "      <td>0.547463</td>\n",
       "      <td>0.138415</td>\n",
       "      <td>10.896145</td>\n",
       "      <td>27.572112</td>\n",
       "      <td>11.192973</td>\n",
       "      <td>1060.610623</td>\n",
       "      <td>2679.860678</td>\n",
       "      <td>1386.692345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.670391</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.740964</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497347</td>\n",
       "      <td>0.612820</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0.492135</td>\n",
       "      <td>0.718647</td>\n",
       "      <td>0.637123</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>0.660448</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.908451</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.663366</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.497276</td>\n",
       "      <td>0.849152</td>\n",
       "      <td>0.692361</td>\n",
       "      <td>0.634500</td>\n",
       "      <td>0.491582</td>\n",
       "      <td>0.497936</td>\n",
       "      <td>0.596169</td>\n",
       "      <td>0.558075</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.010252</td>\n",
       "      <td>0.012065</td>\n",
       "      <td>0.015567</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.102318</td>\n",
       "      <td>0.015758</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>-0.856079</td>\n",
       "      <td>-0.077072</td>\n",
       "      <td>0.484940</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.839844</td>\n",
       "      <td>1.220703</td>\n",
       "      <td>2.258301</td>\n",
       "      <td>-0.865184</td>\n",
       "      <td>-0.087125</td>\n",
       "      <td>0.466327</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.129092</td>\n",
       "      <td>-0.117662</td>\n",
       "      <td>0.054163</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>0.007728</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.720689</td>\n",
       "      <td>0.840380</td>\n",
       "      <td>1.018423</td>\n",
       "      <td>0.992996</td>\n",
       "      <td>0.042786</td>\n",
       "      <td>-0.183762</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.001529</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>3.417969</td>\n",
       "      <td>5.468750</td>\n",
       "      <td>3.271484</td>\n",
       "      <td>0.967148</td>\n",
       "      <td>-0.006561</td>\n",
       "      <td>-0.256119</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.011150</td>\n",
       "      <td>0.095838</td>\n",
       "      <td>-0.098997</td>\n",
       "      <td>0.018756</td>\n",
       "      <td>0.018785</td>\n",
       "      <td>0.034782</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>1.235726</td>\n",
       "      <td>1.721460</td>\n",
       "      <td>2.255044</td>\n",
       "      <td>0.170321</td>\n",
       "      <td>0.488418</td>\n",
       "      <td>0.154120</td>\n",
       "      <td>-0.842468</td>\n",
       "      <td>0.019373</td>\n",
       "      <td>0.020976</td>\n",
       "      <td>0.074771</td>\n",
       "      <td>1.380191</td>\n",
       "      <td>2.377551</td>\n",
       "      <td>17.101885</td>\n",
       "      <td>142.026745</td>\n",
       "      <td>316.450316</td>\n",
       "      <td>946.725089</td>\n",
       "      <td>0.167272</td>\n",
       "      <td>0.487757</td>\n",
       "      <td>0.151733</td>\n",
       "      <td>-0.843257</td>\n",
       "      <td>-0.008024</td>\n",
       "      <td>-0.006670</td>\n",
       "      <td>-0.037785</td>\n",
       "      <td>0.098066</td>\n",
       "      <td>0.091191</td>\n",
       "      <td>0.496310</td>\n",
       "      <td>1.145841</td>\n",
       "      <td>14.267186</td>\n",
       "      <td>53.811503</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.015705</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.091587</td>\n",
       "      <td>0.830795</td>\n",
       "      <td>0.905251</td>\n",
       "      <td>6.214045</td>\n",
       "      <td>66.340108</td>\n",
       "      <td>88.938460</td>\n",
       "      <td>482.557393</td>\n",
       "      <td>0.601940</td>\n",
       "      <td>-0.175697</td>\n",
       "      <td>-0.767520</td>\n",
       "      <td>-0.129289</td>\n",
       "      <td>0.215491</td>\n",
       "      <td>0.583907</td>\n",
       "      <td>0.121185</td>\n",
       "      <td>10.175411</td>\n",
       "      <td>32.381460</td>\n",
       "      <td>10.444407</td>\n",
       "      <td>1816.649881</td>\n",
       "      <td>3178.222952</td>\n",
       "      <td>752.825555</td>\n",
       "      <td>0.597125</td>\n",
       "      <td>-0.176453</td>\n",
       "      <td>-0.771524</td>\n",
       "      <td>-0.130548</td>\n",
       "      <td>-0.010970</td>\n",
       "      <td>-0.027380</td>\n",
       "      <td>0.025762</td>\n",
       "      <td>-0.953930</td>\n",
       "      <td>-1.770620</td>\n",
       "      <td>0.301481</td>\n",
       "      <td>-89.444296</td>\n",
       "      <td>-117.306912</td>\n",
       "      <td>-2.283264</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.125296</td>\n",
       "      <td>0.339485</td>\n",
       "      <td>0.061387</td>\n",
       "      <td>9.044185</td>\n",
       "      <td>21.643801</td>\n",
       "      <td>4.656397</td>\n",
       "      <td>757.940949</td>\n",
       "      <td>1626.093435</td>\n",
       "      <td>437.046180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.663102</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497443</td>\n",
       "      <td>0.612821</td>\n",
       "      <td>0.666131</td>\n",
       "      <td>0.492175</td>\n",
       "      <td>0.718675</td>\n",
       "      <td>0.637099</td>\n",
       "      <td>0.748906</td>\n",
       "      <td>0.660243</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.929578</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.661376</td>\n",
       "      <td>0.493878</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.623762</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.496850</td>\n",
       "      <td>0.848415</td>\n",
       "      <td>0.691944</td>\n",
       "      <td>0.633830</td>\n",
       "      <td>0.491046</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>0.595730</td>\n",
       "      <td>0.557921</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.009768</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.129979</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>-0.851685</td>\n",
       "      <td>-0.082443</td>\n",
       "      <td>0.481033</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>1.269531</td>\n",
       "      <td>0.683594</td>\n",
       "      <td>1.171875</td>\n",
       "      <td>-0.863260</td>\n",
       "      <td>-0.087556</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.032972</td>\n",
       "      <td>-0.127265</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.003642</td>\n",
       "      <td>0.009516</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.767609</td>\n",
       "      <td>0.315911</td>\n",
       "      <td>0.829373</td>\n",
       "      <td>0.999344</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>-0.159836</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>3.255208</td>\n",
       "      <td>1.497396</td>\n",
       "      <td>4.882812</td>\n",
       "      <td>0.978578</td>\n",
       "      <td>-0.011643</td>\n",
       "      <td>-0.214437</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.033070</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>0.415176</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.025199</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>1.332562</td>\n",
       "      <td>1.412188</td>\n",
       "      <td>1.564734</td>\n",
       "      <td>0.164387</td>\n",
       "      <td>0.489069</td>\n",
       "      <td>0.149139</td>\n",
       "      <td>-0.843806</td>\n",
       "      <td>0.017119</td>\n",
       "      <td>0.003250</td>\n",
       "      <td>0.031410</td>\n",
       "      <td>1.069198</td>\n",
       "      <td>0.359047</td>\n",
       "      <td>3.737106</td>\n",
       "      <td>82.193580</td>\n",
       "      <td>32.208885</td>\n",
       "      <td>239.397135</td>\n",
       "      <td>0.163401</td>\n",
       "      <td>0.488814</td>\n",
       "      <td>0.148589</td>\n",
       "      <td>-0.843968</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>-0.015940</td>\n",
       "      <td>0.053926</td>\n",
       "      <td>-0.009795</td>\n",
       "      <td>-0.600410</td>\n",
       "      <td>5.515140</td>\n",
       "      <td>-2.263555</td>\n",
       "      <td>-78.920406</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.039351</td>\n",
       "      <td>0.349265</td>\n",
       "      <td>0.199957</td>\n",
       "      <td>3.356053</td>\n",
       "      <td>28.594942</td>\n",
       "      <td>22.130483</td>\n",
       "      <td>387.474946</td>\n",
       "      <td>0.618863</td>\n",
       "      <td>-0.172680</td>\n",
       "      <td>-0.754349</td>\n",
       "      <td>-0.129973</td>\n",
       "      <td>0.196768</td>\n",
       "      <td>0.639932</td>\n",
       "      <td>0.123348</td>\n",
       "      <td>6.634552</td>\n",
       "      <td>29.010612</td>\n",
       "      <td>8.634400</td>\n",
       "      <td>390.558345</td>\n",
       "      <td>1737.411968</td>\n",
       "      <td>1014.450133</td>\n",
       "      <td>0.612322</td>\n",
       "      <td>-0.174153</td>\n",
       "      <td>-0.759667</td>\n",
       "      <td>-0.132584</td>\n",
       "      <td>0.064927</td>\n",
       "      <td>0.173797</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>0.031692</td>\n",
       "      <td>0.545506</td>\n",
       "      <td>0.469424</td>\n",
       "      <td>-38.355687</td>\n",
       "      <td>-116.846738</td>\n",
       "      <td>31.652380</td>\n",
       "      <td>0.006002</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.004882</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.081710</td>\n",
       "      <td>0.263328</td>\n",
       "      <td>0.059114</td>\n",
       "      <td>3.805955</td>\n",
       "      <td>14.013769</td>\n",
       "      <td>3.991494</td>\n",
       "      <td>286.560303</td>\n",
       "      <td>1163.025607</td>\n",
       "      <td>416.481477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.504132</td>\n",
       "      <td>0.620513</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.652406</td>\n",
       "      <td>0.75625</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.497288</td>\n",
       "      <td>0.612981</td>\n",
       "      <td>0.666096</td>\n",
       "      <td>0.492485</td>\n",
       "      <td>0.718599</td>\n",
       "      <td>0.637199</td>\n",
       "      <td>0.748633</td>\n",
       "      <td>0.660694</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.007066</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>0.003338</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.508197</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.497959</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.497019</td>\n",
       "      <td>0.849392</td>\n",
       "      <td>0.694069</td>\n",
       "      <td>0.635642</td>\n",
       "      <td>0.491512</td>\n",
       "      <td>0.481447</td>\n",
       "      <td>0.598588</td>\n",
       "      <td>0.558258</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>0.017909</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.248909</td>\n",
       "      <td>0.021109</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>-0.852661</td>\n",
       "      <td>-0.069260</td>\n",
       "      <td>0.488846</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>1.190186</td>\n",
       "      <td>3.580729</td>\n",
       "      <td>-0.863777</td>\n",
       "      <td>-0.083736</td>\n",
       "      <td>0.466213</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.153993</td>\n",
       "      <td>-0.121061</td>\n",
       "      <td>0.190012</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.786785</td>\n",
       "      <td>0.730909</td>\n",
       "      <td>1.224636</td>\n",
       "      <td>0.978836</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>-0.194992</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>1.499721</td>\n",
       "      <td>3.320312</td>\n",
       "      <td>1.538086</td>\n",
       "      <td>0.960434</td>\n",
       "      <td>-0.001343</td>\n",
       "      <td>-0.283493</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>-0.090111</td>\n",
       "      <td>-0.170325</td>\n",
       "      <td>-0.513206</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.024698</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.647672</td>\n",
       "      <td>1.856248</td>\n",
       "      <td>1.061945</td>\n",
       "      <td>0.161008</td>\n",
       "      <td>0.491087</td>\n",
       "      <td>0.146981</td>\n",
       "      <td>-0.844000</td>\n",
       "      <td>0.051026</td>\n",
       "      <td>0.074743</td>\n",
       "      <td>0.071737</td>\n",
       "      <td>8.423988</td>\n",
       "      <td>6.857490</td>\n",
       "      <td>10.689540</td>\n",
       "      <td>2084.369900</td>\n",
       "      <td>445.379626</td>\n",
       "      <td>810.506826</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>0.490398</td>\n",
       "      <td>0.145404</td>\n",
       "      <td>-0.844300</td>\n",
       "      <td>-0.015225</td>\n",
       "      <td>-0.003469</td>\n",
       "      <td>-0.034162</td>\n",
       "      <td>-0.120960</td>\n",
       "      <td>0.290009</td>\n",
       "      <td>0.374324</td>\n",
       "      <td>93.112872</td>\n",
       "      <td>-17.906684</td>\n",
       "      <td>-89.828683</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.053938</td>\n",
       "      <td>0.034739</td>\n",
       "      <td>0.102911</td>\n",
       "      <td>3.290633</td>\n",
       "      <td>2.509275</td>\n",
       "      <td>5.346618</td>\n",
       "      <td>569.794893</td>\n",
       "      <td>233.907640</td>\n",
       "      <td>724.458119</td>\n",
       "      <td>0.616119</td>\n",
       "      <td>-0.150822</td>\n",
       "      <td>-0.756967</td>\n",
       "      <td>-0.114060</td>\n",
       "      <td>0.127904</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>0.553013</td>\n",
       "      <td>11.380460</td>\n",
       "      <td>19.065811</td>\n",
       "      <td>33.358820</td>\n",
       "      <td>2752.365093</td>\n",
       "      <td>6546.331906</td>\n",
       "      <td>2181.850987</td>\n",
       "      <td>0.589230</td>\n",
       "      <td>-0.162392</td>\n",
       "      <td>-0.781897</td>\n",
       "      <td>-0.120935</td>\n",
       "      <td>-0.114952</td>\n",
       "      <td>-0.433918</td>\n",
       "      <td>0.152484</td>\n",
       "      <td>-1.879316</td>\n",
       "      <td>-0.969483</td>\n",
       "      <td>-0.855661</td>\n",
       "      <td>-52.559265</td>\n",
       "      <td>182.877900</td>\n",
       "      <td>-68.388209</td>\n",
       "      <td>0.013831</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.013219</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.194634</td>\n",
       "      <td>0.334024</td>\n",
       "      <td>0.186514</td>\n",
       "      <td>10.515282</td>\n",
       "      <td>18.821526</td>\n",
       "      <td>13.561651</td>\n",
       "      <td>1118.669177</td>\n",
       "      <td>2037.005773</td>\n",
       "      <td>1044.511045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_ch1_hand0  max_ch2_hand0  max_ch3_hand0  max_ch4_hand0  max_ch5_hand0  \\\n",
       "0       0.500000       0.620513       0.675978       0.495868       0.759036   \n",
       "1       0.504132       0.615385       0.675978       0.495868       0.746988   \n",
       "2       0.500000       0.620513       0.670391       0.500000       0.740964   \n",
       "3       0.500000       0.620513       0.675978       0.495868       0.759036   \n",
       "4       0.504132       0.620513       0.675978       0.500000       0.746988   \n",
       "\n",
       "   max_ch6_hand0  max_ch7_hand0  max_ch8_hand0  mean_ch1_hand0  \\\n",
       "0       0.652406        0.76250       0.666667        0.497558   \n",
       "1       0.652406        0.76250       0.666667        0.497598   \n",
       "2       0.652406        0.75625       0.666667        0.497347   \n",
       "3       0.663102        0.75625       0.666667        0.497443   \n",
       "4       0.652406        0.75625       0.666667        0.497288   \n",
       "\n",
       "   mean_ch2_hand0  mean_ch3_hand0  mean_ch4_hand0  mean_ch5_hand0  \\\n",
       "0        0.612908        0.665979        0.492323        0.718373   \n",
       "1        0.612596        0.665782        0.492407        0.718562   \n",
       "2        0.612820        0.665915        0.492135        0.718647   \n",
       "3        0.612821        0.666131        0.492175        0.718675   \n",
       "4        0.612981        0.666096        0.492485        0.718599   \n",
       "\n",
       "   mean_ch6_hand0  mean_ch7_hand0  mean_ch8_hand0  std_ch1_hand0  \\\n",
       "0        0.636455        0.748970        0.661048       0.002307   \n",
       "1        0.637166        0.748672        0.660660       0.002384   \n",
       "2        0.637123        0.748899        0.660448       0.002305   \n",
       "3        0.637099        0.748906        0.660243       0.002216   \n",
       "4        0.637199        0.748633        0.660694       0.002410   \n",
       "\n",
       "   std_ch2_hand0  std_ch3_hand0  std_ch4_hand0  std_ch5_hand0  std_ch6_hand0  \\\n",
       "0       0.002685       0.003138       0.002326       0.007215       0.004555   \n",
       "1       0.002809       0.003041       0.002118       0.005858       0.004164   \n",
       "2       0.002796       0.002866       0.002150       0.005362       0.004111   \n",
       "3       0.002933       0.002905       0.001944       0.006295       0.004133   \n",
       "4       0.002631       0.002747       0.002533       0.007066       0.004893   \n",
       "\n",
       "   std_ch7_hand0  std_ch8_hand0  max_ch1_hand1  max_ch2_hand1  max_ch3_hand1  \\\n",
       "0       0.003543       0.002655       0.508197       0.929578       0.757225   \n",
       "1       0.004050       0.002641       0.504098       0.880282       0.739884   \n",
       "2       0.003325       0.002466       0.508197       0.908451       0.757225   \n",
       "3       0.002764       0.002610       0.508197       0.929578       0.809249   \n",
       "4       0.003338       0.002610       0.508197       0.957746       0.809249   \n",
       "\n",
       "   max_ch4_hand1  max_ch5_hand1  max_ch6_hand1  max_ch7_hand1  max_ch8_hand1  \\\n",
       "0       0.730159       0.497959       0.995918       0.648515       0.576037   \n",
       "1       0.677249       0.493878       0.787755       0.638614       0.576037   \n",
       "2       0.714286       0.497959       0.714286       0.663366       0.580645   \n",
       "3       0.661376       0.493878       0.820408       0.623762       0.571429   \n",
       "4       0.746032       0.497959       0.995918       0.683168       0.576037   \n",
       "\n",
       "   mean_ch1_hand1  mean_ch2_hand1  mean_ch3_hand1  mean_ch4_hand1  \\\n",
       "0        0.497131        0.848195        0.691944        0.635252   \n",
       "1        0.496903        0.848111        0.691901        0.634861   \n",
       "2        0.497276        0.849152        0.692361        0.634500   \n",
       "3        0.496850        0.848415        0.691944        0.633830   \n",
       "4        0.497019        0.849392        0.694069        0.635642   \n",
       "\n",
       "   mean_ch5_hand1  mean_ch6_hand1  mean_ch7_hand1  mean_ch8_hand1  \\\n",
       "0        0.491607        0.526964        0.597308        0.558093   \n",
       "1        0.491535        0.511201        0.596760        0.557892   \n",
       "2        0.491582        0.497936        0.596169        0.558075   \n",
       "3        0.491046        0.475204        0.595730        0.557921   \n",
       "4        0.491512        0.481447        0.598588        0.558258   \n",
       "\n",
       "   std_ch1_hand1  std_ch2_hand1  std_ch3_hand1  std_ch4_hand1  std_ch5_hand1  \\\n",
       "0       0.003403       0.011867       0.012139       0.020191       0.002323   \n",
       "1       0.002710       0.007046       0.009382       0.011783       0.002204   \n",
       "2       0.003055       0.010252       0.012065       0.015567       0.002336   \n",
       "3       0.002842       0.009768       0.012697       0.006141       0.002243   \n",
       "4       0.004213       0.017909       0.026751       0.023597       0.002201   \n",
       "\n",
       "   std_ch6_hand1  std_ch7_hand1  std_ch8_hand1  max_Ax_hand0  max_Ay_hand0  \\\n",
       "0       0.156897       0.015387       0.005509     -0.852173     -0.068771   \n",
       "1       0.112410       0.012228       0.005028     -0.850708     -0.075119   \n",
       "2       0.102318       0.015758       0.004804     -0.856079     -0.077072   \n",
       "3       0.129979       0.007751       0.004568     -0.851685     -0.082443   \n",
       "4       0.248909       0.021109       0.005739     -0.852661     -0.069260   \n",
       "\n",
       "   max_Az_hand0  max_Vx_hand0  max_Vy_hand0  max_Vz_hand0  max_Jx_hand0  \\\n",
       "0      0.481033      0.000330      0.000281      0.000349      0.906808   \n",
       "1      0.490311      0.000403      0.000406      0.000343      1.269531   \n",
       "2      0.484940      0.000525      0.000313      0.000903      0.839844   \n",
       "3      0.481033      0.000448      0.000117      0.000328      1.269531   \n",
       "4      0.488846      0.000316      0.000305      0.000813      2.929688   \n",
       "\n",
       "   max_Jy_hand0  max_Jz_hand0  mean_Ax_hand0  mean_Ay_hand0  mean_Az_hand0  \\\n",
       "0      0.944010      1.878005      -0.863647      -0.092331       0.468185   \n",
       "1      0.600962      1.098633      -0.863087      -0.088216       0.469860   \n",
       "2      1.220703      2.258301      -0.865184      -0.087125       0.466327   \n",
       "3      0.683594      1.171875      -0.863260      -0.087556       0.466011   \n",
       "4      1.190186      3.580729      -0.863777      -0.083736       0.466213   \n",
       "\n",
       "   mean_Vx_hand0  mean_Vy_hand0  mean_Vz_hand0  mean_Jx_hand0  mean_Jy_hand0  \\\n",
       "0      -0.000014       0.000033      -0.000021       0.018182       0.033422   \n",
       "1       0.000011      -0.000004      -0.000019       0.079838      -0.067655   \n",
       "2      -0.000012       0.000017       0.000004      -0.129092      -0.117662   \n",
       "3      -0.000028      -0.000003      -0.000023       0.038070       0.032972   \n",
       "4       0.000008       0.000003      -0.000002       0.153993      -0.121061   \n",
       "\n",
       "   mean_Jz_hand0  std_Ax_hand0  std_Ay_hand0  std_Az_hand0  std_Vx_hand0  \\\n",
       "0       0.090670      0.006859      0.010176      0.008799      0.000187   \n",
       "1       0.037227      0.006643      0.006718      0.009974      0.000201   \n",
       "2       0.054163      0.007685      0.007728      0.011771      0.000223   \n",
       "3      -0.127265      0.007256      0.003642      0.009516      0.000249   \n",
       "4       0.190012      0.006393      0.005995      0.011556      0.000169   \n",
       "\n",
       "   std_Vy_hand0  std_Vz_hand0  std_Jx_hand0  std_Jy_hand0  std_Jz_hand0  \\\n",
       "0      0.000229      0.000238      0.488839      0.644995      0.731794   \n",
       "1      0.000152      0.000263      0.576461      0.332292      0.625069   \n",
       "2      0.000161      0.000317      0.720689      0.840380      1.018423   \n",
       "3      0.000092      0.000241      0.767609      0.315911      0.829373   \n",
       "4      0.000144      0.000347      0.786785      0.730909      1.224636   \n",
       "\n",
       "   max_Ax_hand1  max_Ay_hand1  max_Az_hand1  max_Vx_hand1  max_Vy_hand1  \\\n",
       "0      0.992020      0.013489     -0.198410      0.001218      0.000510   \n",
       "1      1.023270      0.007141     -0.178879      0.000690      0.000342   \n",
       "2      0.992996      0.042786     -0.183762      0.000722      0.001529   \n",
       "3      0.999344      0.010071     -0.159836      0.001031      0.000981   \n",
       "4      0.978836      0.062317     -0.194992      0.000294      0.001328   \n",
       "\n",
       "   max_Vz_hand1  max_Jx_hand1  max_Jy_hand1  max_Jz_hand1  mean_Ax_hand1  \\\n",
       "0      0.001187      1.448006      1.255580      2.343750       0.970749   \n",
       "1      0.001220      4.089355      4.516602      2.050781       0.972543   \n",
       "2      0.001429      3.417969      5.468750      3.271484       0.967148   \n",
       "3      0.001074      3.255208      1.497396      4.882812       0.978578   \n",
       "4      0.000615      1.499721      3.320312      1.538086       0.960434   \n",
       "\n",
       "   mean_Ay_hand1  mean_Az_hand1  mean_Vx_hand1  mean_Vy_hand1  mean_Vz_hand1  \\\n",
       "0      -0.013306      -0.239548       0.000030      -0.000022       0.000121   \n",
       "1      -0.014126      -0.223475      -0.000086      -0.000022       0.000048   \n",
       "2      -0.006561      -0.256119      -0.000028       0.000021       0.000029   \n",
       "3      -0.011643      -0.214437       0.000044       0.000030       0.000044   \n",
       "4      -0.001343      -0.283493      -0.000016       0.000107      -0.000194   \n",
       "\n",
       "   mean_Jx_hand1  mean_Jy_hand1  mean_Jz_hand1  std_Ax_hand1  std_Ay_hand1  \\\n",
       "0       0.039065      -0.063439       0.154164      0.016338      0.011627   \n",
       "1       0.125395       0.071997      -0.521592      0.017047      0.013548   \n",
       "2       0.011150       0.095838      -0.098997      0.018756      0.018785   \n",
       "3      -0.033070      -0.195312       0.415176      0.012129      0.011884   \n",
       "4      -0.090111      -0.170325      -0.513206      0.009143      0.024698   \n",
       "\n",
       "   std_Az_hand1  std_Vx_hand1  std_Vy_hand1  std_Vz_hand1  std_Jx_hand1  \\\n",
       "0      0.024494      0.000461      0.000354      0.000641      0.865981   \n",
       "1      0.035703      0.000446      0.000254      0.000520      1.606256   \n",
       "2      0.034782      0.000430      0.000606      0.000787      1.235726   \n",
       "3      0.025199      0.000345      0.000351      0.000478      1.332562   \n",
       "4      0.045012      0.000182      0.000575      0.000444      0.647672   \n",
       "\n",
       "   std_Jy_hand1  std_Jz_hand1  max_w_hand0  max_x_hand0  max_y_hand0  \\\n",
       "0      0.887638      1.211894     0.179352     0.486364     0.160615   \n",
       "1      1.455990      2.292596     0.172172     0.487007     0.155308   \n",
       "2      1.721460      2.255044     0.170321     0.488418     0.154120   \n",
       "3      1.412188      1.564734     0.164387     0.489069     0.149139   \n",
       "4      1.856248      1.061945     0.161008     0.491087     0.146981   \n",
       "\n",
       "   max_z_hand0  max_AVx_hand0  max_AVy_hand0  max_AVz_hand0  max_AAx_hand0  \\\n",
       "0    -0.840857       0.133141       0.061469       0.117029       4.332320   \n",
       "1    -0.842296       0.051942       0.046418       0.042930       2.314447   \n",
       "2    -0.842468       0.019373       0.020976       0.074771       1.380191   \n",
       "3    -0.843806       0.017119       0.003250       0.031410       1.069198   \n",
       "4    -0.844000       0.051026       0.074743       0.071737       8.423988   \n",
       "\n",
       "   max_AAy_hand0  max_AAz_hand0  max_AJx_hand0  max_AJy_hand0  max_AJz_hand0  \\\n",
       "0       2.887801      19.812834     554.574503     268.044509    1338.775861   \n",
       "1       2.108342      11.379475     116.744319     285.209816     662.709244   \n",
       "2       2.377551      17.101885     142.026745     316.450316     946.725089   \n",
       "3       0.359047       3.737106      82.193580      32.208885     239.397135   \n",
       "4       6.857490      10.689540    2084.369900     445.379626     810.506826   \n",
       "\n",
       "   mean_w_hand0  mean_x_hand0  mean_y_hand0  mean_z_hand0  mean_AVx_hand0  \\\n",
       "0      0.176140      0.485378      0.158694     -0.841542       -0.003855   \n",
       "1      0.171507      0.486343      0.154797     -0.842670        0.004716   \n",
       "2      0.167272      0.487757      0.151733     -0.843257       -0.008024   \n",
       "3      0.163401      0.488814      0.148589     -0.843968        0.000744   \n",
       "4      0.159754      0.490398      0.145404     -0.844300       -0.015225   \n",
       "\n",
       "   mean_AVy_hand0  mean_AVz_hand0  mean_AAx_hand0  mean_AAy_hand0  \\\n",
       "0       -0.006977       -0.063971       -0.440979        0.013134   \n",
       "1       -0.005843       -0.013206        0.113415        0.014472   \n",
       "2       -0.006670       -0.037785        0.098066        0.091191   \n",
       "3       -0.001663       -0.015940        0.053926       -0.009795   \n",
       "4       -0.003469       -0.034162       -0.120960        0.290009   \n",
       "\n",
       "   mean_AAz_hand0  mean_AJx_hand0  mean_AJy_hand0  mean_AJz_hand0  \\\n",
       "0       -0.200017      -49.406882      -39.838054       68.564941   \n",
       "1        0.318994      -10.224520        5.586727      -32.269925   \n",
       "2        0.496310        1.145841       14.267186       53.811503   \n",
       "3       -0.600410        5.515140       -2.263555      -78.920406   \n",
       "4        0.374324       93.112872      -17.906684      -89.828683   \n",
       "\n",
       "   std_w_hand0  std_x_hand0  std_y_hand0  std_z_hand0  std_AVx_hand0  \\\n",
       "0     0.002032     0.000740     0.001425     0.000338       0.053708   \n",
       "1     0.000346     0.000413     0.000428     0.000225       0.022519   \n",
       "2     0.002303     0.000457     0.001921     0.000555       0.015705   \n",
       "3     0.000710     0.000178     0.000382     0.000108       0.005741   \n",
       "4     0.001106     0.000628     0.001142     0.000149       0.053938   \n",
       "\n",
       "   std_AVy_hand0  std_AVz_hand0  std_AAx_hand0  std_AAy_hand0  std_AAz_hand0  \\\n",
       "0       0.033528       0.137260       2.915747       1.852018       9.040299   \n",
       "1       0.031592       0.057136       1.075061       1.239390       3.810758   \n",
       "2       0.015094       0.091587       0.830795       0.905251       6.214045   \n",
       "3       0.003118       0.039351       0.349265       0.199957       3.356053   \n",
       "4       0.034739       0.102911       3.290633       2.509275       5.346618   \n",
       "\n",
       "   std_AJx_hand0  std_AJy_hand0  std_AJz_hand0  max_w_hand1  max_x_hand1  \\\n",
       "0     366.140398     183.977327     777.818352     0.613327    -0.175326   \n",
       "1      96.909431     121.285133     445.406712     0.618680    -0.176746   \n",
       "2      66.340108      88.938460     482.557393     0.601940    -0.175697   \n",
       "3      28.594942      22.130483     387.474946     0.618863    -0.172680   \n",
       "4     569.794893     233.907640     724.458119     0.616119    -0.150822   \n",
       "\n",
       "   max_y_hand1  max_z_hand1  max_AVx_hand1  max_AVy_hand1  max_AVz_hand1  \\\n",
       "0    -0.758505    -0.128901       0.140072       0.440644       0.126734   \n",
       "1    -0.753378    -0.131839       0.173872       0.564510       0.275227   \n",
       "2    -0.767520    -0.129289       0.215491       0.583907       0.121185   \n",
       "3    -0.754349    -0.129973       0.196768       0.639932       0.123348   \n",
       "4    -0.756967    -0.114060       0.127904       0.027888       0.553013   \n",
       "\n",
       "   max_AAx_hand1  max_AAy_hand1  max_AAz_hand1  max_AJx_hand1  max_AJy_hand1  \\\n",
       "0       5.745156      20.612016      10.404938     649.805789    1527.420437   \n",
       "1      21.603607      56.450019      29.424453    2797.763022    9050.317251   \n",
       "2      10.175411      32.381460      10.444407    1816.649881    3178.222952   \n",
       "3       6.634552      29.010612       8.634400     390.558345    1737.411968   \n",
       "4      11.380460      19.065811      33.358820    2752.365093    6546.331906   \n",
       "\n",
       "   max_AJz_hand1  mean_w_hand1  mean_x_hand1  mean_y_hand1  mean_z_hand1  \\\n",
       "0     579.105295      0.602803     -0.176687     -0.767038     -0.130432   \n",
       "1    2366.953044      0.608297     -0.178584     -0.761680     -0.133563   \n",
       "2     752.825555      0.597125     -0.176453     -0.771524     -0.130548   \n",
       "3    1014.450133      0.612322     -0.174153     -0.759667     -0.132584   \n",
       "4    2181.850987      0.589230     -0.162392     -0.781897     -0.120935   \n",
       "\n",
       "   mean_AVx_hand1  mean_AVy_hand1  mean_AVz_hand1  mean_AAx_hand1  \\\n",
       "0        0.044346        0.166936       -0.015194        0.369931   \n",
       "1       -0.060590       -0.221805       -0.010201       -1.404595   \n",
       "2       -0.010970       -0.027380        0.025762       -0.953930   \n",
       "3        0.064927        0.173797       -0.004880        0.031692   \n",
       "4       -0.114952       -0.433918        0.152484       -1.879316   \n",
       "\n",
       "   mean_AAy_hand1  mean_AAz_hand1  mean_AJx_hand1  mean_AJy_hand1  \\\n",
       "0        0.966866       -0.768253        7.370830      -55.778711   \n",
       "1       -2.048076       -0.808920      126.811149      415.913816   \n",
       "2       -1.770620        0.301481      -89.444296     -117.306912   \n",
       "3        0.545506        0.469424      -38.355687     -116.846738   \n",
       "4       -0.969483       -0.855661      -52.559265      182.877900   \n",
       "\n",
       "   mean_AJz_hand1  std_w_hand1  std_x_hand1  std_y_hand1  std_z_hand1  \\\n",
       "0      -31.980447     0.005596     0.000748     0.004593     0.001061   \n",
       "1     -126.597961     0.007344     0.001289     0.005919     0.000823   \n",
       "2       -2.283264     0.002735     0.000653     0.002287     0.001059   \n",
       "3       31.652380     0.006002     0.001024     0.004882     0.001771   \n",
       "4      -68.388209     0.013831     0.008176     0.013219     0.006777   \n",
       "\n",
       "   std_AVx_hand1  std_AVy_hand1  std_AVz_hand1  std_AAx_hand1  std_AAy_hand1  \\\n",
       "0       0.067368       0.186562       0.113020       3.575537      10.023728   \n",
       "1       0.182445       0.547463       0.138415      10.896145      27.572112   \n",
       "2       0.125296       0.339485       0.061387       9.044185      21.643801   \n",
       "3       0.081710       0.263328       0.059114       3.805955      14.013769   \n",
       "4       0.194634       0.334024       0.186514      10.515282      18.821526   \n",
       "\n",
       "   std_AAz_hand1  std_AJx_hand1  std_AJy_hand1  std_AJz_hand1  \n",
       "0       6.617085     245.110349     738.475924     504.671766  \n",
       "1      11.192973    1060.610623    2679.860678    1386.692345  \n",
       "2       4.656397     757.940949    1626.093435     437.046180  \n",
       "3       3.991494     286.560303    1163.025607     416.481477  \n",
       "4      13.561651    1118.669177    2037.005773    1044.511045  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_index = 10\n",
    "# Obtain a df of features\n",
    "features_df = physical_df.iloc[:,starting_index:]\n",
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c004999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18899, 180)\n"
     ]
    }
   ],
   "source": [
    "normalised_features_df = features_df.copy()\n",
    "print(normalised_features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a33b68d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18899, 180)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1)) # As this is the range of the activation function - tanh\n",
    "\n",
    "# fit scaler and apply transform\n",
    "normalised_features_df[normalised_features_df.columns] = scaler.fit_transform(features_df[features_df.columns])\n",
    "normalised_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "220861a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_name</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_level</th>\n",
       "      <th>rating_level_num</th>\n",
       "      <th>sub_window_num</th>\n",
       "      <th>slice_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  clothes_id  property_id property_name  interaction_id  \\\n",
       "0               7          14            0    smoothness               1   \n",
       "1               7          14            0    smoothness               1   \n",
       "2               7          14            0    smoothness               1   \n",
       "3               7          14            0    smoothness               1   \n",
       "4               7          14            0    smoothness               1   \n",
       "\n",
       "   rating rating_level  rating_level_num  sub_window_num  slice_num  \n",
       "0       3       medium                 2               1          1  \n",
       "1       3       medium                 2               1          2  \n",
       "2       3       medium                 2               1          3  \n",
       "3       3       medium                 2               2          1  \n",
       "4       3       medium                 2               2          2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info = physical_df.iloc[:, :starting_index]\n",
    "df_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5731fee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18899, 190)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalised_df = pd.concat([df_info,normalised_features_df], axis=1)\n",
    "normalised_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651ad758",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff0e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_2d(df, features_starting_idx):\n",
    "    \n",
    "    X_2d = df.iloc[:,features_starting_idx:].values\n",
    "    \n",
    "    X_tensor_2d = torch.Tensor(X_2d)    \n",
    "    return X_tensor_2d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "640fd610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_train_for_2d_X(df, predicting_feature = 'property_id', output_as_tensor='Yes'):\n",
    "    # CreatE an instance of a one-hot-encoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Perform one-hot encoding on the specified column \n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(df[[predicting_feature]]).toarray())\n",
    "    \n",
    "    # Convert to a numpy array\n",
    "    y_train = encoder_df.to_numpy()\n",
    "    \n",
    "    if output_as_tensor == 'Yes':\n",
    "        # Convert to a tensor\n",
    "        y_train = torch.Tensor(y_train)\n",
    "\n",
    "    return y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27ae18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_test_for_2d_X(df, predicting_feature = 'property_id'):   \n",
    "    y_test = df[predicting_feature].values\n",
    "    #if predicting_feature == 'property_id':\n",
    "       # y_test = y_test - 3\n",
    "    if predicting_feature == 'rating_level_num':\n",
    "        y_test = y_test - 1\n",
    "    \n",
    "    y_test_tensor = torch.Tensor(y_test)    \n",
    "    y_test_tensor = y_test_tensor.type(torch.LongTensor)\n",
    "    \n",
    "    return y_test_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a13b689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_3d(df, features_starting_idx):\n",
    "    dim1 = df.new_interaction_id.nunique()\n",
    "    #print(dim1)\n",
    "    dim2 = df.slice_num.nunique()\n",
    "    dim3 = df.iloc[:,features_starting_idx:].shape[1]\n",
    "        \n",
    "    X = np.zeros((dim1, dim2, dim3)) \n",
    "\n",
    "    itr_id_lst = df.new_interaction_id.unique().tolist()\n",
    "    #print(itr_id_lst[0], itr_id_lst[-1])\n",
    "\n",
    "    for i in range(len(itr_id_lst)): #range(len(itr_id_lst)):\n",
    "        itr_id = itr_id_lst[i]\n",
    "        itr_id_df = df[df.new_interaction_id==itr_id]  \n",
    "        \n",
    "        for j in range(itr_id_df.shape[0]):\n",
    "            vals_arr = itr_id_df.iloc[j,features_starting_idx:].values\n",
    "\n",
    "            X[i,j] = vals_arr\n",
    "    \n",
    "    X_tensor = torch.Tensor(X)    \n",
    "    return X_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeaa534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_train_for_3d_X(df, predicting_feature = 'property_id'):\n",
    "    # Create a dataset with only the required columns\n",
    "    df2 = df[['new_interaction_id', 'property_id', 'rating_level_num']]\n",
    "\n",
    "    # Remove duplicates\n",
    "    df2.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # Reset the indexes\n",
    "    df2.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    ## Create y train\n",
    "    # CreatE an instance of a one-hot-encoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Perform one-hot encoding on the specified column \n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(df2[[predicting_feature]]).toarray())\n",
    "    \n",
    "    # Convert to a numpy array\n",
    "    y_train = encoder_df.to_numpy()\n",
    "    \n",
    "    # Convert to a tensor\n",
    "    y_train = torch.Tensor(y_train)\n",
    "  \n",
    "    return y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8a102fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_y_test_for_3d_X(df, predicting_feature = 'property_id'):\n",
    "    # Create a dataset with only the required columns\n",
    "    df2 = df[['new_interaction_id', 'property_id', 'rating_level_num']]\n",
    "\n",
    "    # Remove duplicates\n",
    "    df2.drop_duplicates(keep='first', inplace=True)\n",
    "\n",
    "    # Reset the indexes\n",
    "    df2.reset_index(drop=True, inplace=True) \n",
    "    \n",
    "    y_test = df2[predicting_feature].values\n",
    "    #if predicting_feature == 'property_id':\n",
    "       # y_test = y_test - 3\n",
    "    if predicting_feature == 'rating_level_num':\n",
    "        y_test = y_test - 1\n",
    "    \n",
    "    y_test = torch.Tensor(y_test)    \n",
    "    y_test = y_test.type(torch.LongTensor)\n",
    "    \n",
    "    return y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e568f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 3 - LSTM + fully connected layers using all 180 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe17efc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participant_id</th>\n",
       "      <th>clothes_id</th>\n",
       "      <th>property_id</th>\n",
       "      <th>property_name</th>\n",
       "      <th>interaction_id</th>\n",
       "      <th>new_interaction_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_level</th>\n",
       "      <th>rating_level_num</th>\n",
       "      <th>sub_window_num</th>\n",
       "      <th>slice_num</th>\n",
       "      <th>max_ch1_hand0</th>\n",
       "      <th>max_ch2_hand0</th>\n",
       "      <th>max_ch3_hand0</th>\n",
       "      <th>max_ch4_hand0</th>\n",
       "      <th>max_ch5_hand0</th>\n",
       "      <th>max_ch6_hand0</th>\n",
       "      <th>max_ch7_hand0</th>\n",
       "      <th>max_ch8_hand0</th>\n",
       "      <th>mean_ch1_hand0</th>\n",
       "      <th>mean_ch2_hand0</th>\n",
       "      <th>mean_ch3_hand0</th>\n",
       "      <th>mean_ch4_hand0</th>\n",
       "      <th>mean_ch5_hand0</th>\n",
       "      <th>mean_ch6_hand0</th>\n",
       "      <th>mean_ch7_hand0</th>\n",
       "      <th>mean_ch8_hand0</th>\n",
       "      <th>std_ch1_hand0</th>\n",
       "      <th>std_ch2_hand0</th>\n",
       "      <th>std_ch3_hand0</th>\n",
       "      <th>std_ch4_hand0</th>\n",
       "      <th>std_ch5_hand0</th>\n",
       "      <th>std_ch6_hand0</th>\n",
       "      <th>std_ch7_hand0</th>\n",
       "      <th>std_ch8_hand0</th>\n",
       "      <th>max_ch1_hand1</th>\n",
       "      <th>max_ch2_hand1</th>\n",
       "      <th>max_ch3_hand1</th>\n",
       "      <th>max_ch4_hand1</th>\n",
       "      <th>max_ch5_hand1</th>\n",
       "      <th>max_ch6_hand1</th>\n",
       "      <th>max_ch7_hand1</th>\n",
       "      <th>max_ch8_hand1</th>\n",
       "      <th>mean_ch1_hand1</th>\n",
       "      <th>mean_ch2_hand1</th>\n",
       "      <th>mean_ch3_hand1</th>\n",
       "      <th>mean_ch4_hand1</th>\n",
       "      <th>mean_ch5_hand1</th>\n",
       "      <th>mean_ch6_hand1</th>\n",
       "      <th>mean_ch7_hand1</th>\n",
       "      <th>mean_ch8_hand1</th>\n",
       "      <th>std_ch1_hand1</th>\n",
       "      <th>std_ch2_hand1</th>\n",
       "      <th>std_ch3_hand1</th>\n",
       "      <th>std_ch4_hand1</th>\n",
       "      <th>std_ch5_hand1</th>\n",
       "      <th>std_ch6_hand1</th>\n",
       "      <th>std_ch7_hand1</th>\n",
       "      <th>std_ch8_hand1</th>\n",
       "      <th>max_Ax_hand0</th>\n",
       "      <th>max_Ay_hand0</th>\n",
       "      <th>max_Az_hand0</th>\n",
       "      <th>max_Vx_hand0</th>\n",
       "      <th>max_Vy_hand0</th>\n",
       "      <th>max_Vz_hand0</th>\n",
       "      <th>max_Jx_hand0</th>\n",
       "      <th>max_Jy_hand0</th>\n",
       "      <th>max_Jz_hand0</th>\n",
       "      <th>mean_Ax_hand0</th>\n",
       "      <th>mean_Ay_hand0</th>\n",
       "      <th>mean_Az_hand0</th>\n",
       "      <th>mean_Vx_hand0</th>\n",
       "      <th>mean_Vy_hand0</th>\n",
       "      <th>mean_Vz_hand0</th>\n",
       "      <th>mean_Jx_hand0</th>\n",
       "      <th>mean_Jy_hand0</th>\n",
       "      <th>mean_Jz_hand0</th>\n",
       "      <th>std_Ax_hand0</th>\n",
       "      <th>std_Ay_hand0</th>\n",
       "      <th>std_Az_hand0</th>\n",
       "      <th>std_Vx_hand0</th>\n",
       "      <th>std_Vy_hand0</th>\n",
       "      <th>std_Vz_hand0</th>\n",
       "      <th>std_Jx_hand0</th>\n",
       "      <th>std_Jy_hand0</th>\n",
       "      <th>std_Jz_hand0</th>\n",
       "      <th>max_Ax_hand1</th>\n",
       "      <th>max_Ay_hand1</th>\n",
       "      <th>max_Az_hand1</th>\n",
       "      <th>max_Vx_hand1</th>\n",
       "      <th>max_Vy_hand1</th>\n",
       "      <th>max_Vz_hand1</th>\n",
       "      <th>max_Jx_hand1</th>\n",
       "      <th>max_Jy_hand1</th>\n",
       "      <th>max_Jz_hand1</th>\n",
       "      <th>mean_Ax_hand1</th>\n",
       "      <th>mean_Ay_hand1</th>\n",
       "      <th>mean_Az_hand1</th>\n",
       "      <th>mean_Vx_hand1</th>\n",
       "      <th>mean_Vy_hand1</th>\n",
       "      <th>mean_Vz_hand1</th>\n",
       "      <th>mean_Jx_hand1</th>\n",
       "      <th>mean_Jy_hand1</th>\n",
       "      <th>mean_Jz_hand1</th>\n",
       "      <th>std_Ax_hand1</th>\n",
       "      <th>std_Ay_hand1</th>\n",
       "      <th>std_Az_hand1</th>\n",
       "      <th>std_Vx_hand1</th>\n",
       "      <th>std_Vy_hand1</th>\n",
       "      <th>std_Vz_hand1</th>\n",
       "      <th>std_Jx_hand1</th>\n",
       "      <th>std_Jy_hand1</th>\n",
       "      <th>std_Jz_hand1</th>\n",
       "      <th>max_w_hand0</th>\n",
       "      <th>max_x_hand0</th>\n",
       "      <th>max_y_hand0</th>\n",
       "      <th>max_z_hand0</th>\n",
       "      <th>max_AVx_hand0</th>\n",
       "      <th>max_AVy_hand0</th>\n",
       "      <th>max_AVz_hand0</th>\n",
       "      <th>max_AAx_hand0</th>\n",
       "      <th>max_AAy_hand0</th>\n",
       "      <th>max_AAz_hand0</th>\n",
       "      <th>max_AJx_hand0</th>\n",
       "      <th>max_AJy_hand0</th>\n",
       "      <th>max_AJz_hand0</th>\n",
       "      <th>mean_w_hand0</th>\n",
       "      <th>mean_x_hand0</th>\n",
       "      <th>mean_y_hand0</th>\n",
       "      <th>mean_z_hand0</th>\n",
       "      <th>mean_AVx_hand0</th>\n",
       "      <th>mean_AVy_hand0</th>\n",
       "      <th>mean_AVz_hand0</th>\n",
       "      <th>mean_AAx_hand0</th>\n",
       "      <th>mean_AAy_hand0</th>\n",
       "      <th>mean_AAz_hand0</th>\n",
       "      <th>mean_AJx_hand0</th>\n",
       "      <th>mean_AJy_hand0</th>\n",
       "      <th>mean_AJz_hand0</th>\n",
       "      <th>std_w_hand0</th>\n",
       "      <th>std_x_hand0</th>\n",
       "      <th>std_y_hand0</th>\n",
       "      <th>std_z_hand0</th>\n",
       "      <th>std_AVx_hand0</th>\n",
       "      <th>std_AVy_hand0</th>\n",
       "      <th>std_AVz_hand0</th>\n",
       "      <th>std_AAx_hand0</th>\n",
       "      <th>std_AAy_hand0</th>\n",
       "      <th>std_AAz_hand0</th>\n",
       "      <th>std_AJx_hand0</th>\n",
       "      <th>std_AJy_hand0</th>\n",
       "      <th>std_AJz_hand0</th>\n",
       "      <th>max_w_hand1</th>\n",
       "      <th>max_x_hand1</th>\n",
       "      <th>max_y_hand1</th>\n",
       "      <th>max_z_hand1</th>\n",
       "      <th>max_AVx_hand1</th>\n",
       "      <th>max_AVy_hand1</th>\n",
       "      <th>max_AVz_hand1</th>\n",
       "      <th>max_AAx_hand1</th>\n",
       "      <th>max_AAy_hand1</th>\n",
       "      <th>max_AAz_hand1</th>\n",
       "      <th>max_AJx_hand1</th>\n",
       "      <th>max_AJy_hand1</th>\n",
       "      <th>max_AJz_hand1</th>\n",
       "      <th>mean_w_hand1</th>\n",
       "      <th>mean_x_hand1</th>\n",
       "      <th>mean_y_hand1</th>\n",
       "      <th>mean_z_hand1</th>\n",
       "      <th>mean_AVx_hand1</th>\n",
       "      <th>mean_AVy_hand1</th>\n",
       "      <th>mean_AVz_hand1</th>\n",
       "      <th>mean_AAx_hand1</th>\n",
       "      <th>mean_AAy_hand1</th>\n",
       "      <th>mean_AAz_hand1</th>\n",
       "      <th>mean_AJx_hand1</th>\n",
       "      <th>mean_AJy_hand1</th>\n",
       "      <th>mean_AJz_hand1</th>\n",
       "      <th>std_w_hand1</th>\n",
       "      <th>std_x_hand1</th>\n",
       "      <th>std_y_hand1</th>\n",
       "      <th>std_z_hand1</th>\n",
       "      <th>std_AVx_hand1</th>\n",
       "      <th>std_AVy_hand1</th>\n",
       "      <th>std_AVz_hand1</th>\n",
       "      <th>std_AAx_hand1</th>\n",
       "      <th>std_AAy_hand1</th>\n",
       "      <th>std_AAz_hand1</th>\n",
       "      <th>std_AJx_hand1</th>\n",
       "      <th>std_AJy_hand1</th>\n",
       "      <th>std_AJz_hand1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241026</td>\n",
       "      <td>0.351956</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>0.304812</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>0.106446</td>\n",
       "      <td>0.458069</td>\n",
       "      <td>0.600224</td>\n",
       "      <td>0.328286</td>\n",
       "      <td>0.763818</td>\n",
       "      <td>0.600703</td>\n",
       "      <td>0.952406</td>\n",
       "      <td>0.569367</td>\n",
       "      <td>-0.989579</td>\n",
       "      <td>-0.970262</td>\n",
       "      <td>-0.979567</td>\n",
       "      <td>-0.987704</td>\n",
       "      <td>-0.961911</td>\n",
       "      <td>-0.973839</td>\n",
       "      <td>-0.977602</td>\n",
       "      <td>-0.980363</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.859156</td>\n",
       "      <td>0.514450</td>\n",
       "      <td>0.460318</td>\n",
       "      <td>-0.004082</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.297030</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>0.257107</td>\n",
       "      <td>0.995134</td>\n",
       "      <td>0.749178</td>\n",
       "      <td>0.696744</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>0.497051</td>\n",
       "      <td>0.440943</td>\n",
       "      <td>0.297865</td>\n",
       "      <td>-0.978453</td>\n",
       "      <td>-0.920148</td>\n",
       "      <td>-0.769635</td>\n",
       "      <td>-0.721283</td>\n",
       "      <td>-0.988758</td>\n",
       "      <td>-0.135255</td>\n",
       "      <td>-0.854100</td>\n",
       "      <td>-0.955585</td>\n",
       "      <td>-0.887918</td>\n",
       "      <td>-0.417059</td>\n",
       "      <td>-0.157425</td>\n",
       "      <td>-0.547869</td>\n",
       "      <td>-0.584079</td>\n",
       "      <td>-0.742455</td>\n",
       "      <td>-0.987309</td>\n",
       "      <td>-0.988306</td>\n",
       "      <td>-0.992311</td>\n",
       "      <td>-0.734308</td>\n",
       "      <td>-0.058930</td>\n",
       "      <td>0.453175</td>\n",
       "      <td>0.415503</td>\n",
       "      <td>0.498786</td>\n",
       "      <td>0.238033</td>\n",
       "      <td>-0.181332</td>\n",
       "      <td>-0.137188</td>\n",
       "      <td>-0.568023</td>\n",
       "      <td>-0.984372</td>\n",
       "      <td>-0.982316</td>\n",
       "      <td>-0.983070</td>\n",
       "      <td>-0.991487</td>\n",
       "      <td>-0.993020</td>\n",
       "      <td>-0.991915</td>\n",
       "      <td>-0.987831</td>\n",
       "      <td>-0.980208</td>\n",
       "      <td>-0.989201</td>\n",
       "      <td>-0.039172</td>\n",
       "      <td>-0.501367</td>\n",
       "      <td>-0.568651</td>\n",
       "      <td>-0.990805</td>\n",
       "      <td>-0.924076</td>\n",
       "      <td>-0.695349</td>\n",
       "      <td>-0.987071</td>\n",
       "      <td>-0.985312</td>\n",
       "      <td>-0.971907</td>\n",
       "      <td>0.639118</td>\n",
       "      <td>-0.100274</td>\n",
       "      <td>-0.272429</td>\n",
       "      <td>-0.941629</td>\n",
       "      <td>0.943874</td>\n",
       "      <td>0.872673</td>\n",
       "      <td>-0.362298</td>\n",
       "      <td>-0.194153</td>\n",
       "      <td>0.127826</td>\n",
       "      <td>-0.957169</td>\n",
       "      <td>-0.983109</td>\n",
       "      <td>-0.949182</td>\n",
       "      <td>-0.999332</td>\n",
       "      <td>-0.999006</td>\n",
       "      <td>-0.998700</td>\n",
       "      <td>-0.978210</td>\n",
       "      <td>-0.978833</td>\n",
       "      <td>-0.962425</td>\n",
       "      <td>0.120998</td>\n",
       "      <td>0.541663</td>\n",
       "      <td>0.170510</td>\n",
       "      <td>-0.877719</td>\n",
       "      <td>-0.782585</td>\n",
       "      <td>-0.931713</td>\n",
       "      <td>-0.940076</td>\n",
       "      <td>-0.907688</td>\n",
       "      <td>-0.985991</td>\n",
       "      <td>-0.979934</td>\n",
       "      <td>-0.994210</td>\n",
       "      <td>-0.999024</td>\n",
       "      <td>-0.994365</td>\n",
       "      <td>0.119734</td>\n",
       "      <td>0.556493</td>\n",
       "      <td>0.182533</td>\n",
       "      <td>-0.877081</td>\n",
       "      <td>-0.112933</td>\n",
       "      <td>-0.191917</td>\n",
       "      <td>0.172213</td>\n",
       "      <td>0.046715</td>\n",
       "      <td>-0.797721</td>\n",
       "      <td>-0.157594</td>\n",
       "      <td>0.158930</td>\n",
       "      <td>-0.766435</td>\n",
       "      <td>-0.301156</td>\n",
       "      <td>-0.969740</td>\n",
       "      <td>-0.989063</td>\n",
       "      <td>-0.977065</td>\n",
       "      <td>-0.993989</td>\n",
       "      <td>-0.989559</td>\n",
       "      <td>-0.994945</td>\n",
       "      <td>-0.988448</td>\n",
       "      <td>-0.995156</td>\n",
       "      <td>-0.998267</td>\n",
       "      <td>-0.987901</td>\n",
       "      <td>-0.996821</td>\n",
       "      <td>-0.999347</td>\n",
       "      <td>-0.996959</td>\n",
       "      <td>0.579593</td>\n",
       "      <td>-0.207280</td>\n",
       "      <td>-0.886235</td>\n",
       "      <td>-0.133564</td>\n",
       "      <td>-0.943090</td>\n",
       "      <td>-0.961539</td>\n",
       "      <td>-0.906408</td>\n",
       "      <td>-0.993646</td>\n",
       "      <td>-0.992445</td>\n",
       "      <td>-0.993466</td>\n",
       "      <td>-0.998611</td>\n",
       "      <td>-0.999300</td>\n",
       "      <td>-0.999123</td>\n",
       "      <td>0.571723</td>\n",
       "      <td>-0.176028</td>\n",
       "      <td>-0.878267</td>\n",
       "      <td>-0.123581</td>\n",
       "      <td>0.132265</td>\n",
       "      <td>0.114995</td>\n",
       "      <td>-0.024707</td>\n",
       "      <td>0.123684</td>\n",
       "      <td>-0.127529</td>\n",
       "      <td>0.199302</td>\n",
       "      <td>0.198584</td>\n",
       "      <td>-0.164631</td>\n",
       "      <td>0.743395</td>\n",
       "      <td>-0.942989</td>\n",
       "      <td>-0.990935</td>\n",
       "      <td>-0.951021</td>\n",
       "      <td>-0.984447</td>\n",
       "      <td>-0.994087</td>\n",
       "      <td>-0.988260</td>\n",
       "      <td>-0.982236</td>\n",
       "      <td>-0.995502</td>\n",
       "      <td>-0.994280</td>\n",
       "      <td>-0.991199</td>\n",
       "      <td>-0.998840</td>\n",
       "      <td>-0.998778</td>\n",
       "      <td>-0.998416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.230770</td>\n",
       "      <td>0.351956</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.304812</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>0.106535</td>\n",
       "      <td>0.457327</td>\n",
       "      <td>0.599751</td>\n",
       "      <td>0.328514</td>\n",
       "      <td>0.764280</td>\n",
       "      <td>0.602491</td>\n",
       "      <td>0.951629</td>\n",
       "      <td>0.568445</td>\n",
       "      <td>-0.989229</td>\n",
       "      <td>-0.968885</td>\n",
       "      <td>-0.980203</td>\n",
       "      <td>-0.988803</td>\n",
       "      <td>-0.969074</td>\n",
       "      <td>-0.976084</td>\n",
       "      <td>-0.974391</td>\n",
       "      <td>-0.980466</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>0.760564</td>\n",
       "      <td>0.479768</td>\n",
       "      <td>0.354498</td>\n",
       "      <td>-0.012244</td>\n",
       "      <td>0.575510</td>\n",
       "      <td>0.277228</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>0.256530</td>\n",
       "      <td>0.994936</td>\n",
       "      <td>0.749071</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.291602</td>\n",
       "      <td>0.452270</td>\n",
       "      <td>0.439619</td>\n",
       "      <td>0.297396</td>\n",
       "      <td>-0.982842</td>\n",
       "      <td>-0.952588</td>\n",
       "      <td>-0.821947</td>\n",
       "      <td>-0.837338</td>\n",
       "      <td>-0.989331</td>\n",
       "      <td>-0.380445</td>\n",
       "      <td>-0.884059</td>\n",
       "      <td>-0.959461</td>\n",
       "      <td>-0.886900</td>\n",
       "      <td>-0.421465</td>\n",
       "      <td>-0.150578</td>\n",
       "      <td>-0.546344</td>\n",
       "      <td>-0.582153</td>\n",
       "      <td>-0.742516</td>\n",
       "      <td>-0.984997</td>\n",
       "      <td>-0.991120</td>\n",
       "      <td>-0.995210</td>\n",
       "      <td>-0.733818</td>\n",
       "      <td>-0.054319</td>\n",
       "      <td>0.455053</td>\n",
       "      <td>0.417190</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>0.238123</td>\n",
       "      <td>-0.176843</td>\n",
       "      <td>-0.144556</td>\n",
       "      <td>-0.570785</td>\n",
       "      <td>-0.984864</td>\n",
       "      <td>-0.988326</td>\n",
       "      <td>-0.980810</td>\n",
       "      <td>-0.990873</td>\n",
       "      <td>-0.995350</td>\n",
       "      <td>-0.991068</td>\n",
       "      <td>-0.985650</td>\n",
       "      <td>-0.989803</td>\n",
       "      <td>-0.990776</td>\n",
       "      <td>-0.008904</td>\n",
       "      <td>-0.506077</td>\n",
       "      <td>-0.554681</td>\n",
       "      <td>-0.991092</td>\n",
       "      <td>-0.927038</td>\n",
       "      <td>-0.694854</td>\n",
       "      <td>-0.967712</td>\n",
       "      <td>-0.964208</td>\n",
       "      <td>-0.975054</td>\n",
       "      <td>0.642146</td>\n",
       "      <td>-0.101240</td>\n",
       "      <td>-0.255789</td>\n",
       "      <td>-0.942063</td>\n",
       "      <td>0.943872</td>\n",
       "      <td>0.872309</td>\n",
       "      <td>-0.355137</td>\n",
       "      <td>-0.181314</td>\n",
       "      <td>0.065502</td>\n",
       "      <td>-0.955312</td>\n",
       "      <td>-0.980318</td>\n",
       "      <td>-0.925928</td>\n",
       "      <td>-0.999354</td>\n",
       "      <td>-0.999286</td>\n",
       "      <td>-0.998945</td>\n",
       "      <td>-0.959584</td>\n",
       "      <td>-0.965279</td>\n",
       "      <td>-0.928917</td>\n",
       "      <td>0.113299</td>\n",
       "      <td>0.542467</td>\n",
       "      <td>0.164254</td>\n",
       "      <td>-0.879209</td>\n",
       "      <td>-0.788702</td>\n",
       "      <td>-0.932419</td>\n",
       "      <td>-0.943368</td>\n",
       "      <td>-0.910027</td>\n",
       "      <td>-0.986339</td>\n",
       "      <td>-0.983616</td>\n",
       "      <td>-0.995620</td>\n",
       "      <td>-0.999001</td>\n",
       "      <td>-0.995053</td>\n",
       "      <td>0.114771</td>\n",
       "      <td>0.557711</td>\n",
       "      <td>0.177916</td>\n",
       "      <td>-0.878249</td>\n",
       "      <td>-0.110580</td>\n",
       "      <td>-0.191596</td>\n",
       "      <td>0.179751</td>\n",
       "      <td>0.049015</td>\n",
       "      <td>-0.797719</td>\n",
       "      <td>-0.156049</td>\n",
       "      <td>0.159665</td>\n",
       "      <td>-0.766074</td>\n",
       "      <td>-0.302451</td>\n",
       "      <td>-0.994841</td>\n",
       "      <td>-0.993888</td>\n",
       "      <td>-0.993105</td>\n",
       "      <td>-0.995995</td>\n",
       "      <td>-0.995622</td>\n",
       "      <td>-0.995237</td>\n",
       "      <td>-0.995191</td>\n",
       "      <td>-0.998214</td>\n",
       "      <td>-0.998840</td>\n",
       "      <td>-0.994900</td>\n",
       "      <td>-0.999159</td>\n",
       "      <td>-0.999570</td>\n",
       "      <td>-0.998259</td>\n",
       "      <td>0.585591</td>\n",
       "      <td>-0.208809</td>\n",
       "      <td>-0.880409</td>\n",
       "      <td>-0.136687</td>\n",
       "      <td>-0.941532</td>\n",
       "      <td>-0.958191</td>\n",
       "      <td>-0.897454</td>\n",
       "      <td>-0.986173</td>\n",
       "      <td>-0.979398</td>\n",
       "      <td>-0.981553</td>\n",
       "      <td>-0.994975</td>\n",
       "      <td>-0.995869</td>\n",
       "      <td>-0.996443</td>\n",
       "      <td>0.577854</td>\n",
       "      <td>-0.178063</td>\n",
       "      <td>-0.872131</td>\n",
       "      <td>-0.126934</td>\n",
       "      <td>0.117509</td>\n",
       "      <td>0.083325</td>\n",
       "      <td>-0.023532</td>\n",
       "      <td>0.121184</td>\n",
       "      <td>-0.129599</td>\n",
       "      <td>0.199234</td>\n",
       "      <td>0.200637</td>\n",
       "      <td>-0.160782</td>\n",
       "      <td>0.742444</td>\n",
       "      <td>-0.925173</td>\n",
       "      <td>-0.984371</td>\n",
       "      <td>-0.936886</td>\n",
       "      <td>-0.987936</td>\n",
       "      <td>-0.983986</td>\n",
       "      <td>-0.965549</td>\n",
       "      <td>-0.978245</td>\n",
       "      <td>-0.986291</td>\n",
       "      <td>-0.984267</td>\n",
       "      <td>-0.985112</td>\n",
       "      <td>-0.994982</td>\n",
       "      <td>-0.995564</td>\n",
       "      <td>-0.995649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241026</td>\n",
       "      <td>0.340782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.304812</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>0.105977</td>\n",
       "      <td>0.457861</td>\n",
       "      <td>0.600071</td>\n",
       "      <td>0.327780</td>\n",
       "      <td>0.764491</td>\n",
       "      <td>0.602384</td>\n",
       "      <td>0.952221</td>\n",
       "      <td>0.567943</td>\n",
       "      <td>-0.989589</td>\n",
       "      <td>-0.969031</td>\n",
       "      <td>-0.981343</td>\n",
       "      <td>-0.988636</td>\n",
       "      <td>-0.971692</td>\n",
       "      <td>-0.976385</td>\n",
       "      <td>-0.978975</td>\n",
       "      <td>-0.981760</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.816902</td>\n",
       "      <td>0.514450</td>\n",
       "      <td>0.428572</td>\n",
       "      <td>-0.004082</td>\n",
       "      <td>0.428572</td>\n",
       "      <td>0.326732</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.257472</td>\n",
       "      <td>0.997383</td>\n",
       "      <td>0.750233</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.291724</td>\n",
       "      <td>0.414584</td>\n",
       "      <td>0.438194</td>\n",
       "      <td>0.297822</td>\n",
       "      <td>-0.980656</td>\n",
       "      <td>-0.931014</td>\n",
       "      <td>-0.771042</td>\n",
       "      <td>-0.785107</td>\n",
       "      <td>-0.988695</td>\n",
       "      <td>-0.436072</td>\n",
       "      <td>-0.850588</td>\n",
       "      <td>-0.961268</td>\n",
       "      <td>-0.890633</td>\n",
       "      <td>-0.422821</td>\n",
       "      <td>-0.154542</td>\n",
       "      <td>-0.543802</td>\n",
       "      <td>-0.583592</td>\n",
       "      <td>-0.736674</td>\n",
       "      <td>-0.987736</td>\n",
       "      <td>-0.986036</td>\n",
       "      <td>-0.990897</td>\n",
       "      <td>-0.735653</td>\n",
       "      <td>-0.053096</td>\n",
       "      <td>0.451093</td>\n",
       "      <td>0.415651</td>\n",
       "      <td>0.497882</td>\n",
       "      <td>0.239296</td>\n",
       "      <td>-0.192053</td>\n",
       "      <td>-0.148202</td>\n",
       "      <td>-0.569910</td>\n",
       "      <td>-0.982490</td>\n",
       "      <td>-0.986570</td>\n",
       "      <td>-0.977353</td>\n",
       "      <td>-0.989873</td>\n",
       "      <td>-0.995094</td>\n",
       "      <td>-0.989250</td>\n",
       "      <td>-0.982060</td>\n",
       "      <td>-0.974212</td>\n",
       "      <td>-0.984971</td>\n",
       "      <td>-0.038226</td>\n",
       "      <td>-0.479631</td>\n",
       "      <td>-0.558174</td>\n",
       "      <td>-0.991075</td>\n",
       "      <td>-0.906099</td>\n",
       "      <td>-0.691700</td>\n",
       "      <td>-0.972633</td>\n",
       "      <td>-0.958047</td>\n",
       "      <td>-0.961943</td>\n",
       "      <td>0.633037</td>\n",
       "      <td>-0.092331</td>\n",
       "      <td>-0.289585</td>\n",
       "      <td>-0.941847</td>\n",
       "      <td>0.944188</td>\n",
       "      <td>0.872212</td>\n",
       "      <td>-0.364613</td>\n",
       "      <td>-0.179053</td>\n",
       "      <td>0.104477</td>\n",
       "      <td>-0.950830</td>\n",
       "      <td>-0.972711</td>\n",
       "      <td>-0.927838</td>\n",
       "      <td>-0.999377</td>\n",
       "      <td>-0.998300</td>\n",
       "      <td>-0.998403</td>\n",
       "      <td>-0.968907</td>\n",
       "      <td>-0.958949</td>\n",
       "      <td>-0.930081</td>\n",
       "      <td>0.111315</td>\n",
       "      <td>0.544231</td>\n",
       "      <td>0.162854</td>\n",
       "      <td>-0.879386</td>\n",
       "      <td>-0.791156</td>\n",
       "      <td>-0.933613</td>\n",
       "      <td>-0.941954</td>\n",
       "      <td>-0.911110</td>\n",
       "      <td>-0.986219</td>\n",
       "      <td>-0.981118</td>\n",
       "      <td>-0.995538</td>\n",
       "      <td>-0.998959</td>\n",
       "      <td>-0.994764</td>\n",
       "      <td>0.110235</td>\n",
       "      <td>0.559495</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>-0.878855</td>\n",
       "      <td>-0.114078</td>\n",
       "      <td>-0.191830</td>\n",
       "      <td>0.176102</td>\n",
       "      <td>0.048951</td>\n",
       "      <td>-0.797606</td>\n",
       "      <td>-0.155521</td>\n",
       "      <td>0.159879</td>\n",
       "      <td>-0.766005</td>\n",
       "      <td>-0.301345</td>\n",
       "      <td>-0.965699</td>\n",
       "      <td>-0.993244</td>\n",
       "      <td>-0.969085</td>\n",
       "      <td>-0.990123</td>\n",
       "      <td>-0.996947</td>\n",
       "      <td>-0.997724</td>\n",
       "      <td>-0.992292</td>\n",
       "      <td>-0.998620</td>\n",
       "      <td>-0.999153</td>\n",
       "      <td>-0.991684</td>\n",
       "      <td>-0.999424</td>\n",
       "      <td>-0.999684</td>\n",
       "      <td>-0.998113</td>\n",
       "      <td>0.566833</td>\n",
       "      <td>-0.207680</td>\n",
       "      <td>-0.896479</td>\n",
       "      <td>-0.133976</td>\n",
       "      <td>-0.939613</td>\n",
       "      <td>-0.957666</td>\n",
       "      <td>-0.906743</td>\n",
       "      <td>-0.991558</td>\n",
       "      <td>-0.988160</td>\n",
       "      <td>-0.993441</td>\n",
       "      <td>-0.996636</td>\n",
       "      <td>-0.998547</td>\n",
       "      <td>-0.998862</td>\n",
       "      <td>0.565388</td>\n",
       "      <td>-0.175778</td>\n",
       "      <td>-0.883404</td>\n",
       "      <td>-0.123705</td>\n",
       "      <td>0.124487</td>\n",
       "      <td>0.099164</td>\n",
       "      <td>-0.015073</td>\n",
       "      <td>0.121819</td>\n",
       "      <td>-0.129408</td>\n",
       "      <td>0.201098</td>\n",
       "      <td>0.196920</td>\n",
       "      <td>-0.165133</td>\n",
       "      <td>0.743693</td>\n",
       "      <td>-0.972134</td>\n",
       "      <td>-0.992089</td>\n",
       "      <td>-0.975612</td>\n",
       "      <td>-0.984483</td>\n",
       "      <td>-0.989002</td>\n",
       "      <td>-0.978637</td>\n",
       "      <td>-0.990351</td>\n",
       "      <td>-0.988621</td>\n",
       "      <td>-0.987650</td>\n",
       "      <td>-0.993807</td>\n",
       "      <td>-0.996414</td>\n",
       "      <td>-0.997308</td>\n",
       "      <td>-0.998629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241026</td>\n",
       "      <td>0.351956</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>0.518072</td>\n",
       "      <td>0.326204</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>0.106191</td>\n",
       "      <td>0.457861</td>\n",
       "      <td>0.600590</td>\n",
       "      <td>0.327887</td>\n",
       "      <td>0.764558</td>\n",
       "      <td>0.602323</td>\n",
       "      <td>0.952239</td>\n",
       "      <td>0.567456</td>\n",
       "      <td>-0.989989</td>\n",
       "      <td>-0.967511</td>\n",
       "      <td>-0.981089</td>\n",
       "      <td>-0.989723</td>\n",
       "      <td>-0.966768</td>\n",
       "      <td>-0.976261</td>\n",
       "      <td>-0.982523</td>\n",
       "      <td>-0.980699</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.859156</td>\n",
       "      <td>0.618498</td>\n",
       "      <td>0.322752</td>\n",
       "      <td>-0.012244</td>\n",
       "      <td>0.640816</td>\n",
       "      <td>0.247524</td>\n",
       "      <td>0.142858</td>\n",
       "      <td>0.256395</td>\n",
       "      <td>0.995652</td>\n",
       "      <td>0.749179</td>\n",
       "      <td>0.692946</td>\n",
       "      <td>0.290316</td>\n",
       "      <td>0.350005</td>\n",
       "      <td>0.437136</td>\n",
       "      <td>0.297463</td>\n",
       "      <td>-0.982005</td>\n",
       "      <td>-0.934272</td>\n",
       "      <td>-0.759036</td>\n",
       "      <td>-0.915227</td>\n",
       "      <td>-0.989146</td>\n",
       "      <td>-0.283615</td>\n",
       "      <td>-0.926506</td>\n",
       "      <td>-0.963167</td>\n",
       "      <td>-0.887579</td>\n",
       "      <td>-0.426550</td>\n",
       "      <td>-0.157425</td>\n",
       "      <td>-0.545398</td>\n",
       "      <td>-0.586589</td>\n",
       "      <td>-0.742668</td>\n",
       "      <td>-0.984997</td>\n",
       "      <td>-0.990442</td>\n",
       "      <td>-0.994938</td>\n",
       "      <td>-0.733969</td>\n",
       "      <td>-0.053579</td>\n",
       "      <td>0.450738</td>\n",
       "      <td>0.414561</td>\n",
       "      <td>0.496761</td>\n",
       "      <td>0.237944</td>\n",
       "      <td>-0.179884</td>\n",
       "      <td>-0.137221</td>\n",
       "      <td>-0.579287</td>\n",
       "      <td>-0.983468</td>\n",
       "      <td>-0.993671</td>\n",
       "      <td>-0.981691</td>\n",
       "      <td>-0.988705</td>\n",
       "      <td>-0.997187</td>\n",
       "      <td>-0.991816</td>\n",
       "      <td>-0.980892</td>\n",
       "      <td>-0.990306</td>\n",
       "      <td>-0.987761</td>\n",
       "      <td>-0.032078</td>\n",
       "      <td>-0.503903</td>\n",
       "      <td>-0.541061</td>\n",
       "      <td>-0.990907</td>\n",
       "      <td>-0.915759</td>\n",
       "      <td>-0.697063</td>\n",
       "      <td>-0.973826</td>\n",
       "      <td>-0.983747</td>\n",
       "      <td>-0.944637</td>\n",
       "      <td>0.652336</td>\n",
       "      <td>-0.098316</td>\n",
       "      <td>-0.246432</td>\n",
       "      <td>-0.941578</td>\n",
       "      <td>0.944249</td>\n",
       "      <td>0.872286</td>\n",
       "      <td>-0.368281</td>\n",
       "      <td>-0.206654</td>\n",
       "      <td>0.151899</td>\n",
       "      <td>-0.968204</td>\n",
       "      <td>-0.982735</td>\n",
       "      <td>-0.947719</td>\n",
       "      <td>-0.999501</td>\n",
       "      <td>-0.999014</td>\n",
       "      <td>-0.999031</td>\n",
       "      <td>-0.966470</td>\n",
       "      <td>-0.966324</td>\n",
       "      <td>-0.951485</td>\n",
       "      <td>0.104951</td>\n",
       "      <td>0.545046</td>\n",
       "      <td>0.156980</td>\n",
       "      <td>-0.880772</td>\n",
       "      <td>-0.791326</td>\n",
       "      <td>-0.934445</td>\n",
       "      <td>-0.943880</td>\n",
       "      <td>-0.911471</td>\n",
       "      <td>-0.987122</td>\n",
       "      <td>-0.986953</td>\n",
       "      <td>-0.995731</td>\n",
       "      <td>-0.999338</td>\n",
       "      <td>-0.995484</td>\n",
       "      <td>0.106090</td>\n",
       "      <td>0.560828</td>\n",
       "      <td>0.170560</td>\n",
       "      <td>-0.879591</td>\n",
       "      <td>-0.111671</td>\n",
       "      <td>-0.190411</td>\n",
       "      <td>0.179345</td>\n",
       "      <td>0.048768</td>\n",
       "      <td>-0.797754</td>\n",
       "      <td>-0.158787</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>-0.766137</td>\n",
       "      <td>-0.303050</td>\n",
       "      <td>-0.989433</td>\n",
       "      <td>-0.997373</td>\n",
       "      <td>-0.993854</td>\n",
       "      <td>-0.998071</td>\n",
       "      <td>-0.998884</td>\n",
       "      <td>-0.999530</td>\n",
       "      <td>-0.996688</td>\n",
       "      <td>-0.999420</td>\n",
       "      <td>-0.999813</td>\n",
       "      <td>-0.995509</td>\n",
       "      <td>-0.999752</td>\n",
       "      <td>-0.999921</td>\n",
       "      <td>-0.998485</td>\n",
       "      <td>0.585796</td>\n",
       "      <td>-0.204431</td>\n",
       "      <td>-0.881512</td>\n",
       "      <td>-0.134703</td>\n",
       "      <td>-0.940476</td>\n",
       "      <td>-0.956152</td>\n",
       "      <td>-0.906613</td>\n",
       "      <td>-0.993227</td>\n",
       "      <td>-0.989388</td>\n",
       "      <td>-0.994575</td>\n",
       "      <td>-0.999050</td>\n",
       "      <td>-0.999204</td>\n",
       "      <td>-0.998470</td>\n",
       "      <td>0.582345</td>\n",
       "      <td>-0.173310</td>\n",
       "      <td>-0.869825</td>\n",
       "      <td>-0.125886</td>\n",
       "      <td>0.135159</td>\n",
       "      <td>0.115554</td>\n",
       "      <td>-0.022281</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>-0.127818</td>\n",
       "      <td>0.201379</td>\n",
       "      <td>0.197798</td>\n",
       "      <td>-0.165129</td>\n",
       "      <td>0.744034</td>\n",
       "      <td>-0.938847</td>\n",
       "      <td>-0.987591</td>\n",
       "      <td>-0.947937</td>\n",
       "      <td>-0.974035</td>\n",
       "      <td>-0.992828</td>\n",
       "      <td>-0.983429</td>\n",
       "      <td>-0.990709</td>\n",
       "      <td>-0.995212</td>\n",
       "      <td>-0.992004</td>\n",
       "      <td>-0.994691</td>\n",
       "      <td>-0.998644</td>\n",
       "      <td>-0.998075</td>\n",
       "      <td>-0.998693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>smoothness</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>0.241026</td>\n",
       "      <td>0.351956</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.304812</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.333334</td>\n",
       "      <td>0.105846</td>\n",
       "      <td>0.458242</td>\n",
       "      <td>0.600506</td>\n",
       "      <td>0.328723</td>\n",
       "      <td>0.764373</td>\n",
       "      <td>0.602575</td>\n",
       "      <td>0.951527</td>\n",
       "      <td>0.568528</td>\n",
       "      <td>-0.989113</td>\n",
       "      <td>-0.970855</td>\n",
       "      <td>-0.982114</td>\n",
       "      <td>-0.986610</td>\n",
       "      <td>-0.962694</td>\n",
       "      <td>-0.971898</td>\n",
       "      <td>-0.978897</td>\n",
       "      <td>-0.980697</td>\n",
       "      <td>0.016394</td>\n",
       "      <td>0.915492</td>\n",
       "      <td>0.618498</td>\n",
       "      <td>0.492064</td>\n",
       "      <td>-0.004082</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.366336</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>0.256824</td>\n",
       "      <td>0.997948</td>\n",
       "      <td>0.754550</td>\n",
       "      <td>0.697788</td>\n",
       "      <td>0.291541</td>\n",
       "      <td>0.367741</td>\n",
       "      <td>0.444030</td>\n",
       "      <td>0.298248</td>\n",
       "      <td>-0.973323</td>\n",
       "      <td>-0.879495</td>\n",
       "      <td>-0.492333</td>\n",
       "      <td>-0.674262</td>\n",
       "      <td>-0.989347</td>\n",
       "      <td>0.371875</td>\n",
       "      <td>-0.799849</td>\n",
       "      <td>-0.953724</td>\n",
       "      <td>-0.888257</td>\n",
       "      <td>-0.417398</td>\n",
       "      <td>-0.151659</td>\n",
       "      <td>-0.548143</td>\n",
       "      <td>-0.583711</td>\n",
       "      <td>-0.737616</td>\n",
       "      <td>-0.974412</td>\n",
       "      <td>-0.986286</td>\n",
       "      <td>-0.985978</td>\n",
       "      <td>-0.734421</td>\n",
       "      <td>-0.049298</td>\n",
       "      <td>0.450964</td>\n",
       "      <td>0.416933</td>\n",
       "      <td>0.497091</td>\n",
       "      <td>0.238981</td>\n",
       "      <td>-0.171444</td>\n",
       "      <td>-0.148450</td>\n",
       "      <td>-0.562888</td>\n",
       "      <td>-0.985434</td>\n",
       "      <td>-0.989582</td>\n",
       "      <td>-0.977766</td>\n",
       "      <td>-0.992312</td>\n",
       "      <td>-0.995606</td>\n",
       "      <td>-0.988233</td>\n",
       "      <td>-0.980415</td>\n",
       "      <td>-0.977572</td>\n",
       "      <td>-0.981928</td>\n",
       "      <td>-0.051941</td>\n",
       "      <td>-0.465140</td>\n",
       "      <td>-0.566206</td>\n",
       "      <td>-0.991309</td>\n",
       "      <td>-0.909646</td>\n",
       "      <td>-0.704007</td>\n",
       "      <td>-0.986692</td>\n",
       "      <td>-0.971950</td>\n",
       "      <td>-0.980560</td>\n",
       "      <td>0.621701</td>\n",
       "      <td>-0.086185</td>\n",
       "      <td>-0.317926</td>\n",
       "      <td>-0.941801</td>\n",
       "      <td>0.944803</td>\n",
       "      <td>0.871091</td>\n",
       "      <td>-0.373012</td>\n",
       "      <td>-0.204285</td>\n",
       "      <td>0.066275</td>\n",
       "      <td>-0.976031</td>\n",
       "      <td>-0.964120</td>\n",
       "      <td>-0.906614</td>\n",
       "      <td>-0.999737</td>\n",
       "      <td>-0.998386</td>\n",
       "      <td>-0.999099</td>\n",
       "      <td>-0.983703</td>\n",
       "      <td>-0.955734</td>\n",
       "      <td>-0.967074</td>\n",
       "      <td>0.101328</td>\n",
       "      <td>0.547569</td>\n",
       "      <td>0.154437</td>\n",
       "      <td>-0.880973</td>\n",
       "      <td>-0.788771</td>\n",
       "      <td>-0.931090</td>\n",
       "      <td>-0.942088</td>\n",
       "      <td>-0.902945</td>\n",
       "      <td>-0.984214</td>\n",
       "      <td>-0.983918</td>\n",
       "      <td>-0.989284</td>\n",
       "      <td>-0.998787</td>\n",
       "      <td>-0.994903</td>\n",
       "      <td>0.102183</td>\n",
       "      <td>0.562827</td>\n",
       "      <td>0.166788</td>\n",
       "      <td>-0.879936</td>\n",
       "      <td>-0.116054</td>\n",
       "      <td>-0.190923</td>\n",
       "      <td>0.176640</td>\n",
       "      <td>0.048043</td>\n",
       "      <td>-0.797314</td>\n",
       "      <td>-0.155884</td>\n",
       "      <td>0.161603</td>\n",
       "      <td>-0.766261</td>\n",
       "      <td>-0.303190</td>\n",
       "      <td>-0.983526</td>\n",
       "      <td>-0.990722</td>\n",
       "      <td>-0.981613</td>\n",
       "      <td>-0.997338</td>\n",
       "      <td>-0.989515</td>\n",
       "      <td>-0.994763</td>\n",
       "      <td>-0.991339</td>\n",
       "      <td>-0.994533</td>\n",
       "      <td>-0.997652</td>\n",
       "      <td>-0.992844</td>\n",
       "      <td>-0.995052</td>\n",
       "      <td>-0.999170</td>\n",
       "      <td>-0.997168</td>\n",
       "      <td>0.582721</td>\n",
       "      <td>-0.180899</td>\n",
       "      <td>-0.884487</td>\n",
       "      <td>-0.117784</td>\n",
       "      <td>-0.943651</td>\n",
       "      <td>-0.972696</td>\n",
       "      <td>-0.880702</td>\n",
       "      <td>-0.990991</td>\n",
       "      <td>-0.993008</td>\n",
       "      <td>-0.979089</td>\n",
       "      <td>-0.995052</td>\n",
       "      <td>-0.997011</td>\n",
       "      <td>-0.996720</td>\n",
       "      <td>0.556579</td>\n",
       "      <td>-0.160697</td>\n",
       "      <td>-0.895283</td>\n",
       "      <td>-0.113405</td>\n",
       "      <td>0.109865</td>\n",
       "      <td>0.066044</td>\n",
       "      <td>0.014734</td>\n",
       "      <td>0.120515</td>\n",
       "      <td>-0.128858</td>\n",
       "      <td>0.199156</td>\n",
       "      <td>0.197554</td>\n",
       "      <td>-0.162683</td>\n",
       "      <td>0.743029</td>\n",
       "      <td>-0.859082</td>\n",
       "      <td>-0.900871</td>\n",
       "      <td>-0.859034</td>\n",
       "      <td>-0.900662</td>\n",
       "      <td>-0.982916</td>\n",
       "      <td>-0.978981</td>\n",
       "      <td>-0.970685</td>\n",
       "      <td>-0.986771</td>\n",
       "      <td>-0.989260</td>\n",
       "      <td>-0.981962</td>\n",
       "      <td>-0.994707</td>\n",
       "      <td>-0.996628</td>\n",
       "      <td>-0.996723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   participant_id  clothes_id  property_id property_name  interaction_id  \\\n",
       "0               7          14            0    smoothness               1   \n",
       "1               7          14            0    smoothness               1   \n",
       "2               7          14            0    smoothness               1   \n",
       "3               7          14            0    smoothness               1   \n",
       "4               7          14            0    smoothness               1   \n",
       "\n",
       "   new_interaction_id  rating rating_level  rating_level_num  sub_window_num  \\\n",
       "0                   1       3       medium                 2               1   \n",
       "1                   1       3       medium                 2               1   \n",
       "2                   1       3       medium                 2               1   \n",
       "3                   2       3       medium                 2               2   \n",
       "4                   2       3       medium                 2               2   \n",
       "\n",
       "   slice_num  max_ch1_hand0  max_ch2_hand0  max_ch3_hand0  max_ch4_hand0  \\\n",
       "0          1       0.000000       0.241026       0.351956      -0.008264   \n",
       "1          2       0.008264       0.230770       0.351956      -0.008264   \n",
       "2          3       0.000000       0.241026       0.340782       0.000000   \n",
       "3          1       0.000000       0.241026       0.351956      -0.008264   \n",
       "4          2       0.008264       0.241026       0.351956       0.000000   \n",
       "\n",
       "   max_ch5_hand0  max_ch6_hand0  max_ch7_hand0  max_ch8_hand0  mean_ch1_hand0  \\\n",
       "0       0.518072       0.304812         0.5250       0.333334        0.106446   \n",
       "1       0.493976       0.304812         0.5250       0.333334        0.106535   \n",
       "2       0.481928       0.304812         0.5125       0.333334        0.105977   \n",
       "3       0.518072       0.326204         0.5125       0.333334        0.106191   \n",
       "4       0.493976       0.304812         0.5125       0.333334        0.105846   \n",
       "\n",
       "   mean_ch2_hand0  mean_ch3_hand0  mean_ch4_hand0  mean_ch5_hand0  \\\n",
       "0        0.458069        0.600224        0.328286        0.763818   \n",
       "1        0.457327        0.599751        0.328514        0.764280   \n",
       "2        0.457861        0.600071        0.327780        0.764491   \n",
       "3        0.457861        0.600590        0.327887        0.764558   \n",
       "4        0.458242        0.600506        0.328723        0.764373   \n",
       "\n",
       "   mean_ch6_hand0  mean_ch7_hand0  mean_ch8_hand0  std_ch1_hand0  \\\n",
       "0        0.600703        0.952406        0.569367      -0.989579   \n",
       "1        0.602491        0.951629        0.568445      -0.989229   \n",
       "2        0.602384        0.952221        0.567943      -0.989589   \n",
       "3        0.602323        0.952239        0.567456      -0.989989   \n",
       "4        0.602575        0.951527        0.568528      -0.989113   \n",
       "\n",
       "   std_ch2_hand0  std_ch3_hand0  std_ch4_hand0  std_ch5_hand0  std_ch6_hand0  \\\n",
       "0      -0.970262      -0.979567      -0.987704      -0.961911      -0.973839   \n",
       "1      -0.968885      -0.980203      -0.988803      -0.969074      -0.976084   \n",
       "2      -0.969031      -0.981343      -0.988636      -0.971692      -0.976385   \n",
       "3      -0.967511      -0.981089      -0.989723      -0.966768      -0.976261   \n",
       "4      -0.970855      -0.982114      -0.986610      -0.962694      -0.971898   \n",
       "\n",
       "   std_ch7_hand0  std_ch8_hand0  max_ch1_hand1  max_ch2_hand1  max_ch3_hand1  \\\n",
       "0      -0.977602      -0.980363       0.016394       0.859156       0.514450   \n",
       "1      -0.974391      -0.980466       0.008196       0.760564       0.479768   \n",
       "2      -0.978975      -0.981760       0.016394       0.816902       0.514450   \n",
       "3      -0.982523      -0.980699       0.016394       0.859156       0.618498   \n",
       "4      -0.978897      -0.980697       0.016394       0.915492       0.618498   \n",
       "\n",
       "   max_ch4_hand1  max_ch5_hand1  max_ch6_hand1  max_ch7_hand1  max_ch8_hand1  \\\n",
       "0       0.460318      -0.004082       0.991836       0.297030       0.152074   \n",
       "1       0.354498      -0.012244       0.575510       0.277228       0.152074   \n",
       "2       0.428572      -0.004082       0.428572       0.326732       0.161290   \n",
       "3       0.322752      -0.012244       0.640816       0.247524       0.142858   \n",
       "4       0.492064      -0.004082       0.991836       0.366336       0.152074   \n",
       "\n",
       "   mean_ch1_hand1  mean_ch2_hand1  mean_ch3_hand1  mean_ch4_hand1  \\\n",
       "0        0.257107        0.995134        0.749178        0.696744   \n",
       "1        0.256530        0.994936        0.749071        0.695700   \n",
       "2        0.257472        0.997383        0.750233        0.694737   \n",
       "3        0.256395        0.995652        0.749179        0.692946   \n",
       "4        0.256824        0.997948        0.754550        0.697788   \n",
       "\n",
       "   mean_ch5_hand1  mean_ch6_hand1  mean_ch7_hand1  mean_ch8_hand1  \\\n",
       "0        0.291791        0.497051        0.440943        0.297865   \n",
       "1        0.291602        0.452270        0.439619        0.297396   \n",
       "2        0.291724        0.414584        0.438194        0.297822   \n",
       "3        0.290316        0.350005        0.437136        0.297463   \n",
       "4        0.291541        0.367741        0.444030        0.298248   \n",
       "\n",
       "   std_ch1_hand1  std_ch2_hand1  std_ch3_hand1  std_ch4_hand1  std_ch5_hand1  \\\n",
       "0      -0.978453      -0.920148      -0.769635      -0.721283      -0.988758   \n",
       "1      -0.982842      -0.952588      -0.821947      -0.837338      -0.989331   \n",
       "2      -0.980656      -0.931014      -0.771042      -0.785107      -0.988695   \n",
       "3      -0.982005      -0.934272      -0.759036      -0.915227      -0.989146   \n",
       "4      -0.973323      -0.879495      -0.492333      -0.674262      -0.989347   \n",
       "\n",
       "   std_ch6_hand1  std_ch7_hand1  std_ch8_hand1  max_Ax_hand0  max_Ay_hand0  \\\n",
       "0      -0.135255      -0.854100      -0.955585     -0.887918     -0.417059   \n",
       "1      -0.380445      -0.884059      -0.959461     -0.886900     -0.421465   \n",
       "2      -0.436072      -0.850588      -0.961268     -0.890633     -0.422821   \n",
       "3      -0.283615      -0.926506      -0.963167     -0.887579     -0.426550   \n",
       "4       0.371875      -0.799849      -0.953724     -0.888257     -0.417398   \n",
       "\n",
       "   max_Az_hand0  max_Vx_hand0  max_Vy_hand0  max_Vz_hand0  max_Jx_hand0  \\\n",
       "0     -0.157425     -0.547869     -0.584079     -0.742455     -0.987309   \n",
       "1     -0.150578     -0.546344     -0.582153     -0.742516     -0.984997   \n",
       "2     -0.154542     -0.543802     -0.583592     -0.736674     -0.987736   \n",
       "3     -0.157425     -0.545398     -0.586589     -0.742668     -0.984997   \n",
       "4     -0.151659     -0.548143     -0.583711     -0.737616     -0.974412   \n",
       "\n",
       "   max_Jy_hand0  max_Jz_hand0  mean_Ax_hand0  mean_Ay_hand0  mean_Az_hand0  \\\n",
       "0     -0.988306     -0.992311      -0.734308      -0.058930       0.453175   \n",
       "1     -0.991120     -0.995210      -0.733818      -0.054319       0.455053   \n",
       "2     -0.986036     -0.990897      -0.735653      -0.053096       0.451093   \n",
       "3     -0.990442     -0.994938      -0.733969      -0.053579       0.450738   \n",
       "4     -0.986286     -0.985978      -0.734421      -0.049298       0.450964   \n",
       "\n",
       "   mean_Vx_hand0  mean_Vy_hand0  mean_Vz_hand0  mean_Jx_hand0  mean_Jy_hand0  \\\n",
       "0       0.415503       0.498786       0.238033      -0.181332      -0.137188   \n",
       "1       0.417190       0.496689       0.238123      -0.176843      -0.144556   \n",
       "2       0.415651       0.497882       0.239296      -0.192053      -0.148202   \n",
       "3       0.414561       0.496761       0.237944      -0.179884      -0.137221   \n",
       "4       0.416933       0.497091       0.238981      -0.171444      -0.148450   \n",
       "\n",
       "   mean_Jz_hand0  std_Ax_hand0  std_Ay_hand0  std_Az_hand0  std_Vx_hand0  \\\n",
       "0      -0.568023     -0.984372     -0.982316     -0.983070     -0.991487   \n",
       "1      -0.570785     -0.984864     -0.988326     -0.980810     -0.990873   \n",
       "2      -0.569910     -0.982490     -0.986570     -0.977353     -0.989873   \n",
       "3      -0.579287     -0.983468     -0.993671     -0.981691     -0.988705   \n",
       "4      -0.562888     -0.985434     -0.989582     -0.977766     -0.992312   \n",
       "\n",
       "   std_Vy_hand0  std_Vz_hand0  std_Jx_hand0  std_Jy_hand0  std_Jz_hand0  \\\n",
       "0     -0.993020     -0.991915     -0.987831     -0.980208     -0.989201   \n",
       "1     -0.995350     -0.991068     -0.985650     -0.989803     -0.990776   \n",
       "2     -0.995094     -0.989250     -0.982060     -0.974212     -0.984971   \n",
       "3     -0.997187     -0.991816     -0.980892     -0.990306     -0.987761   \n",
       "4     -0.995606     -0.988233     -0.980415     -0.977572     -0.981928   \n",
       "\n",
       "   max_Ax_hand1  max_Ay_hand1  max_Az_hand1  max_Vx_hand1  max_Vy_hand1  \\\n",
       "0     -0.039172     -0.501367     -0.568651     -0.990805     -0.924076   \n",
       "1     -0.008904     -0.506077     -0.554681     -0.991092     -0.927038   \n",
       "2     -0.038226     -0.479631     -0.558174     -0.991075     -0.906099   \n",
       "3     -0.032078     -0.503903     -0.541061     -0.990907     -0.915759   \n",
       "4     -0.051941     -0.465140     -0.566206     -0.991309     -0.909646   \n",
       "\n",
       "   max_Vz_hand1  max_Jx_hand1  max_Jy_hand1  max_Jz_hand1  mean_Ax_hand1  \\\n",
       "0     -0.695349     -0.987071     -0.985312     -0.971907       0.639118   \n",
       "1     -0.694854     -0.967712     -0.964208     -0.975054       0.642146   \n",
       "2     -0.691700     -0.972633     -0.958047     -0.961943       0.633037   \n",
       "3     -0.697063     -0.973826     -0.983747     -0.944637       0.652336   \n",
       "4     -0.704007     -0.986692     -0.971950     -0.980560       0.621701   \n",
       "\n",
       "   mean_Ay_hand1  mean_Az_hand1  mean_Vx_hand1  mean_Vy_hand1  mean_Vz_hand1  \\\n",
       "0      -0.100274      -0.272429      -0.941629       0.943874       0.872673   \n",
       "1      -0.101240      -0.255789      -0.942063       0.943872       0.872309   \n",
       "2      -0.092331      -0.289585      -0.941847       0.944188       0.872212   \n",
       "3      -0.098316      -0.246432      -0.941578       0.944249       0.872286   \n",
       "4      -0.086185      -0.317926      -0.941801       0.944803       0.871091   \n",
       "\n",
       "   mean_Jx_hand1  mean_Jy_hand1  mean_Jz_hand1  std_Ax_hand1  std_Ay_hand1  \\\n",
       "0      -0.362298      -0.194153       0.127826     -0.957169     -0.983109   \n",
       "1      -0.355137      -0.181314       0.065502     -0.955312     -0.980318   \n",
       "2      -0.364613      -0.179053       0.104477     -0.950830     -0.972711   \n",
       "3      -0.368281      -0.206654       0.151899     -0.968204     -0.982735   \n",
       "4      -0.373012      -0.204285       0.066275     -0.976031     -0.964120   \n",
       "\n",
       "   std_Az_hand1  std_Vx_hand1  std_Vy_hand1  std_Vz_hand1  std_Jx_hand1  \\\n",
       "0     -0.949182     -0.999332     -0.999006     -0.998700     -0.978210   \n",
       "1     -0.925928     -0.999354     -0.999286     -0.998945     -0.959584   \n",
       "2     -0.927838     -0.999377     -0.998300     -0.998403     -0.968907   \n",
       "3     -0.947719     -0.999501     -0.999014     -0.999031     -0.966470   \n",
       "4     -0.906614     -0.999737     -0.998386     -0.999099     -0.983703   \n",
       "\n",
       "   std_Jy_hand1  std_Jz_hand1  max_w_hand0  max_x_hand0  max_y_hand0  \\\n",
       "0     -0.978833     -0.962425     0.120998     0.541663     0.170510   \n",
       "1     -0.965279     -0.928917     0.113299     0.542467     0.164254   \n",
       "2     -0.958949     -0.930081     0.111315     0.544231     0.162854   \n",
       "3     -0.966324     -0.951485     0.104951     0.545046     0.156980   \n",
       "4     -0.955734     -0.967074     0.101328     0.547569     0.154437   \n",
       "\n",
       "   max_z_hand0  max_AVx_hand0  max_AVy_hand0  max_AVz_hand0  max_AAx_hand0  \\\n",
       "0    -0.877719      -0.782585      -0.931713      -0.940076      -0.907688   \n",
       "1    -0.879209      -0.788702      -0.932419      -0.943368      -0.910027   \n",
       "2    -0.879386      -0.791156      -0.933613      -0.941954      -0.911110   \n",
       "3    -0.880772      -0.791326      -0.934445      -0.943880      -0.911471   \n",
       "4    -0.880973      -0.788771      -0.931090      -0.942088      -0.902945   \n",
       "\n",
       "   max_AAy_hand0  max_AAz_hand0  max_AJx_hand0  max_AJy_hand0  max_AJz_hand0  \\\n",
       "0      -0.985991      -0.979934      -0.994210      -0.999024      -0.994365   \n",
       "1      -0.986339      -0.983616      -0.995620      -0.999001      -0.995053   \n",
       "2      -0.986219      -0.981118      -0.995538      -0.998959      -0.994764   \n",
       "3      -0.987122      -0.986953      -0.995731      -0.999338      -0.995484   \n",
       "4      -0.984214      -0.983918      -0.989284      -0.998787      -0.994903   \n",
       "\n",
       "   mean_w_hand0  mean_x_hand0  mean_y_hand0  mean_z_hand0  mean_AVx_hand0  \\\n",
       "0      0.119734      0.556493      0.182533     -0.877081       -0.112933   \n",
       "1      0.114771      0.557711      0.177916     -0.878249       -0.110580   \n",
       "2      0.110235      0.559495      0.174286     -0.878855       -0.114078   \n",
       "3      0.106090      0.560828      0.170560     -0.879591       -0.111671   \n",
       "4      0.102183      0.562827      0.166788     -0.879936       -0.116054   \n",
       "\n",
       "   mean_AVy_hand0  mean_AVz_hand0  mean_AAx_hand0  mean_AAy_hand0  \\\n",
       "0       -0.191917        0.172213        0.046715       -0.797721   \n",
       "1       -0.191596        0.179751        0.049015       -0.797719   \n",
       "2       -0.191830        0.176102        0.048951       -0.797606   \n",
       "3       -0.190411        0.179345        0.048768       -0.797754   \n",
       "4       -0.190923        0.176640        0.048043       -0.797314   \n",
       "\n",
       "   mean_AAz_hand0  mean_AJx_hand0  mean_AJy_hand0  mean_AJz_hand0  \\\n",
       "0       -0.157594        0.158930       -0.766435       -0.301156   \n",
       "1       -0.156049        0.159665       -0.766074       -0.302451   \n",
       "2       -0.155521        0.159879       -0.766005       -0.301345   \n",
       "3       -0.158787        0.159960       -0.766137       -0.303050   \n",
       "4       -0.155884        0.161603       -0.766261       -0.303190   \n",
       "\n",
       "   std_w_hand0  std_x_hand0  std_y_hand0  std_z_hand0  std_AVx_hand0  \\\n",
       "0    -0.969740    -0.989063    -0.977065    -0.993989      -0.989559   \n",
       "1    -0.994841    -0.993888    -0.993105    -0.995995      -0.995622   \n",
       "2    -0.965699    -0.993244    -0.969085    -0.990123      -0.996947   \n",
       "3    -0.989433    -0.997373    -0.993854    -0.998071      -0.998884   \n",
       "4    -0.983526    -0.990722    -0.981613    -0.997338      -0.989515   \n",
       "\n",
       "   std_AVy_hand0  std_AVz_hand0  std_AAx_hand0  std_AAy_hand0  std_AAz_hand0  \\\n",
       "0      -0.994945      -0.988448      -0.995156      -0.998267      -0.987901   \n",
       "1      -0.995237      -0.995191      -0.998214      -0.998840      -0.994900   \n",
       "2      -0.997724      -0.992292      -0.998620      -0.999153      -0.991684   \n",
       "3      -0.999530      -0.996688      -0.999420      -0.999813      -0.995509   \n",
       "4      -0.994763      -0.991339      -0.994533      -0.997652      -0.992844   \n",
       "\n",
       "   std_AJx_hand0  std_AJy_hand0  std_AJz_hand0  max_w_hand1  max_x_hand1  \\\n",
       "0      -0.996821      -0.999347      -0.996959     0.579593    -0.207280   \n",
       "1      -0.999159      -0.999570      -0.998259     0.585591    -0.208809   \n",
       "2      -0.999424      -0.999684      -0.998113     0.566833    -0.207680   \n",
       "3      -0.999752      -0.999921      -0.998485     0.585796    -0.204431   \n",
       "4      -0.995052      -0.999170      -0.997168     0.582721    -0.180899   \n",
       "\n",
       "   max_y_hand1  max_z_hand1  max_AVx_hand1  max_AVy_hand1  max_AVz_hand1  \\\n",
       "0    -0.886235    -0.133564      -0.943090      -0.961539      -0.906408   \n",
       "1    -0.880409    -0.136687      -0.941532      -0.958191      -0.897454   \n",
       "2    -0.896479    -0.133976      -0.939613      -0.957666      -0.906743   \n",
       "3    -0.881512    -0.134703      -0.940476      -0.956152      -0.906613   \n",
       "4    -0.884487    -0.117784      -0.943651      -0.972696      -0.880702   \n",
       "\n",
       "   max_AAx_hand1  max_AAy_hand1  max_AAz_hand1  max_AJx_hand1  max_AJy_hand1  \\\n",
       "0      -0.993646      -0.992445      -0.993466      -0.998611      -0.999300   \n",
       "1      -0.986173      -0.979398      -0.981553      -0.994975      -0.995869   \n",
       "2      -0.991558      -0.988160      -0.993441      -0.996636      -0.998547   \n",
       "3      -0.993227      -0.989388      -0.994575      -0.999050      -0.999204   \n",
       "4      -0.990991      -0.993008      -0.979089      -0.995052      -0.997011   \n",
       "\n",
       "   max_AJz_hand1  mean_w_hand1  mean_x_hand1  mean_y_hand1  mean_z_hand1  \\\n",
       "0      -0.999123      0.571723     -0.176028     -0.878267     -0.123581   \n",
       "1      -0.996443      0.577854     -0.178063     -0.872131     -0.126934   \n",
       "2      -0.998862      0.565388     -0.175778     -0.883404     -0.123705   \n",
       "3      -0.998470      0.582345     -0.173310     -0.869825     -0.125886   \n",
       "4      -0.996720      0.556579     -0.160697     -0.895283     -0.113405   \n",
       "\n",
       "   mean_AVx_hand1  mean_AVy_hand1  mean_AVz_hand1  mean_AAx_hand1  \\\n",
       "0        0.132265        0.114995       -0.024707        0.123684   \n",
       "1        0.117509        0.083325       -0.023532        0.121184   \n",
       "2        0.124487        0.099164       -0.015073        0.121819   \n",
       "3        0.135159        0.115554       -0.022281        0.123207   \n",
       "4        0.109865        0.066044        0.014734        0.120515   \n",
       "\n",
       "   mean_AAy_hand1  mean_AAz_hand1  mean_AJx_hand1  mean_AJy_hand1  \\\n",
       "0       -0.127529        0.199302        0.198584       -0.164631   \n",
       "1       -0.129599        0.199234        0.200637       -0.160782   \n",
       "2       -0.129408        0.201098        0.196920       -0.165133   \n",
       "3       -0.127818        0.201379        0.197798       -0.165129   \n",
       "4       -0.128858        0.199156        0.197554       -0.162683   \n",
       "\n",
       "   mean_AJz_hand1  std_w_hand1  std_x_hand1  std_y_hand1  std_z_hand1  \\\n",
       "0        0.743395    -0.942989    -0.990935    -0.951021    -0.984447   \n",
       "1        0.742444    -0.925173    -0.984371    -0.936886    -0.987936   \n",
       "2        0.743693    -0.972134    -0.992089    -0.975612    -0.984483   \n",
       "3        0.744034    -0.938847    -0.987591    -0.947937    -0.974035   \n",
       "4        0.743029    -0.859082    -0.900871    -0.859034    -0.900662   \n",
       "\n",
       "   std_AVx_hand1  std_AVy_hand1  std_AVz_hand1  std_AAx_hand1  std_AAy_hand1  \\\n",
       "0      -0.994087      -0.988260      -0.982236      -0.995502      -0.994280   \n",
       "1      -0.983986      -0.965549      -0.978245      -0.986291      -0.984267   \n",
       "2      -0.989002      -0.978637      -0.990351      -0.988621      -0.987650   \n",
       "3      -0.992828      -0.983429      -0.990709      -0.995212      -0.992004   \n",
       "4      -0.982916      -0.978981      -0.970685      -0.986771      -0.989260   \n",
       "\n",
       "   std_AAz_hand1  std_AJx_hand1  std_AJy_hand1  std_AJz_hand1  \n",
       "0      -0.991199      -0.998840      -0.998778      -0.998416  \n",
       "1      -0.985112      -0.994982      -0.995564      -0.995649  \n",
       "2      -0.993807      -0.996414      -0.997308      -0.998629  \n",
       "3      -0.994691      -0.998644      -0.998075      -0.998693  \n",
       "4      -0.981962      -0.994707      -0.996628      -0.996723  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column to interact\n",
    "\n",
    "normalised_df.insert(5, \"new_interaction_id\", None)\n",
    "normalised_df['new_interaction_id'] = normalised_df.groupby(['participant_id', 'clothes_id', 'property_id', 'sub_window_num'], sort=False).ngroup() + 1\n",
    "normalised_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11e6e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain features for each hand\n",
    "hand1_emg = normalised_df.iloc[:,35:59]\n",
    "\n",
    "hand0_acc = normalised_df.iloc[:,59:86]\n",
    "hand1_acc = normalised_df.iloc[:,86:113]\n",
    "\n",
    "hand0_qua = normalised_df.iloc[:,113:152]\n",
    "hand1_qua = normalised_df.iloc[:,152:]\n",
    "\n",
    "df_info = normalised_df.iloc[:,:11]\n",
    "\n",
    "# Combine the data to ceate a df for each hand\n",
    "emg_0 = normalised_df.iloc[:,:35]\n",
    "emg_1 = pd.concat([df_info, hand1_emg], axis=1)\n",
    "\n",
    "hand_0 = pd.concat([emg_0, hand0_acc, hand0_qua], axis=1)\n",
    "hand_1 = pd.concat([df_info, hand1_emg, hand1_acc, hand1_qua], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a274476c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18899, 101)\n",
      "(18899, 101)\n",
      "(18899, 35)\n",
      "(18899, 35)\n"
     ]
    }
   ],
   "source": [
    "print(hand_0.shape)\n",
    "print(hand_1.shape)\n",
    "\n",
    "print(emg_0.shape)\n",
    "print(emg_1.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f383100",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faf095ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_all_features_properties(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(90, 40, 1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(3 * 40 * 2, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 5)\n",
    "          \n",
    "    def forward(self, x1, x2): #, x2\n",
    "        x1, (hn, cn) = self.rnn(x1) #, (self.h0, self.c0)\n",
    "        x1 = F.tanh(x1)\n",
    "        x2, (hm, cm) = self.rnn(x2) # (self.h0, self.c0)\n",
    "        x2 = F.tanh(x2)\n",
    "        \n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "class LSTM_all_features_ratings(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(90+5, 40, 1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(3 * 40 * 2, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "          \n",
    "    def forward(self, x1, x2): #, x2\n",
    "        x1, (hn, cn) = self.rnn(x1) #, (self.h0, self.c0)\n",
    "        x1 = F.tanh(x1)\n",
    "        x2, (hm, cm) = self.rnn(x2) # (self.h0, self.c0)\n",
    "        x2 = F.tanh(x2)\n",
    "        \n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "081f9c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_model_for_3d_X(train_dataloader, val_dataloader, learning_rate, num_epochs, model):\n",
    "\n",
    "    # Model\n",
    "    train_model = model\n",
    "\n",
    "    # Loss and Optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.7)\n",
    "\n",
    "    best_avg_loss = np.inf\n",
    "    best_model = None\n",
    "    #best_model_epoch_num = np.inf\n",
    "    train_loss_lst = []\n",
    "    val_loss_lst = []\n",
    "    avg_loss_lst = []\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        #Set the model in training mode\n",
    "        train_model.train()\n",
    "\n",
    "        # Initialise the total training and validation loss\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "        avg_loss = 0\n",
    "\n",
    "        #running_loss = 0.0\n",
    "        for i, train_data in enumerate(train_dataloader, 0):\n",
    "            #print(len(train_data))\n",
    "\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "            train_input1, train_input2, train_labels = train_data #train_input2, \n",
    "\n",
    "            #train_labels = train_labels.type(torch.LongTensor)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            train_preds = train_model(train_input1, train_input2)  \n",
    "            #print(train_labels)#\n",
    "\n",
    "            train_loss = criterion(train_preds, train_labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training loss\n",
    "            epoch_train_loss += train_loss.item()\n",
    "\n",
    "        # Switch off auto grad for evaluation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set the model in evaluation mode\n",
    "            train_model.eval()\n",
    "\n",
    "            for j, val_data in enumerate(val_dataloader, 0):\n",
    "               # print(len(val_data))\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "                val_input1, val_input2, val_labels = val_data # val_input2, \n",
    "\n",
    "                #val_labels = val_labels.type(torch.LongTensor)\n",
    "\n",
    "                val_preds = train_model(val_input1, val_input2) #, val_input2\n",
    "\n",
    "                # Update validation loss\n",
    "                val_loss = criterion(val_preds, val_labels)\n",
    "\n",
    "                epoch_val_loss += val_loss.item()\n",
    "     \n",
    "        avg_training_loss = epoch_train_loss / len(train_dataloader) #count_train\n",
    "        avg_validation_loss = epoch_val_loss / len(val_dataloader) #count_val\n",
    "        avg_loss = (avg_training_loss + avg_validation_loss) / 2\n",
    "        \n",
    "        train_loss_lst.append(avg_training_loss)\n",
    "        val_loss_lst.append(avg_validation_loss)\n",
    "        avg_loss_lst.append(avg_loss)\n",
    "         \n",
    "        print(f'epoch {epoch+1}: train loss = {round(avg_training_loss,3)}, val loss = {round(avg_validation_loss,3)}, average loss = {round(avg_loss,3)}')\n",
    "\n",
    "        if avg_loss < best_avg_loss:\n",
    "            best_avg_loss = avg_loss\n",
    "            best_model = train_model.state_dict()\n",
    "\n",
    "    return best_avg_loss, best_model, train_loss_lst, val_loss_lst, avg_loss_lst   #, avg_loss_lst, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5af2c451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def LSTM_LOP0CV(data_0, data_1, model, num_folds=5, predicting_feature='property_id', learning_rate=0.01, num_epochs=10, random_state=num): #, num_inner_folds=5\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(num)\n",
    "        \n",
    "    total_conf_mat = 0\n",
    "    micro_f1_lst = []\n",
    "    acc_lst = []\n",
    "    if predicting_feature == 'property_id':\n",
    "        macro_f1_lst = []\n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        weighted_f1_lst = [] \n",
    "        \n",
    "        data0_add = create_y_train_for_2d_X(data_0, predicting_feature = 'property_id', output_as_tensor='No')\n",
    "        data0_add_pd = pd.DataFrame(data0_add, columns = ['smoothness','thickness','warmth', 'flexibility', 'softness'])\n",
    "        data_0 = pd.concat([data_0.reset_index(drop=True), data0_add_pd.reset_index(drop=True)], axis=1)\n",
    "        data1_add = create_y_train_for_2d_X(data_1, predicting_feature = 'property_id', output_as_tensor='No')\n",
    "        data1_add_pd = pd.DataFrame(data1_add, columns = ['smoothness','thickness','warmth', 'flexibility', 'softness'])\n",
    "        data_1 = pd.concat([data_1.reset_index(drop=True), data1_add_pd.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    for participant in sorted(data_0.participant_id.unique()): # # #:lst: #\n",
    "        print(f'LEAVING PARTICIPANT {participant} OUT:')\n",
    "        \n",
    "        # Split the data into training and testing\n",
    "        training_data_0 = data_0[data_0.participant_id != participant] \n",
    "        training_data_1 = data_1[data_1.participant_id != participant] \n",
    "        testing_data_0 = data_0[data_0.participant_id == participant] \n",
    "        testing_data_1 = data_1[data_1.participant_id == participant] \n",
    "\n",
    "        # Data preparation\n",
    "        X_train_0 = create_X_3d(training_data_0, 11)\n",
    "        X_train_1 = create_X_3d(training_data_1, 11) \n",
    "        X_test_0 = create_X_3d(testing_data_0, 11) \n",
    "        X_test_1 = create_X_3d(testing_data_1, 11)           \n",
    "        y_train = create_y_train_for_3d_X(training_data_0, predicting_feature = predicting_feature)\n",
    "        y_test = create_y_test_for_3d_X(testing_data_0, predicting_feature = predicting_feature)        \n",
    " \n",
    "\n",
    "        #print(X_train_0.shape)\n",
    "        #print(X_train_1.shape)\n",
    "        #print(y_train.shape)\n",
    "        #print(X_test_0.shape)\n",
    "        #print(X_test_1.shape)\n",
    "        #print(y_test.shape)\n",
    " \n",
    "        # Create the datasets and dataloaders\n",
    "        train_dataset = TensorDataset(X_train_0, X_train_1, y_train) \n",
    "        \n",
    "        test_dataset = TensorDataset(X_test_0, X_test_1, y_test)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=y_test.shape[0]//4) # num_workers=2,       \n",
    "            \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_folds, shuffle=True, random_state=num)\n",
    "                \n",
    "        min_avg_loss_subject = np.inf\n",
    "        best_model_subject = None\n",
    "        \n",
    "        best_train_loss_lst = None\n",
    "        best_val_loss_lst = None\n",
    "        best_avg_loss_lst = None\n",
    "        best_fold = np.inf\n",
    "\n",
    "        for fold, (train_ids, val_ids) in enumerate(cv_inner.split(train_dataset)):\n",
    "            print(f'FOLD {fold+1}:')\n",
    "                       \n",
    "            # Sample elements randomly from a given list of ids, no replacement.\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids) # The ids are the same for both\n",
    "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "            # Define data loaders for training and testing data in this fold\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=train_subsampler) #, batch_size=100\n",
    "            val_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=val_subsampler) #, batch_size=20        \n",
    "\n",
    "            avg_loss_fold, best_model_fold, fold_train_loss_lst, fold_val_loss_lst, fold_avg_loss_lst = find_best_model_for_3d_X(train_dataloader, val_dataloader, learning_rate, num_epochs, model)\n",
    "                           \n",
    "            if avg_loss_fold < min_avg_loss_subject:\n",
    "                min_avg_loss_subject = avg_loss_fold\n",
    "                best_model_subject = best_model_fold\n",
    "                best_train_loss_lst = fold_train_loss_lst\n",
    "                best_val_loss_lst = fold_val_loss_lst\n",
    "                best_avg_loss_lst = fold_avg_loss_lst\n",
    "                best_fold = fold+1\n",
    "\n",
    "        fig = plt.figure(f\"{participant}\")                  \n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_train_loss_lst)\n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_val_loss_lst)\n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_avg_loss_lst)\n",
    "        plt.title(f\"Loss when participant {participant} is left out for fold {best_fold} (lr={learning_rate}, num_epochs ={num_epochs})\")\n",
    "        plt.legend(['train loss', 'val loss', 'avg_loss'])\n",
    "\n",
    "        # save trained model \n",
    "        name = 'model_participant_'+str(participant)+'.pt'\n",
    "        torch.save(best_model_subject, name)\n",
    "        print(f'The model for participant {participant} has been saved')\n",
    "        \n",
    "        test_model = model\n",
    "        test_model.load_state_dict(torch.load(name))\n",
    "\n",
    "        dataiter = iter(test_dataloader) \n",
    "        test_input1, test_input2, test_labels = dataiter.next() \n",
    "    \n",
    "        test_preds = test_model(test_input1, test_input2) \n",
    "        \n",
    "        test_preds_np = test_preds.detach().numpy()\n",
    "        test_predicted_np = np.argmax(test_preds_np, axis = 1)\n",
    "        \n",
    "        test_labels_np = test_labels.numpy()    \n",
    "        \n",
    "        if predicting_feature == 'property_id':\n",
    "            conf_mat = confusion_matrix(test_labels_np, test_predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "            macro_f1_score = f1_score(test_labels_np, test_predicted_np, average='macro') \n",
    "            macro_f1_lst.append(macro_f1_score) \n",
    "        elif predicting_feature == 'rating_level_num':\n",
    "            conf_mat = confusion_matrix(test_labels_np, test_predicted_np, labels=[0,1,2])\n",
    "            weighted_f1_score = f1_score(test_labels_np, test_predicted_np, average='weighted') \n",
    "            weighted_f1_lst.append(weighted_f1_score)\n",
    "            \n",
    "        total_conf_mat += conf_mat\n",
    "        micro_f1_score = f1_score(test_labels_np, test_predicted_np, average='micro')  \n",
    "        micro_f1_lst.append(micro_f1_score)\n",
    "        acc = accuracy_score(test_labels_np, test_predicted_np)\n",
    "        acc_lst.append(acc)\n",
    "\n",
    "\n",
    "        print(f\"Leaving participant {participant} out\")\n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        if predicting_feature == 'property_id':\n",
    "            print(f\"(3) Macro F1 score = {round(macro_f1_score,2)}\")\n",
    "        elif predicting_feature == 'rating_level_num':\n",
    "            print(f\"(3) Weighted F1 score = {round(weighted_f1_score,2)}\")            \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "        \n",
    "        total_conf_mat += conf_mat \n",
    "        micro_f1_lst.append(micro_f1_score)\n",
    "        acc_lst.append(acc)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "    avg_micro_f1_score = sum(micro_f1_lst) / len(micro_f1_lst)\n",
    "    if predicting_feature == 'property_id':\n",
    "        avg_macro_f1_score = sum(macro_f1_lst) / len(macro_f1_lst)  \n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        avg_weighted_f1_score = sum(weighted_f1_lst) / len(weighted_f1_lst)             \n",
    "    avg_acc = sum(acc_lst) / len(acc_lst)   \n",
    "    \n",
    "    print(f'Using Leave One Participant Out CV (LOPOCV):') \n",
    "    print(\"(1) Confusion matrix:\\n\", total_conf_mat)\n",
    "    print(f\"(2) Average micro F1 score = {round(avg_micro_f1_score,2)}\")\n",
    "    if predicting_feature == 'property_id':\n",
    "        print(f\"(3) Average macro F1 score = {round(avg_macro_f1_score,2)}\")\n",
    "    elif predicting_feature == 'rating_level_num':\n",
    "        print(f\"(3) Average weighted F1 score = {round(avg_weighted_f1_score,2)}\")      \n",
    "    print(f\"(4) Average Percentage Classification accuracy = {round(avg_acc*100,2)}%\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9428aa2",
   "metadata": {},
   "source": [
    "### Run the model for properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90840762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAVING PARTICIPANT 1 OUT:\n",
      "FOLD 1:\n",
      "epoch 1: train loss = 1.613, val loss = 1.596, average loss = 1.604\n",
      "epoch 2: train loss = 1.608, val loss = 1.612, average loss = 1.61\n",
      "epoch 3: train loss = 1.606, val loss = 1.601, average loss = 1.603\n",
      "epoch 4: train loss = 1.61, val loss = 1.616, average loss = 1.613\n",
      "epoch 5: train loss = 1.611, val loss = 1.613, average loss = 1.612\n",
      "epoch 6: train loss = 1.606, val loss = 1.583, average loss = 1.594\n",
      "epoch 7: train loss = 1.614, val loss = 1.625, average loss = 1.62\n",
      "epoch 8: train loss = 1.614, val loss = 1.623, average loss = 1.619\n",
      "epoch 9: train loss = 1.617, val loss = 1.614, average loss = 1.615\n",
      "epoch 10: train loss = 1.626, val loss = 1.611, average loss = 1.619\n",
      "epoch 11: train loss = 1.617, val loss = 1.677, average loss = 1.647\n",
      "epoch 12: train loss = 1.613, val loss = 1.604, average loss = 1.609\n",
      "epoch 13: train loss = 1.621, val loss = 1.625, average loss = 1.623\n",
      "epoch 14: train loss = 1.622, val loss = 1.675, average loss = 1.648\n",
      "epoch 15: train loss = 1.622, val loss = 1.624, average loss = 1.623\n",
      "epoch 16: train loss = 1.63, val loss = 1.681, average loss = 1.656\n",
      "epoch 17: train loss = 1.623, val loss = 1.66, average loss = 1.641\n",
      "epoch 18: train loss = 1.61, val loss = 1.675, average loss = 1.643\n",
      "epoch 19: train loss = 1.619, val loss = 1.663, average loss = 1.641\n",
      "epoch 20: train loss = 1.62, val loss = 1.682, average loss = 1.651\n",
      "epoch 21: train loss = 1.63, val loss = 1.612, average loss = 1.621\n",
      "epoch 22: train loss = 1.631, val loss = 1.669, average loss = 1.65\n",
      "epoch 23: train loss = 1.623, val loss = 1.632, average loss = 1.627\n",
      "epoch 24: train loss = 1.63, val loss = 1.619, average loss = 1.625\n",
      "epoch 25: train loss = 1.629, val loss = 1.642, average loss = 1.636\n",
      "epoch 26: train loss = 1.636, val loss = 1.61, average loss = 1.623\n",
      "epoch 27: train loss = 1.63, val loss = 1.662, average loss = 1.646\n",
      "epoch 28: train loss = 1.632, val loss = 1.699, average loss = 1.666\n",
      "epoch 29: train loss = 1.63, val loss = 1.611, average loss = 1.621\n",
      "epoch 30: train loss = 1.634, val loss = 1.607, average loss = 1.621\n",
      "epoch 31: train loss = 1.632, val loss = 1.609, average loss = 1.621\n",
      "epoch 32: train loss = 1.633, val loss = 1.629, average loss = 1.631\n",
      "epoch 33: train loss = 1.634, val loss = 1.612, average loss = 1.623\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/2363913973.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLSTM_LOP0CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhand_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhand_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_all_features_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicting_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'property_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.085\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, num_inner_folds=5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/1861039680.py\u001b[0m in \u001b[0;36mLSTM_LOP0CV\u001b[0;34m(data_0, data_1, model, num_folds, predicting_feature, learning_rate, num_epochs, random_state)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_subsampler\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, batch_size=20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mavg_loss_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_train_loss_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_val_loss_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_avg_loss_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_model_for_3d_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mavg_loss_fold\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_avg_loss_subject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/3809940380.py\u001b[0m in \u001b[0;36mfind_best_model_for_3d_X\u001b[0;34m(train_dataloader, val_dataloader, learning_rate, num_epochs, model)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m#print(train_labels)#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/2022380094.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#, x2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, (self.h0, self.c0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (self.h0, self.c0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;31m# xxx: isinstance check needs to be in conditional for TorchScript to compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             \u001b[0moutput_packed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput_packed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTM_LOP0CV(hand_0, hand_1, model=LSTM_all_features_properties(), num_folds=5, predicting_feature='property_id', learning_rate=0.085, num_epochs=50, random_state=num) #, num_inner_folds=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0e907",
   "metadata": {},
   "source": [
    "### Run the model for ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef2a2ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAVING PARTICIPANT 1 OUT:\n",
      "FOLD 1:\n",
      "epoch 1: train loss = 1.037, val loss = 1.029, average loss = 1.033\n",
      "epoch 2: train loss = 1.024, val loss = 1.011, average loss = 1.017\n",
      "epoch 3: train loss = 1.0, val loss = 0.994, average loss = 0.997\n",
      "epoch 4: train loss = 0.985, val loss = 0.989, average loss = 0.987\n",
      "epoch 5: train loss = 0.982, val loss = 0.984, average loss = 0.983\n",
      "epoch 6: train loss = 0.976, val loss = 0.965, average loss = 0.97\n",
      "epoch 7: train loss = 0.969, val loss = 0.993, average loss = 0.981\n",
      "epoch 8: train loss = 0.956, val loss = 0.968, average loss = 0.962\n",
      "epoch 9: train loss = 0.955, val loss = 1.081, average loss = 1.018\n",
      "epoch 10: train loss = 0.941, val loss = 0.937, average loss = 0.939\n",
      "epoch 11: train loss = 0.939, val loss = 0.94, average loss = 0.939\n",
      "epoch 12: train loss = 0.932, val loss = 0.983, average loss = 0.958\n",
      "epoch 13: train loss = 0.935, val loss = 0.927, average loss = 0.931\n",
      "epoch 14: train loss = 0.936, val loss = 0.945, average loss = 0.941\n",
      "epoch 15: train loss = 0.928, val loss = 0.917, average loss = 0.923\n",
      "epoch 16: train loss = 0.926, val loss = 0.916, average loss = 0.921\n",
      "epoch 17: train loss = 0.934, val loss = 0.923, average loss = 0.928\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/421668729.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLSTM_LOP0CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhand_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhand_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_all_features_ratings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicting_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rating_level_num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, num_inner_folds=5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/1861039680.py\u001b[0m in \u001b[0;36mLSTM_LOP0CV\u001b[0;34m(data_0, data_1, model, num_folds, predicting_feature, learning_rate, num_epochs, random_state)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_subsampler\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, batch_size=20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mavg_loss_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_train_loss_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_val_loss_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_avg_loss_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_model_for_3d_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mavg_loss_fold\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_avg_loss_subject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/3809940380.py\u001b[0m in \u001b[0;36mfind_best_model_for_3d_X\u001b[0;34m(train_dataloader, val_dataloader, learning_rate, num_epochs, model)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_input1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;31m#print(train_labels)#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/2022380094.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#, x2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, (self.h0, self.c0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (self.h0, self.c0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    692\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTM_LOP0CV(hand_0, hand_1, model=LSTM_all_features_ratings(), num_folds=5, predicting_feature='rating_level_num', learning_rate=0.005, num_epochs=50, random_state=num) #, num_inner_folds=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03910a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 4 - LSTM + fully connected layers using only the emg data (48 features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc49f77",
   "metadata": {},
   "source": [
    "complete_emg = normalised_df.iloc[:,:59]\n",
    "hand0_emg = normalised_df.iloc[:,35:59]\n",
    "hand0_emg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b71f4b4-8868-415f-9418-8503620ecb93",
   "metadata": {},
   "source": [
    "#hand0_emg = normalised_df.iloc[:,19:27]\n",
    "hand1_emg = normalised_df.iloc[:,35:59]\n",
    "\n",
    "emg_0 = normalised_df.iloc[:,:35]\n",
    "emg_1 = pd.concat([df_info, hand1_emg], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff25e95",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d84d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_emg_features_properties(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(24, 15, 1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(3 * 15 * 2, 25)\n",
    "        self.fc2 = nn.Linear(25, 10)\n",
    "        self.fc3 = nn.Linear(10, 5)\n",
    "          \n",
    "    def forward(self, x1, x2): #, x2\n",
    "        x1, (hn, cn) = self.rnn(x1) #, (self.h0, self.c0)\n",
    "        x1 = F.tanh(x1)\n",
    "        x2, (hm, cm) = self.rnn(x2) # (self.h0, self.c0)\n",
    "        x2 = F.tanh(x2)\n",
    "        \n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x\n",
    "    \n",
    "class LSTM_emg_features_ratings(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(24+5, 15, 1, batch_first=True)\n",
    "        self.fc1 = nn.Linear(3 * 15 * 2, 25)\n",
    "        self.fc2 = nn.Linear(25, 10)\n",
    "        self.fc3 = nn.Linear(10, 3)\n",
    "          \n",
    "    def forward(self, x1, x2): #, x2\n",
    "        x1, (hn, cn) = self.rnn(x1) #, (self.h0, self.c0)\n",
    "        x1 = F.tanh(x1)\n",
    "        x2, (hm, cm) = self.rnn(x2) # (self.h0, self.c0)\n",
    "        x2 = F.tanh(x2)\n",
    "        \n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5355cefe",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ec1ec13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAVING PARTICIPANT 1 OUT:\n",
      "FOLD 1:\n",
      "epoch 1: train loss = 1.61, val loss = 1.609, average loss = 1.61\n",
      "epoch 2: train loss = 1.61, val loss = 1.61, average loss = 1.61\n",
      "epoch 3: train loss = 1.609, val loss = 1.61, average loss = 1.609\n",
      "epoch 4: train loss = 1.609, val loss = 1.611, average loss = 1.61\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/3398315568.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLSTM_LOP0CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memg_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memg_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLSTM_emg_features_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicting_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'property_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, num_inner_folds=5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/1861039680.py\u001b[0m in \u001b[0;36mLSTM_LOP0CV\u001b[0;34m(data_0, data_1, model, num_folds, predicting_feature, learning_rate, num_epochs, random_state)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_subsampler\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#, batch_size=20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mavg_loss_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_train_loss_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_val_loss_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_avg_loss_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_model_for_3d_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mavg_loss_fold\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_avg_loss_subject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2l/2jbt3sns75nf0k4xsrp2zvy00000gn/T/ipykernel_1563/3809940380.py\u001b[0m in \u001b[0;36mfind_best_model_for_3d_X\u001b[0;34m(train_dataloader, val_dataloader, learning_rate, num_epochs, model)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LSTM_LOP0CV(emg_0, emg_1, model=LSTM_emg_features_properties(), num_folds=5, predicting_feature='property_id', learning_rate=0.005, num_epochs=70, random_state=num) #, num_inner_folds=5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f399fc",
   "metadata": {},
   "source": [
    "### Run the model for ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3382ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEAVING PARTICIPANT 1 OUT:\n",
      "FOLD 1:\n",
      "epoch 1: train loss = 1.037, val loss = 1.031, average loss = 1.034\n",
      "epoch 2: train loss = 1.031, val loss = 1.028, average loss = 1.03\n",
      "epoch 3: train loss = 1.022, val loss = 0.997, average loss = 1.009\n",
      "epoch 4: train loss = 0.994, val loss = 0.98, average loss = 0.987\n",
      "epoch 5: train loss = 0.981, val loss = 0.981, average loss = 0.981\n",
      "epoch 6: train loss = 0.972, val loss = 0.971, average loss = 0.972\n",
      "epoch 7: train loss = 0.97, val loss = 0.968, average loss = 0.969\n",
      "epoch 8: train loss = 0.968, val loss = 0.97, average loss = 0.969\n",
      "epoch 9: train loss = 0.964, val loss = 1.0, average loss = 0.982\n",
      "epoch 10: train loss = 0.962, val loss = 0.963, average loss = 0.962\n",
      "epoch 11: train loss = 0.961, val loss = 0.958, average loss = 0.96\n",
      "epoch 12: train loss = 0.961, val loss = 0.96, average loss = 0.961\n",
      "epoch 13: train loss = 0.96, val loss = 0.959, average loss = 0.959\n",
      "epoch 14: train loss = 0.955, val loss = 0.958, average loss = 0.956\n",
      "epoch 15: train loss = 0.953, val loss = 0.961, average loss = 0.957\n",
      "epoch 16: train loss = 0.95, val loss = 0.964, average loss = 0.957\n",
      "epoch 17: train loss = 0.942, val loss = 0.952, average loss = 0.947\n",
      "epoch 18: train loss = 0.936, val loss = 0.944, average loss = 0.94\n",
      "epoch 19: train loss = 0.933, val loss = 0.938, average loss = 0.936\n",
      "epoch 20: train loss = 0.934, val loss = 0.933, average loss = 0.934\n",
      "epoch 21: train loss = 0.93, val loss = 0.937, average loss = 0.934\n",
      "epoch 22: train loss = 0.925, val loss = 0.947, average loss = 0.936\n",
      "epoch 23: train loss = 0.927, val loss = 0.96, average loss = 0.944\n",
      "epoch 24: train loss = 0.929, val loss = 0.976, average loss = 0.953\n",
      "epoch 25: train loss = 0.922, val loss = 0.941, average loss = 0.931\n"
     ]
    }
   ],
   "source": [
    "LSTM_LOP0CV(emg_0, emg_1, model=LSTM_emg_features_ratings(), num_folds=5, predicting_feature='rating_level_num', learning_rate=0.005, num_epochs=70, random_state=num) #, num_inner_folds=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtryftugyihuoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf3c47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddae3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d494769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b458f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f57dfeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a1d36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0e1cb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af37f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2dfef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeafe6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37497147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f0654e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64fb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model_for_fold_4(train_dataloader, val_dataloader, learning_rate, num_epochs):\n",
    "\n",
    "    # Model\n",
    "    train_model = LSTM_2()\n",
    "\n",
    "    # Loss and Optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.7)\n",
    "\n",
    "    best_avg_loss = np.inf\n",
    "    best_model = None\n",
    "    #best_model_epoch_num = np.inf\n",
    "    train_loss_lst = []\n",
    "    val_loss_lst = []\n",
    "    avg_loss_lst = []\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        #Set the model in training mode\n",
    "        train_model.train()\n",
    "\n",
    "        # Initialise the total training and validation loss\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "        avg_loss = 0\n",
    "        #count_train = 0\n",
    "        #count_val = 0\n",
    "\n",
    "        #running_loss = 0.0\n",
    "        for i, train_data in enumerate(train_dataloader, 0):\n",
    "            #print(len(train_data))\n",
    "            #count_train += 1\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "            train_input1, train_input2, train_labels = train_data #train_input2, \n",
    "\n",
    "            #train_labels = train_labels.type(torch.LongTensor)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            train_preds = train_model(train_input1, train_input2)  \n",
    "            #print(train_labels)#\n",
    "\n",
    "            train_loss = criterion(train_preds, train_labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training loss\n",
    "            epoch_train_loss += train_loss.item()\n",
    "\n",
    "        # Switch off auto grad for evaluation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set the model in evaluation mode\n",
    "            train_model.eval()\n",
    "\n",
    "            for j, val_data in enumerate(val_dataloader, 0):\n",
    "               # count_val += 1\n",
    "               # print(len(val_data))\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "                val_input1, val_input2, val_labels = val_data # val_input2, \n",
    "\n",
    "                #val_labels = val_labels.type(torch.LongTensor)\n",
    "\n",
    "                val_preds = train_model(val_input1, val_input2) #, val_input2\n",
    "\n",
    "                # Update validation loss\n",
    "                val_loss = criterion(val_preds, val_labels)\n",
    "\n",
    "                epoch_val_loss += val_loss.item()\n",
    "        #print(len(train_dataloader), len(val_dataloader))       \n",
    "        avg_training_loss = epoch_train_loss / len(train_dataloader) #count_train\n",
    "        avg_validation_loss = epoch_val_loss / len(val_dataloader) #count_val\n",
    "        avg_loss = (avg_training_loss + avg_validation_loss) / 2\n",
    "        \n",
    "        train_loss_lst.append(avg_training_loss)\n",
    "        val_loss_lst.append(avg_validation_loss)\n",
    "        avg_loss_lst.append(avg_loss)\n",
    "         \n",
    "        #print(f'epoch {epoch+1}: train loss = {round(avg_training_loss,2)}, val loss = {round(avg_validation_loss,2)}, average loss = {round(avg_loss,2)}')\n",
    "\n",
    "        if avg_loss < best_avg_loss:\n",
    "            best_avg_loss = avg_loss\n",
    "            best_model = train_model.state_dict()\n",
    "\n",
    "    return best_avg_loss, best_model, train_loss_lst, val_loss_lst, avg_loss_lst   #, avg_loss_lst, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aadc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def LSTM_LOP0CV_properties_2(data_0, data_1, num_folds=5, predicting_feature='property_id', learning_rate=0.01, num_epochs=10, random_state=num): #, num_inner_folds=5\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(num)\n",
    "    \n",
    "   # elif predicting_feature == 'rating_level_num':\n",
    "    #weighted_f1_lst = [] \n",
    "    total_conf_mat = 0\n",
    "    micro_f1_lst = []\n",
    "    macro_f1_lst = []\n",
    "    acc_lst = []\n",
    "\n",
    "    #lst = [6,24,2]#,24]\n",
    "    \n",
    "    for participant in sorted(data_0.participant_id.unique()): # #:lst: #\n",
    "        print(f'LEAVING PARTICIPANT {participant} OUT:')\n",
    "        \n",
    "        # Split the data into training and testing\n",
    "        training_data_0 = data_0[data_0.participant_id != participant] \n",
    "        training_data_1 = data_1[data_1.participant_id != participant] \n",
    "        testing_data_0 = data_0[data_0.participant_id == participant] \n",
    "        testing_data_1 = data_1[data_1.participant_id == participant] \n",
    "\n",
    "        # Data preparation\n",
    "        X_train_0 = create_X_3d(training_data_0, 11)\n",
    "        X_train_1 = create_X_3d(training_data_1, 11)        \n",
    "        y_train = create_y_train_for_3d_X(training_data_0, predicting_feature = 'property_id')\n",
    "        X_test_0 = create_X_3d(testing_data_0, 11) \n",
    "        X_test_1 = create_X_3d(testing_data_1, 11)\n",
    "        y_test = create_y_test_for_3d_X(testing_data_0, predicting_feature = 'property_id')\n",
    "        #print(y_test)\n",
    "\n",
    "        #print(X_train_0.shape)\n",
    "        #print(X_train_1.shape)\n",
    "        #print(y_train.shape)\n",
    "        #print(X_test_0.shape)\n",
    "        #print(X_test_1.shape)\n",
    "        #print(y_test.shape)\n",
    " \n",
    "        # Create the datasets and dataloaders\n",
    "        train_dataset = TensorDataset(X_train_0, X_train_1, y_train) \n",
    "        \n",
    "        test_dataset = TensorDataset(X_test_0, X_test_1, y_test)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=30) # num_workers=2,       \n",
    "            \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_folds, shuffle=True, random_state=num)\n",
    "                \n",
    "        min_avg_loss_subject = np.inf\n",
    "        best_model_subject = None\n",
    "        \n",
    "        best_train_loss_lst = None\n",
    "        best_val_loss_lst = None\n",
    "        best_avg_loss_lst = None\n",
    "        best_fold = np.inf\n",
    "\n",
    "        for fold, (train_ids, val_ids) in enumerate(cv_inner.split(train_dataset)):\n",
    "            #print(f'FOLD {fold+1}:')\n",
    "                       \n",
    "            # Sample elements randomly from a given list of ids, no replacement.\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids) # The ids are the same for both\n",
    "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "            # Define data loaders for training and testing data in this fold\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=train_subsampler) #, batch_size=100\n",
    "            val_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=val_subsampler) #, batch_size=20        \n",
    "\n",
    "            avg_loss_fold, best_model_fold, fold_train_loss_lst, fold_val_loss_lst, fold_avg_loss_lst = find_best_model_for_fold_4(train_dataloader, val_dataloader, learning_rate, num_epochs)\n",
    "                           \n",
    "            if avg_loss_fold < min_avg_loss_subject:\n",
    "                min_avg_loss_subject = avg_loss_fold\n",
    "                best_model_subject = best_model_fold\n",
    "                best_train_loss_lst = fold_train_loss_lst\n",
    "                best_val_loss_lst = fold_val_loss_lst\n",
    "                best_avg_loss_lst = fold_avg_loss_lst\n",
    "                best_fold = fold+1\n",
    "\n",
    "        fig = plt.figure(f\"{participant}\")                  \n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_train_loss_lst)\n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_val_loss_lst)\n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_avg_loss_lst)\n",
    "        plt.title(f\"Loss when participant {participant} is left out for fold {best_fold} (lr={learning_rate}, num_epochs ={num_epochs})\")\n",
    "        plt.legend(['train loss', 'val loss', 'avg_loss'])\n",
    "\n",
    "        # save trained model \n",
    "        name = 'model_participant_'+str(participant)+'.pt'\n",
    "        torch.save(best_model_subject, name)\n",
    "        print(f'The model for participant {participant} has been saved')\n",
    "        \n",
    "        test_model = LSTM_2()\n",
    "        test_model.load_state_dict(torch.load(name))\n",
    "\n",
    "        dataiter = iter(test_dataloader) \n",
    "        test_input1, test_input2, test_labels = dataiter.next() \n",
    "    \n",
    "        test_preds = test_model(test_input1, test_input2) \n",
    "        \n",
    "        test_preds_np = test_preds.detach().numpy()\n",
    "        test_predicted_np = np.argmax(test_preds_np, axis = 1)\n",
    "        \n",
    "        test_labels_np = test_labels.numpy()       \n",
    "        \n",
    "\n",
    "        conf_mat = confusion_matrix(test_labels_np, test_predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "        macro_f1_score = f1_score(test_labels_np, test_predicted_np, average='macro') \n",
    "        micro_f1_score = f1_score(test_labels_np, test_predicted_np, average='micro')  \n",
    "        acc = accuracy_score(test_labels_np, test_predicted_np)\n",
    "\n",
    "        print(f\"Leaving participant {participant} out\")\n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        print(f\"(3) macro F1 score = {round(macro_f1_score,2)}\")    \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "        \n",
    "        total_conf_mat += conf_mat \n",
    "        micro_f1_lst.append(micro_f1_score)\n",
    "        macro_f1_lst.append(macro_f1_score) \n",
    "        acc_lst.append(acc)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "    avg_micro_f1_score = sum(micro_f1_lst) / len(micro_f1_lst)\n",
    "    avg_macro_f1_score = sum(macro_f1_lst) / len(macro_f1_lst)         \n",
    "    avg_acc = sum(acc_lst) / len(acc_lst)   \n",
    "    \n",
    "    print(f'Using Leave One Participant Out CV (LOPOCV):') \n",
    "    print(\"(1) Confusion matrix:\\n\", total_conf_mat)\n",
    "    print(f\"(2) Average micro F1 score = {round(avg_micro_f1_score,2)}\")\n",
    "    #if predicting_feature == 'property_id':\n",
    "    print(f\"(3) Average macro F1 score = {round(avg_macro_f1_score,2)}\")\n",
    "    #elif predicting_feature == 'rating_level_num':\n",
    "        #print(f\"(3) Average weighted F1 score = {round(avg_weighted_f1_score,2)}\")      \n",
    "    print(f\"(4) Average Percentage Classification accuracy = {round(avg_acc*100,2)}%\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a844967",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_LOP0CV_properties_2(emg_0, emg_1, num_folds=5, predicting_feature='property_id', learning_rate=0.05, num_epochs=70, random_state=num) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192662c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb412602",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 5 - CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bea4585",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_emg = normalised_df.iloc[:,:59]\n",
    "hand0_emg = normalised_df.iloc[:,43:51]\n",
    "hand0_emg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b4b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hand0_emg = normalised_df.iloc[:,19:27]\n",
    "hand1_emg = normalised_df.iloc[:,43:51]\n",
    "\n",
    "emg_0 = pd.concat([df_info, hand0_emg], axis=1)\n",
    "emg_1 = pd.concat([df_info, hand1_emg], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501649a7",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402ec841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=3, kernel_size=1, stride=1, padding=0, groups=3) # Change kernel size to 3\n",
    "        self.pool = nn.MaxPool1d(1, 1) # Change kernel size to 1 and stride to 1\n",
    "        self.rnn = nn.LSTM(8, 4, 1, batch_first=True)\n",
    "        #self.h0 = torch.randn(1, 50, 7)\n",
    "        #self.c0 = torch.randn(1, 50, 7)\n",
    "        self.fc1 = nn.Linear(3 * 4 * 2, 18)\n",
    "        self.fc2 = nn.Linear(18, 10)\n",
    "        self.fc3 = nn.Linear(10, 5)\n",
    "          \n",
    "    def forward(self, x1, x2): #, x2\n",
    "        x1 = self.pool(F.tanh(self.conv1(x1))) # Use tanh instead?\n",
    "        x2 = self.pool(F.tanh(self.conv1(x2))) # Use tanh instead?\n",
    "        \n",
    "        #x = self.pool(F.relu(self.conv2(x)))\n",
    "        x1, (hn, cn) = self.rnn(x1) #, (self.h0, self.c0)\n",
    "        x1 = F.tanh(x1)\n",
    "        x2, (hm, cm) = self.rnn(x2) # (self.h0, self.c0)\n",
    "        x2 = F.tanh(x2)\n",
    "        \n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        \n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75b282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = CNN_LSTM()\n",
    "print(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392415b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model_for_fold_3(train_dataloader, val_dataloader, learning_rate, num_epochs):\n",
    "\n",
    "    # Model\n",
    "    train_model = CNN_LSTM()\n",
    "\n",
    "    # Loss and Optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.7)\n",
    "\n",
    "    best_avg_loss = np.inf\n",
    "    best_model = None\n",
    "    #best_model_epoch_num = np.inf\n",
    "    train_loss_lst = []\n",
    "    val_loss_lst = []\n",
    "    avg_loss_lst = []\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        #Set the model in training mode\n",
    "        train_model.train()\n",
    "\n",
    "        # Initialise the total training and validation loss\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "        avg_loss = 0\n",
    "        #count_train = 0\n",
    "        #count_val = 0\n",
    "\n",
    "        #running_loss = 0.0\n",
    "        for i, train_data in enumerate(train_dataloader, 0):\n",
    "            #print(len(train_data))\n",
    "            #count_train += 1\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "            train_input1, train_input2, train_labels = train_data #train_input2, \n",
    "\n",
    "            #train_labels = train_labels.type(torch.LongTensor)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            train_preds = train_model(train_input1, train_input2)  \n",
    "            #print(train_labels)#\n",
    "\n",
    "            train_loss = criterion(train_preds, train_labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training loss\n",
    "            epoch_train_loss += train_loss.item()\n",
    "\n",
    "        # Switch off auto grad for evaluation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set the model in evaluation mode\n",
    "            train_model.eval()\n",
    "\n",
    "            for j, val_data in enumerate(val_dataloader, 0):\n",
    "               # count_val += 1\n",
    "               # print(len(val_data))\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "                val_input1, val_input2, val_labels = val_data # val_input2, \n",
    "\n",
    "                #val_labels = val_labels.type(torch.LongTensor)\n",
    "\n",
    "                val_preds = train_model(val_input1, val_input2) #, val_input2\n",
    "\n",
    "                # Update validation loss\n",
    "                val_loss = criterion(val_preds, val_labels)\n",
    "\n",
    "                epoch_val_loss += val_loss.item()\n",
    "        #print(len(train_dataloader), len(val_dataloader))       \n",
    "        avg_training_loss = epoch_train_loss / len(train_dataloader) #count_train\n",
    "        avg_validation_loss = epoch_val_loss / len(val_dataloader) #count_val\n",
    "        avg_loss = (avg_training_loss + avg_validation_loss) / 2\n",
    "        \n",
    "        train_loss_lst.append(avg_training_loss)\n",
    "        val_loss_lst.append(avg_validation_loss)\n",
    "        avg_loss_lst.append(avg_loss)\n",
    "         \n",
    "        print(f'epoch {epoch+1}: train loss = {round(avg_training_loss,2)}, val loss = {round(avg_validation_loss,2)}, average loss = {round(avg_loss,2)}')\n",
    "\n",
    "        if avg_loss < best_avg_loss:\n",
    "            best_avg_loss = avg_loss\n",
    "            best_model = train_model.state_dict()\n",
    "\n",
    "    return best_avg_loss, best_model, train_loss_lst, val_loss_lst, avg_loss_lst   #, avg_loss_lst, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740884a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def CNN_LSTM_LOP0CV_properties_1(data_0, data_1, num_folds=5, predicting_feature='property_id', learning_rate=0.01, num_epochs=10, random_state=num): #, num_inner_folds=5\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(num)\n",
    "    \n",
    "   # elif predicting_feature == 'rating_level_num':\n",
    "    #weighted_f1_lst = [] \n",
    "    total_conf_mat = 0\n",
    "    micro_f1_lst = []\n",
    "    macro_f1_lst = []\n",
    "    acc_lst = []\n",
    "\n",
    "    lst = [6,24,2]#,24]\n",
    "    \n",
    "    for participant in lst: #sorted(data0.participant_id.unique()): # #:lst: #\n",
    "        print(f'LEAVING PARTICIPANT {participant} OUT:')\n",
    "        \n",
    "        # Split the data into training and testing\n",
    "        training_data_0 = data_0[data_0.participant_id != participant] \n",
    "        training_data_1 = data_1[data_1.participant_id != participant] \n",
    "        testing_data_0 = data_0[data_0.participant_id == participant] \n",
    "        testing_data_1 = data_1[data_1.participant_id == participant] \n",
    "\n",
    "        # Data preparation\n",
    "        X_train_0 = create_X_3d(training_data_0, 11)\n",
    "        X_train_1 = create_X_3d(training_data_1, 11)        \n",
    "        y_train = create_y_train_for_3d_X(training_data_0, predicting_feature = 'property_id')\n",
    "        X_test_0 = create_X_3d(testing_data_0, 11) \n",
    "        X_test_1 = create_X_3d(testing_data_1, 11)\n",
    "        y_test = create_y_test_for_3d_X(testing_data_0, predicting_feature = 'property_id')\n",
    "        #print(y_test)\n",
    "\n",
    "        #print(X_train_0.shape)\n",
    "        #print(X_train_1.shape)\n",
    "        #print(y_train.shape)\n",
    "        #print(X_test_0.shape)\n",
    "        #print(X_test_1.shape)\n",
    "        #print(y_test.shape)\n",
    " \n",
    "        # Create the datasets and dataloaders\n",
    "        train_dataset = TensorDataset(X_train_0, X_train_1, y_train) \n",
    "        \n",
    "        test_dataset = TensorDataset(X_test_0, X_test_1, y_test)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=30) # num_workers=2,       \n",
    "            \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_folds, shuffle=True, random_state=num)\n",
    "                \n",
    "        min_avg_loss_subject = np.inf\n",
    "        best_model_subject = None\n",
    "        \n",
    "        best_train_loss_lst = None\n",
    "        best_val_loss_lst = None\n",
    "        best_avg_loss_lst = None\n",
    "        best_fold = np.inf\n",
    "\n",
    "        for fold, (train_ids, val_ids) in enumerate(cv_inner.split(train_dataset)):\n",
    "            #print(f'FOLD {fold+1}:')\n",
    "                       \n",
    "            # Sample elements randomly from a given list of ids, no replacement.\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids) # The ids are the same for both\n",
    "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "            # Define data loaders for training and testing data in this fold\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=train_subsampler) #, batch_size=100\n",
    "            val_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=val_subsampler) #, batch_size=20        \n",
    "\n",
    "            avg_loss_fold, best_model_fold, fold_train_loss_lst, fold_val_loss_lst, fold_avg_loss_lst = find_best_model_for_fold_3(train_dataloader, val_dataloader, learning_rate, num_epochs)\n",
    "                           \n",
    "            if avg_loss_fold < min_avg_loss_subject:\n",
    "                min_avg_loss_subject = avg_loss_fold\n",
    "                best_model_subject = best_model_fold\n",
    "                best_train_loss_lst = fold_train_loss_lst\n",
    "                best_val_loss_lst = fold_val_loss_lst\n",
    "                best_avg_loss_lst = fold_avg_loss_lst\n",
    "                best_fold = fold+1\n",
    "\n",
    "        fig = plt.figure(f\"{participant}\")                  \n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_train_loss_lst)\n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_val_loss_lst)\n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_avg_loss_lst)\n",
    "        plt.title(f\"Loss when participant {participant} is left out for fold {best_fold} (lr={learning_rate}, num_epochs ={num_epochs})\")\n",
    "        plt.legend(['train loss', 'val loss', 'avg_loss'])\n",
    "\n",
    "        # save trained model \n",
    "        name = 'model_participant_'+str(participant)+'.pt'\n",
    "        torch.save(best_model_subject, name)\n",
    "        print(f'The model for participant {participant} has been saved')\n",
    "        \n",
    "        test_model = CNN_LSTM()\n",
    "        test_model.load_state_dict(torch.load(name))\n",
    "\n",
    "        dataiter = iter(test_dataloader) \n",
    "        test_input1, test_input2, test_labels = dataiter.next() \n",
    "    \n",
    "        test_preds = test_model(test_input1, test_input2) \n",
    "        \n",
    "        test_preds_np = test_preds.detach().numpy()\n",
    "        test_predicted_np = np.argmax(test_preds_np, axis = 1)\n",
    "        \n",
    "        test_labels_np = test_labels.numpy()       \n",
    "        \n",
    "\n",
    "        conf_mat = confusion_matrix(test_labels_np, test_predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "        macro_f1_score = f1_score(test_labels_np, test_predicted_np, average='macro') \n",
    "        micro_f1_score = f1_score(test_labels_np, test_predicted_np, average='micro')  \n",
    "        acc = accuracy_score(test_labels_np, test_predicted_np)\n",
    "\n",
    "        print(f\"Leaving participant {participant} out\")\n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        print(f\"(3) macro F1 score = {round(macro_f1_score,2)}\")    \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "        \n",
    "        total_conf_mat += conf_mat \n",
    "        micro_f1_lst.append(micro_f1_score)\n",
    "        macro_f1_lst.append(macro_f1_score) \n",
    "        acc_lst.append(acc)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "    avg_micro_f1_score = sum(micro_f1_lst) / len(micro_f1_lst)\n",
    "    avg_macro_f1_score = sum(macro_f1_lst) / len(macro_f1_lst)         \n",
    "    avg_acc = sum(acc_lst) / len(acc_lst)   \n",
    "    \n",
    "    print(f'Using Leave One Participant Out CV (LOPOCV):') \n",
    "    print(\"(1) Confusion matrix:\\n\", total_conf_mat)\n",
    "    print(f\"(2) Average micro F1 score = {round(avg_micro_f1_score,2)}\")\n",
    "    #if predicting_feature == 'property_id':\n",
    "    print(f\"(3) Average macro F1 score = {round(avg_macro_f1_score,2)}\")\n",
    "    #elif predicting_feature == 'rating_level_num':\n",
    "        #print(f\"(3) Average weighted F1 score = {round(avg_weighted_f1_score,2)}\")      \n",
    "    print(f\"(4) Average Percentage Classification accuracy = {round(avg_acc*100,2)}%\")\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dd47a3",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_LSTM_LOP0CV_properties_1(emg_0, emg_1, num_folds=5, predicting_feature='property_id', learning_rate=0.3, num_epochs=30, random_state=num) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917e1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_LSTM_LOP0CV_properties_1(emg_0, emg_1, num_folds=5, predicting_feature='property_id', learning_rate=0.3, num_epochs=30, random_state=num) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a9d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4283f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model_for_fold_2(train_dataloader, val_dataloader, learning_rate, num_epochs):\n",
    "\n",
    "    # Model\n",
    "    train_model = Linear_model_2()\n",
    "\n",
    "    # Loss and Optimiser\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(train_model.parameters(), lr=learning_rate, momentum=0.7)\n",
    "\n",
    "    best_avg_loss = np.inf\n",
    "    best_model = None\n",
    "    #best_model_epoch_num = np.inf\n",
    "    train_loss_lst = []\n",
    "    val_loss_lst = []\n",
    "    avg_loss_lst = []\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        #Set the model in training mode\n",
    "        train_model.train()\n",
    "\n",
    "        # Initialise the total training and validation loss\n",
    "        epoch_train_loss = 0\n",
    "        epoch_val_loss = 0\n",
    "        avg_loss = 0\n",
    "        #count_train = 0\n",
    "        #count_val = 0\n",
    "\n",
    "        #running_loss = 0.0\n",
    "        for i, train_data in enumerate(train_dataloader, 0):\n",
    "            #print(len(train_data))\n",
    "            #count_train += 1\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "            train_input1, train_labels = train_data #train_input2, \n",
    "\n",
    "            #train_labels = train_labels.type(torch.LongTensor)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            train_preds = train_model(train_input1) #, train_input2\n",
    "            #print(train_labels)#\n",
    "\n",
    "            train_loss = criterion(train_preds, train_labels)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update training loss\n",
    "            epoch_train_loss += train_loss.item()\n",
    "\n",
    "        # Switch off auto grad for evaluation\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # Set the model in evaluation mode\n",
    "            train_model.eval()\n",
    "\n",
    "            for j, val_data in enumerate(val_dataloader, 0):\n",
    "               # count_val += 1\n",
    "               # print(len(val_data))\n",
    "            # get the inputs; data is a list of [input1, input2, label]\n",
    "                val_input1, val_labels = val_data # val_input2, \n",
    "\n",
    "                #val_labels = val_labels.type(torch.LongTensor)\n",
    "\n",
    "                val_preds = train_model(val_input1) #, val_input2\n",
    "\n",
    "                # Update validation loss\n",
    "                val_loss = criterion(val_preds, val_labels)\n",
    "\n",
    "                epoch_val_loss += val_loss.item()\n",
    "        #print(len(train_dataloader), len(val_dataloader))       \n",
    "        avg_training_loss = epoch_train_loss / len(train_dataloader) #count_train\n",
    "        avg_validation_loss = epoch_val_loss / len(val_dataloader) #count_val\n",
    "        avg_loss = (avg_training_loss + avg_validation_loss) / 2\n",
    "        \n",
    "        train_loss_lst.append(avg_training_loss)\n",
    "        val_loss_lst.append(avg_validation_loss)\n",
    "        avg_loss_lst.append(avg_loss)\n",
    "         \n",
    "        #print(f'epoch {epoch+1}: train loss = {round(avg_training_loss,2)}, val loss = {round(avg_validation_loss,2)}, average loss = {round(avg_loss,2)}')\n",
    "\n",
    "        if avg_loss < best_avg_loss:\n",
    "            best_avg_loss = avg_loss\n",
    "            best_model = train_model.state_dict()\n",
    "\n",
    "    return best_avg_loss, best_model, train_loss_lst, val_loss_lst, avg_loss_lst   #, avg_loss_lst, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "def Linear_LOP0CV_properties_2(data, num_folds=5, predicting_feature='property_id', learning_rate=0.01, num_epochs=10, random_state=num, X_dim=2): #, num_inner_folds=5\n",
    "    # Set fixed random number seed\n",
    "    torch.manual_seed(num)\n",
    "    \n",
    "   # elif predicting_feature == 'rating_level_num':\n",
    "    #weighted_f1_lst = [] \n",
    "    total_conf_mat = 0\n",
    "    micro_f1_lst = []\n",
    "    macro_f1_lst = []\n",
    "    acc_lst = []\n",
    "\n",
    "    #lst = [6,24,2]#,24]\n",
    "    \n",
    "    for participant in sorted(data.participant_id.unique()): # #:lst: #\n",
    "        print(f'LEAVING PARTICIPANT {participant} OUT:')\n",
    "        \n",
    "        # Split the data into training and testing\n",
    "        training_data = data[data.participant_id != participant] \n",
    "        testing_data = data[data.participant_id == participant] \n",
    "\n",
    "        # Data preparation\n",
    "        if X_dim == 2:\n",
    "            X_train = create_X_2d(training_data, 11)       \n",
    "            y_train = create_y_train_for_2d_X(training_data, predicting_feature = 'property_id')\n",
    "            X_test = create_X_2d(testing_data, 11) \n",
    "            y_test = create_y_test_for_2d_X(testing_data, predicting_feature = 'property_id')\n",
    "        elif X_dim == 3:\n",
    "            X_train = create_X_3d(training_data, 11)       \n",
    "            y_train = create_y_train_for_3d_X(training_data, predicting_feature = 'property_id')\n",
    "            X_test = create_X_3d(testing_data, 11) \n",
    "            y_test = create_y_test_for_3d_X(testing_data, predicting_feature = 'property_id')\n",
    "\n",
    "        #print(X_train.shape)\n",
    "        #print(y_train.shape)\n",
    "        #print(X_test.shape)\n",
    "        #print(y_test.shape)\n",
    " \n",
    "        # Create the datasets and dataloaders\n",
    "        train_dataset = TensorDataset(X_train, y_train) \n",
    "        \n",
    "        test_dataset = TensorDataset(X_test, y_test)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=90) # num_workers=2,       \n",
    "            \n",
    "        # Configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=num_folds, shuffle=True, random_state=num)\n",
    "                \n",
    "        min_avg_loss_subject = np.inf\n",
    "        best_model_subject = None\n",
    "        \n",
    "        best_train_loss_lst = None\n",
    "        best_val_loss_lst = None\n",
    "        best_avg_loss_lst = None\n",
    "        best_fold = np.inf\n",
    "\n",
    "        for fold, (train_ids, val_ids) in enumerate(cv_inner.split(train_dataset)):\n",
    "            #print(f'FOLD {fold+1}:')\n",
    "                       \n",
    "            # Sample elements randomly from a given list of ids, no replacement.\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids) # The ids are the same for both\n",
    "            val_subsampler = torch.utils.data.SubsetRandomSampler(val_ids)\n",
    "\n",
    "            # Define data loaders for training and testing data in this fold\n",
    "            train_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=train_subsampler) #, batch_size=100\n",
    "            val_dataloader = torch.utils.data.DataLoader(train_dataset, sampler=val_subsampler) #, batch_size=20        \n",
    "\n",
    "            avg_loss_fold, best_model_fold, fold_train_loss_lst, fold_val_loss_lst, fold_avg_loss_lst = find_best_model_for_fold_2(train_dataloader, val_dataloader, learning_rate, num_epochs)\n",
    "                           \n",
    "            if avg_loss_fold < min_avg_loss_subject:\n",
    "                min_avg_loss_subject = avg_loss_fold\n",
    "                best_model_subject = best_model_fold\n",
    "                best_train_loss_lst = fold_train_loss_lst\n",
    "                best_val_loss_lst = fold_val_loss_lst\n",
    "                best_avg_loss_lst = fold_avg_loss_lst\n",
    "                best_fold = fold+1\n",
    "\n",
    "        fig = plt.figure(f\"{participant}\")                  \n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_train_loss_lst)\n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_val_loss_lst)\n",
    "        plt.plot(np.linspace(1, num_epochs, num_epochs).astype(int), best_avg_loss_lst)\n",
    "        plt.title(f\"Loss when participant {participant} is left out for fold {best_fold} (lr={learning_rate}, num_epochs ={num_epochs})\")\n",
    "        plt.legend(['train loss', 'val loss', 'avg_loss'])\n",
    "\n",
    "        # save trained model \n",
    "        name = 'model_participant_'+str(participant)+'.pt'\n",
    "        torch.save(best_model_subject, name)\n",
    "        print(f'The model for participant {participant} has been saved')\n",
    "        \n",
    "        test_model = Linear_model_2()\n",
    "        test_model.load_state_dict(torch.load(name))\n",
    "\n",
    "        dataiter = iter(test_dataloader) \n",
    "        test_input1, test_labels = dataiter.next() \n",
    "    \n",
    "        test_preds = test_model(test_input1) \n",
    "        \n",
    "        test_preds_np = test_preds.detach().numpy()\n",
    "        test_predicted_np = np.argmax(test_preds_np, axis = 1)\n",
    "        \n",
    "        test_labels_np = test_labels.numpy()       \n",
    "        \n",
    "\n",
    "        conf_mat = confusion_matrix(test_labels_np, test_predicted_np, labels=[0, 1, 2, 3, 4])\n",
    "        macro_f1_score = f1_score(test_labels_np, test_predicted_np, average='macro') \n",
    "        micro_f1_score = f1_score(test_labels_np, test_predicted_np, average='micro')  \n",
    "        acc = accuracy_score(test_labels_np, test_predicted_np)\n",
    "\n",
    "        print(f\"Leaving participant {participant} out\")\n",
    "        print(\"(1) Confusion matrix:\\n\", conf_mat)\n",
    "        print(f\"(2) micro F1 score = {round(micro_f1_score,2)}\")\n",
    "        print(f\"(3) macro F1 score = {round(macro_f1_score,2)}\")    \n",
    "        print(f\"(4) Percentage Classification accuracy = {round(acc*100,2)}%\")\n",
    "        \n",
    "        total_conf_mat += conf_mat \n",
    "        micro_f1_lst.append(micro_f1_score)\n",
    "        macro_f1_lst.append(macro_f1_score) \n",
    "        acc_lst.append(acc)\n",
    "        print('--------------------------------')\n",
    "        \n",
    "    avg_micro_f1_score = sum(micro_f1_lst) / len(micro_f1_lst)\n",
    "    avg_macro_f1_score = sum(macro_f1_lst) / len(macro_f1_lst)         \n",
    "    avg_acc = sum(acc_lst) / len(acc_lst)   \n",
    "    \n",
    "    print(f'Using Leave One Participant Out CV (LOPOCV):') \n",
    "    print(\"(1) Confusion matrix:\\n\", total_conf_mat)\n",
    "    print(f\"(2) Average micro F1 score = {round(avg_micro_f1_score,2)}\")\n",
    "    #if predicting_feature == 'property_id':\n",
    "    print(f\"(3) Average macro F1 score = {round(avg_macro_f1_score,2)}\")\n",
    "    #elif predicting_feature == 'rating_level_num':\n",
    "        #print(f\"(3) Average weighted F1 score = {round(avg_weighted_f1_score,2)}\")      \n",
    "    print(f\"(4) Average Percentage Classification accuracy = {round(avg_acc*100,2)}%\")\n",
    "            \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
